Q:

What problem was solved by introducing the dimension of a vector space?

In linear algebra, we care a lot about dimensions. I get why it’s useful but not why it’s such a big deal. So I wondered what problem was solved historically by introducing a rigorous definition of dimension of a vector space?

A:

I will begin by 2 examples where the notion of dimension is essential :

The increasing sequence of subspaces 

$$\{0\}\subset\ker(A-\lambda I)\subset\ker(A-\lambda I)^2\subset\ker(A-\lambda I)^3\subset\dots$$
(with ultimate stabilisation at a certain step) and the connection of their dimensions with the so important Jordan decomposition of a matrix $A$ relatively to eigenvalue $\lambda$ (well described in this answer by Bernard here).

the concept of degree of field extensions (see paragraph "examples" here) where for example $\mathbb{Q} (\sqrt {2},\sqrt {3})$ can be considered in two different ways as a vector space of dimension $4$ over $\mathbb{Q}$. 

But, on an historical point of view, the concept of dimension finds its roots in the connection with 

the concept of rank, which was initially defined as the maximal size of a sub-determinant one could extract from a determinant ,[in modern terms : replace in the previous sentence : "determinant" by "matrices"]. We were far, when this concept has emerged, from "rank = dimension of the range of the corresponding linear mapping". This concept of "rank" has emerged (not with this name) when Rouché has published an article in Journal de l'Ecole Polytechnique (1880) explaining the kind of solutions one could expect from a linear system of $n$ equations with $p$ unknowns and rank $r \le \min(n,p)$ .
[connected to the previous item] the "rank-nullity" theorem. Mathematicians have been accustomed more and more to identify a subspace either as the kernel or the range of a certain linear mapping. This can be traced back to 1884 where Sylvester has defined the "nullity" of a square matrix

Here is a quotation of https://mathshistory.st-andrews.ac.uk/HistTopics/Matrices_and_determinants/ :
Sylvester defined the nullity of $n(A)$ of matrix $A$, to be the largest $i$ such that every minor of $A$ of order $n-i+1$ is zero. He was interested in invariants of matrices, that is properties which are not changed by certain transformations. He proved that
$$\max \{n(A), n(B)\} \le n(AB) \le n(A) + n(B)$$. 
Remark : The concept of dimension/rank can be enlarged

"The rank of a mathematical object is defined whenever that object is free. In general, the rank of a free object is the cardinal number of the free generating subset G" as explained in https://mathworld.wolfram.com/Rank.html. 
it is also to be connected to the "number of degrees of freedom", a somewhat looser concept that can be much more complicated when you are not in the linear case, with manifolds (generalized surfaces) instead of vector spaces.  
it has been discovered in the 1960s in the framework of numerical analysis that there is a notion of low rank approximation expressing that for example a set of points in the $n$-dimensional space is "close to belong to $p$-dimensional subspace", using the concept of "singular value decomposition" (a generalization of eigenvalues/vectors decomposition). These concepts are very fundamental in present-day treatments of the so-called "big-data".

