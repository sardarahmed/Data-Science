Q:

What changes in mathematics resulted in the change of the definition of primes and exclusion of 1?

Why 1 is not prime? I read in this article that G.H Hardy explicitly included 1 as a prime in the first 6 editions of "A Course in Pure Mathematics", published between 1908-1933. He updated the definition in 1938 to make $2$ the smallest prime. What was the reason behind this?
Also from todays Ring Theory course we get the definition of prime to be $$\text{if}\  p|ab \ \text{then either} \ p|a \ \text{or} \ p|b.$$
Although in a $\operatorname{PID}$ primes and irreducibles are equivalent.
What changes in mathematics resulted in the change of the definition of primes and exclude 1?
I mean how the definition of prime evolved with time?

A:

As to the primality of $1$, nothing really evolved. This is an illustration that some things in mathematics are not right or wrong, they are just a matter of taste. And some fraction of the population prefers a definition that does not make an explicit exception for $1$. The prime/irreducible shift in terminology, on the other hand, does reflect changes in mathematics, namely the exploration of number rings without unique factorization in the 19th century, first by Kummer and then by Dedekind.
Caldwell et al. in The History of the Primality of One collected source quotes concerning $1$ being prime (and a number) from Plato to 2012, and they show that the disarray on this issue goes back to antiquity. While Plato and Aristotle did not even consider $1$ to be a number, let alone prime, Plato's nephew and successor Speusippus took it to be both, although he was unique in this regard at the time. Over the centuries he got company (Waring, Gregory, Legendre, etc.), but  $1$-is-a-prime party has always been in the minority. Hardy was its last prominent representative, but some schoolbooks count $1$ among primes as late as 2012. In Why Isn't 1 a Prime Number? Evelyn Lamb speculates that the exclusion of $1$ is due to the desire to have uniqueness in the prime factorization theorem, and hence to separate primes from units. But even if this is a factor now the widespread exclusion much predates Gauss's formulation of the theorem and the times when people paid attention to such abstractions.
But unique factorization did play a direct role in the definitional shift in ring theory. In History of the terms “prime” and “irreducible” in Ring Theory on Math SE @mweiss speculated that the shift occurred due to first reproducing the traditional definition of (integer) primes at the level of ideals, and then descending it to the level of elements. This leads to the modern convention in ring theory that turns Euclid's lemma into the definition of prime quoted in the OP.
As neat as this theory is, it is not how it happened. The shift can be traced to Dedekind's Sur la théorie des nombres entiers algébriques (1877), and Dedekind makes it before introducing ideals, when considering divisibility in the ring $\mathbb{Z}(\sqrt{-5})$ singled out by Kummer. Moreover, Dedekind makes clear that he considers Euclid's lemma, not the traditional definition, to be the "characteristic" property of primes, because it is what gives unique factorization. Accordingly, he renames what the traditional definition defines into "irréductible", "irreducible".
A nice expose of Dedekind's 1877 work, with English translation of extensive excerpts and commentary, is Barnett's Richard Dedekind and the Creation of an Ideal: Early Developments in Ring Theory. Here are some Dedekind's quotes in Barnett's translation (he translates "irréductible" as "indecomposable"):

"Each positive number, different
from unity, is either a prime number, that is, a number divisible only by itself and unity, or else
a composite number. In the latter case we can always express it as a product of prime numbers
and -- which is the most important thing -- in only one way. That is, the system of prime
numbers occurring as factors in this product is completely determined by giving the number of
times a designated prime number occurs as factor. This property depends essentially on the
theorem that a prime divides a product of two factors only when it divides one of the factors.

[...] A number (different from zero and $\pm1$) is called decomposable when it is the product of two factors, neither of which is a unit. In the contrary case the number is called indecomposable... However, despite the indecomposability of these fifteen numbers, there are numerous relations between their products... In each of these ten relations, the same number is represented in two or three different ways
as a product of indecomposable numbers. Thus one sees that an indecomposable number
may very well divide a product without dividing any of its factors. Such an indecomposable
number therefore does not possess the property which, in the theory of rational numbers, is
characteristic of a prime number."

