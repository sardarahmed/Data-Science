Q:

What is the S notation in Student's The Probable Error of a Mean?

In William S. Gosset's The Probable Error of a Mean (JSTOR), he begins to derive the $t$ sampling distribution as follows.

Samples of $n$ individuals are drawn out of a population distributed normally...
If $s$ be the standard deviation found from a sample $x_1,x_2,...x_n$ (all these being measured from the mean of the population), then

$$
s^2 = \frac{S(x_1^2)}{n}-\left(\frac{S(x_1)}{n}\right)^2 = \frac{S(x_1^2)}{n} - \frac{S(x_1)^2}{n^2} - \frac{2S(x_1x_2)}{n^2}
$$
And so on. What is the meaning of the $S$ notation, $S(x_1)$?
My first guess was summation, but summing over a scalar ($x_1$) doesn't mean much, and it's not clear how $S(x_1x_2)$ gets introduced.

Edit. @terry-s 's answer is correct, I just thought I'd add how Gosset's equation comes out of the typical sample standard deviation for anyone curious. The typical definition of standard deviation is (without Bessel's correction):
$$
s^2 = \frac{1}{n} \sum (x_i-\bar x)^2
$$
For
$$
\bar x = \frac{\sum x_i}{n}
$$
If we expand, we have
$$
(x_i-\bar x) = x_i^2 + \bar x ^2 - 2\bar x x_i
$$
And thus the expression for $s^2$ becomes (after evaluating the sum of $\bar x$)
$$
s^2 = \bar x^2 + \frac{\sum x_i^2}{n} - 2\bar x\frac{\sum x_i}{n}
$$
And finally, by the definition of $\bar x$, the first and last terms on the right combine to give $-\bar x^2$, so
$$
s^2 = \frac{\sum x_i^2}{n} - \bar x^2
$$
Or, more in line with Gosset's equation, this is
$$
s^2 = \frac{\sum x_i^2}{n} - \left(\frac{\sum x_i}{n}\right)^2
$$
Which is identical to the equation Gosset starts with, assuming $S(x_1)=\sum x_i$. By the identity
$$
\left(\sum x_i\right)^2 = \sum x_i^2 +2\sum_i \sum_{j=1}^{i-1} x_i x_j
$$
we can expand the right-most term as
$$
\left(\frac{\sum x_i}{n}\right)^2 = \frac{1}{n^2} \sum x_i^2 + \frac{2}{n^2} \sum_{i,\ j} x_i x_j
$$
Where the double summation is to be performed for each $i$, taking $j$ from 1 to $i$, and this is what Gosset intended by $S(x_1 x_2)$.

A:

I believe your 'first-guess' reading of "Student"'s $S()$ notation is actually right: on comparing it with other conventions for writing the sample variance $s^2$, the notation $S()$ appears to be a forerunner of modern $\Sigma$ notation.
But in any event it appears there are also further problems with the text of "Student"'s paper, caused either by the typography of the original or perhaps the reprint version, or else by original ambiguities or inconsistencies of notation and usage.
For example, if the first equation that you quote is to make sense as part of an evaluation of some sample variance or standard deviation as stated, it seems that $x_1$ in the first term $(1/n)S(x_1^2)$ has to mean something like 'each of the sample differences like $x_1$' -- i.e. what would now be written $x_i$ with the summation taken from $i = 1$ to $i = n$. (If it doesn't mean something like that, then as you already said, it would look meaningless to sum over a single item.) But such an $x_i$ interpretation of $x_1$ is inconsistent with the usage of $x_1$ in the immediately-preceding description of the sample, where $x_1$ is given as only one single item in the sample group of differences from the (population) mean. Then again, the second term of the first equation quoted has to be read non-literally or as a typo, else the two terms mean the same and are equal, and the first equation collapses to a trivial zero value, which certainly can't have been intended.
All in all, I'd suggest that the original paper presents such problems
of typography or ambiguity that it might be advisable to refer first to a more modern source, and then if the old paper is the point of historical interest, the more modern texts can provide means to help decipherment. (An example I'd offer of a text with modern descendants of the old equations to use for decipherment would be Wall & Jenkins, 'Practical Statistics for Astronomers', but that's just a local choice of something at hand, there are dozens of others. Another reference with exclusive focus on testing with the t-distribution, that might be helpful, is de Winter (2013), "Using the Student's t-test with extremely small sample sizes".)

