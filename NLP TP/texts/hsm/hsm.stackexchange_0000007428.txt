Q:

When were adversarial techniques first used in machine learning?

For the purposes of this question, a technique is considered adversarial if it develops two systems (or two kinds of system), the first trying to process certain kinds of data well, and the second trying to provide the first with hard-to-process data. Examples include:

Adversarial machine learning, in which the processor tries to identify security risks, while the agent trying to fool it seeks to bypass security checks;
Generative adversarial networks, in which the processor is discriminative (i.e. it models a conditional probability distribution) and the agent trying to fool it is generative (i.e. it models a joint probability distribution).

Judging by the dates discussed in the above links, AML dates to the early 2000s while GANs date to 2014. These both seem very recent, and I suspect the general meaning of "adversarial" I specify above has been used for much longer. Clearly, the idea of requiring continual adaptation by both agents to shifting goalposts need not be tied to such specific examples as security or Bayesian models. Any simulation of two competing species evolving, e.g. a predator and its prey, will be "adversarial" in the sense of this question.
So my question is: when was some kind of adversarial technique first used, in the hope it would lead to machines learning to solve problems more effectively than would happen without adversarial techniques? (A simulation that illustrates how biological evolution works, without wanting to solve a specific data-driven problem of human interest, would not qualify.)

A:

I am unsure as to the parameters of what is being asked, so this may not answer it. First, "data-driven problem" is a term linked to the recent rise of data science and projecting it too far into the past risks modernizing people's intentions. Second, biological evolution need not work by "competition" between two or more species, natural selection applies even to a single species in its "competition" with the environment. And in artificial selection (real or simulated) the environment can be intentionally manipulated to make it an "adversary".
Lotka and Volterra developed predator-prey models in 1920-s, but there were no "data machines" then and this probably would not be "wanting to solve a specific data-driven problem of human interest". Closer is perhaps Turing's celebrated 1950 paper Computing Machinery and Intelligence, where he proposed his "imitation game" where a machine tries to fool a human interrogator, the origin of the "Turing test" of machine intelligence, and even suggested "evolutionary learning" as a means of achieving it: 

"We  have  thus  divided  our  problem  into  two  parts.   The child-programme  and the  education  process.   These two remain very  closely connected. We cannot  expect to find a  good child-machine at the  first  attempt. One  must experiment with teaching one such  machine and  see how well it  learns. One can then try another  and  see  if  it  is  better  or  worse.   There  is  an  obvious connection  between  this  process  and  evolution... Equally important is the  fact  that  he  is not  restricted  to  random  mutations.    If  he can trace a cause for  some weakness he can probably think  of the kind  of mutation which will improve it... It  is probably  wise to  include a  random  element  in a  learning machine... Since  there  is  probably  a  very  large number   of   satisfactory   solutions  the   random   method   seems to  be better than the systematic.   It  should  be noticed that  it  is
  used   in  the  analogous  process   of   evolution."

It is not clear to me that Turing proposes automating both "adversaries" here, but this paper is often cited as seminal on machine learning and genetic algorithms, where candidate solutions to optimization or search problems are treated as an evolving population of "individuals" with "traits", and generational selection is implemented according to "fitness". It is believed that Fraser's 1957 simulations of artificial selection incorporated all the requisite elements of such algorithms, but again, I am not sure if this was "data-driven". Bremermann in the 1960s used "evolving programs" specifically to solve optimization problems, see e.g. Revisiting Bremermannâ€™s Genetic Algorithm by Fogel and Anderson. 
As for the more narrowly understood agent vs agent machine learning that is indeed recent, although computer programs playing against each other dates back to 1980-s.

