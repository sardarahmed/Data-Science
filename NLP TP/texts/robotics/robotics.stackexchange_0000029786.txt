Q:

camera_calibration for multiple camera setup

I'm currently looking at the camera_calibration package to use it in our lab. We have a setup with multiple cameras (= more than a dual setup). I would like to know if there are other people with a similar setup and how did you calibrate? I could to the stereo calibration for every camera pair but I'm rather interested in expanding the camera_calibration.
One thing I'm mainly interested in is getting the extrinsic calibration correct to reflect the entire lab in stead of just reflecting the stereo setup. Because I also need this information in a tf publisher node for other calculations.
Because we have hardware 'configurable' synchronization getting same timestamps should be to much of a problem (I still need to find out what the influence of the NIC will be).
Are there people interested in collaborating?

Originally posted by KoenBuys on ROS Answers with karma: 2314 on 2011-02-22
Post score: 2

A:

Hi Koen, for the extrinsic calibration of multiple cameras it is considerably more difficult to generate feature correspondences and initial poses for the optimisation.
In the stereo-vision case multiple views of a checkerboard are ideal: we can make assumptions about the relative views eg. the cameras are roughly pointing in the same direction and share the same "up". After extracting the checkerboard corners it's easy to assume the feature correspondences. Given the checkerboard size we can also estimate the relative camera pose.
You'll probably need to calibrate each cameras' intrinsics separately, and then investigate either 1) using some sort of fiduciary marker, or 2) a rich feature descriptor (eg SURF) and a lot of random objects in your scene to generate the feature correspondences for bundle adjustment. This really becomes a full bundle adjustment problem. Most of the code you'll need is in this stack.
If you have a small separation between your cameras you might get away with a checkerboard pattern with one corner modified so you can uniquely identify "up" on the board. You could then generate initial relative camera pose estimates and feature correspondences from that.
Edit: The camera_pose_calibration package recently appeared on the ROS wiki. It looks like what you're after.

Originally posted by rreid with karma: 124 on 2011-03-22
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by mkoval on 2011-04-27:
Were you able to install the camera_pose_calibration package? Installing the deb using the instructions on the Wiki fails because there does not seem to be a package named ros-diamondback-camera-pose.
Comment by rreid on 2011-03-23:
The stereo calibration is inherited from OpenCV, and was never designed for the "general" use case. http://opencv.willowgarage.com/documentation/camera_calibration_and_3d_reconstruction.html ...what you're asking for is non-trivial. Unfortunately i dont have time to help at the moment, sorry.
Comment by KoenBuys on 2011-03-22:
One of the things I wanted to ask is : who is interested in sharing the workload to implement such a 'general' package and why doesn't image_geometry implement the general calibration matrix (instead of the specific one now) and that the stereo_calibration makes such assumptions?

