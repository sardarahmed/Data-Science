Q:

More information for multisensor fusion needed

Hello there,
I'm a beginner at ROS and I've some questions regarding multisensor fusion. I am currently working on a robot (Pioneer P3-AT) with a monocular vision and Hokuyo LRF without an a priori map. However, I am unclear about how to apply the proposed algorithms like EKF, Bayesian, etc. I've read many journals about applying feature extraction, where the camera extracts vertical edges and segmentation technique applied on the LRF.
It'll be awesome if I can get some explanation about which algorithms to use and if there are any libraries around. And also, isit possible to obtain the fused data and use the available libraries (e.g. GMapping, GridSLAM, OctoMap) to create a map, localize and navigate?
Thanks.

Originally posted by barrybear on ROS Answers with karma: 57 on 2012-12-06
Post score: 2

A:

There are many possible ways to build your pipeline. However, there are several tools that already exist in ROS, to get you started:

viso2_ros: A library for visual odometry from a monocular camera
laser_scan_matcher: A tool for laser-based odometry via scan matching
hector_mapping: A tool for laser-based odometry and SLAM
robot_pose_ekf: An EKF filter capable of fusing different odometry sources
gmapping: A laser-based algorithm for SLAM, requiring an odometric estimate

The general pipeline is to gather available sources of odometry (laser, camera, wheels, IMU) and fuse them using the EKF filter. Next, feed the fused output, together with laser scans, to a SLAM/mapping algorithm, in order to build a metric grid map.

Originally posted by Ivan Dryanovski with karma: 4954 on 2012-12-07
This answer was ACCEPTED on the original site
Post score: 5

Original comments
Comment by barrybear on 2012-12-08:
Wow thanks! Thats alot of information provided :) However if I may ask, the laser_scan_matcher library is able to obtain input from not only the laser range scanner, but also wheel odometry, velocity model, etc but the hector_mapping only uses laser range scanner right?
Comment by barrybear on 2012-12-08:
So, does that mean I can just use either one of these libraries? And also, would a pan-tilt-unit be signifcant in obtaining more accurate results but also may cause complex programming for the sensor fusion?
Comment by Ivan Dryanovski on 2012-12-08:
laser_scan_matcher accepts these as inputs to help the scan matching, but doesn't fuse them in the filter sense. I believe hector_mapping accepts IMU. You can try either any laser / camera odometry package and see what performance you get.
Comment by Ivan Dryanovski on 2012-12-08:
Lasers scanners operate on the 2D assumption, so a pan-tilt laser probably wouldn't improve anything. A camera mounted on a Pan-tilt might give you pmore freedom, but it would certainly come at the cost of a more complicated pipeline. I'm not sure how viso2 handls  that.
Comment by barrybear on 2012-12-08:
Oh alright. I guess I'll try to get it working first without so many complications involved :p Thanks Ivan Dryanovski for an awesome insight! :)
Comment by barrybear on 2012-12-08:
Oh alright. I guess I'll try to get it working first without so many complications involved :p
Comment by barrybear on 2012-12-08:
Oh alright. I guess I'll try to get it working first without so many complications involved :p
Comment by barrybear on 2013-05-19:
Hello @Ivan Dryanovski! I was continue working on the ROS nodes as you described above, but I am kinda confused as to which TF/sensor msgs to send from laser & cam to the ROS_Pose_EKF. And then what's next to send to the Hector_Mapping or GMapping..

