Q:

About slam_gmapping

Nice to meet you
I am studying creating an environmental map using turtlebot2 and gmapping.
turtlebot2 performs object recognition when generating an environmental map,
As a result, in the environmental map, the object recognition result
I am thinking to add position information of objects.
So I have something I would like to ask everyone.
It is a package that performs SLAM with turtlebot2↓
roslaunch turtlebot_navigation gmapping_demo.launch

Save the environmental map generated by SLAM as an image↓
rosrun map_server map_server

I would like to add a node related to object recognition by rewriting the above contents.
However, to me who just began to learn ROS
I am not considering what kind of procedure to proceed.
In the first place, edit the package provided at the time of installing ROS,
Including whether it is possible to add functions
I am pleased if you can teach.
I look forward to your reply
Finally I will describe the environment of my PC.
Ubuntu14.04, ROS indigo

Originally posted by green youth on ROS Answers with karma: 1 on 2017-09-11
Post score: 0

Original comments
Comment by bvbdort on 2017-09-11:
I guess, for object recognition you are using RGB images. You need a transform between the robot location(from where you detected the object) and the position of the object in robot frame. You need either RGBD camera or you have to detect objects using with laser scans.

A:

you can use the pacakage named turtlebot_navigationto navigate.By using this package,you need a kinect camera or something like rplidar to gather data.And then ,you can use it for obstacle-avoid,but some parameters must be changed to suit your robot.

Originally posted by skydddive with karma: 26 on 2018-07-04
This answer was ACCEPTED on the original site
Post score: 0

