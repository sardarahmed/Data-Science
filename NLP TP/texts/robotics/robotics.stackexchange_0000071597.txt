Q:

Not use kinect, how to show scan by rviz?

I use binocular cameras to capture images, and calculate the depth images. Now I transform depth image to pointcloud msg, I can show pointcloud by rviz.
Finally, I use pointcloud_to_laserscan node to acquire scan, but can't show scan by rviz. I guess the reason is I've never been set frame, I don't know how to set the frame. Can anyone help me?

Originally posted by 123 on ROS Answers with karma: 1 on 2016-01-25
Post score: 0

A:

The most likely error is that you never set the frame, yes. But to be sure RViz usually tells what the problem is in the displays section (left) of the window.
All you have to do it to run a node together with the rest of your code that publishes the corresponding transformation between any of the frames in your TF (world or base_link for instance) to the frame you want the laserscan to be represented. For this, you can follow this python or c++ tutorials. In those tutorials, just change the parameters of the transformations and the frame names.
Note: For your application, it seems that the approach stereo-vision to laserscan is a bit unefficient if you are computing the full pointcloud from the cameras. If you are going to use only the laserscan (and not the pointcloud for any other reason) I suggest just to get the 3D data from the corresponding plane and transform directly into laserscan instead of having all the overhead in the middle.

Originally posted by Javier V. Gómez with karma: 1305 on 2016-01-26
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by 123 on 2016-01-26:
In the tutorials, the example uses the pose of a turtle to make a frame, I don't know how to make a frame for pointcloud or scan, which point is the initial position? Thanks!
Comment by Javier V. Gómez on 2016-03-03:
@123 Please next time use @user_name so that I get a notification. All you have to do it to publish a transformation but is up to you to fill this transformation. It can be with constant values, for example.

