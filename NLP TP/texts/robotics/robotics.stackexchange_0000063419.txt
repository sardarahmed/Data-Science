Q:

gmapping with Structure Sensor

Hi
I am using the Structure Sensor onboard the Parrot AR.Drone for SLAM
The Structure Sensor is a depth sensor and cannot use RGB-D SLAM techniques
the structure sensor is connected to the ODROID-U3 board which runs on ROS Indigo
I would like to ask if I can use the gmapping slam with the Structure sensor
If yes, could you provide with a system architecture.
What are the system dependencies that have to be installed

Originally posted by Francis Dom on ROS Answers with karma: 21 on 2014-10-20
Post score: 0

A:

Specwise, the structure sensor seems to be very similar to the Kinect/Xtion in terms of resolution, refresh rate, and  FOV. It's a shame they didn't include RGB output.
The FOV on the Kinect is they typical limitation for gmapping, since it can't match as many features as a laserscanner, and doesn't map as much area. It's also fairly noisy compared to a typical laserscanner.
You're also missing odometry, which is necessary for gmapping, and in general makes the task a lot harder. You could try hector_slam, which works without odometry, though I've never tested it myself. Feel free to search around for kinect + hector_slam threads, and you'll find that most people don't have a lot of luck with that setup.
Since you asked about architecture, you'd use the pointcloud_to_laserscan nodelet to convert the pointcloud into a laserscan, and then go from there with the standard gmapping/hector_slam tutorials.

Originally posted by paulbovbel with karma: 4518 on 2014-10-20
This answer was ACCEPTED on the original site
Post score: 0

