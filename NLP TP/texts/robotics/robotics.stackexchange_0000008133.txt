Q:

"Ambiguous up to scale" , Explanation required

I am reading "Computer Vision: Models, Learning, and Inference" in which author writes at several points (like on page 428-429) that although matrix A seems to have 'n' degree of freedom but since it is ambiguous up to scale so it only has 'n-1' degree of freedom? Can anyone explain what this thing means? Why one degree of freedom is decreased?

A:

I don't have access to the quoted reference, but believe the explanation (stated, for simplicity, in terms of a vector rather than a matrix) below will apply. 
Consider an  $n$-element vector $V$.  In general, there are $n$ degrees of freedom for populating the vector.  However, if scale is unimportant or of no account, that is, if all scalar multiples $a V$ are taken as equivalent, then we might as well scale $V$ so that $||V|| = 1$ (ie has unit length).  In this case, we have at most $n-1$ degrees of freedom, because specifying any $n-1$ elements of a unit length vector forces the value of the remaining element.

