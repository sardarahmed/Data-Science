Q:

Directional hearing for Linux robot?

I want to give my Linux robot the ability to locate a sound source and drive towards it. I am reading a paper on sound localization that seems to cover the theory well enough, but I'm at a loss as to how do I implement it. Specifically I would like to know:

How do I connect two microphones to a Linux PC?
How do I record from two microphones simultaneously?
Is there any library of sound processing algorithms (similar to how OpenCV is a library of computer vision algorithms) available for Linux?

A:

The easiest way to connect multiple microphones to a Linux PC is probably to use USB mics. There are myriad brands appealing to all tastes and pocket sizes, check your favorite online marketplace for options.
The PortAudio C++ library (and its Python wrapper, PyAudio) enable cross-platform access to multiple audio devices in either callback or blocking modes. Also see here for a list of audio-processing libraries; specifically, the Open embeddeD Audition System (ODAS) and Time Difference of Arrival (TDOAS) libraries are concerned with determining the direction of sound sources. Additionally, a solution implemented directly on PyAudio is discussed here.
For an integrated solution, the ReSpeaker project builds a variety of microphone arrays that can be controlled through a Python API. See here for how it can be used to determine sound source direction.

