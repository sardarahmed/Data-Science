Q:

Navigation for a Humanoid robot

Hello, after being quite a bit confused on how to navigate my biped robot in an partly unknown environment (I do have a floorplan, but do not know where obstacles are), I want to share my thoughts and ask you for feedback If my approach makes sense or not.
What I do have:

a static OccupancyGrid of the floorplan

odometry data from the robot

PointCloud from Kinect

a desired Goal

My plan now is to use :

amcl (with kinect_to_laser, tf, and the static floorplan) to get /map -> /odom

costmap_2d (with static floorplan, tf and PointCloud2) to create a map for the global planner

navfn (or any other global planner) to get a global path for the robot (with CostMap2D and tf)

octomap_server (with PointCloud2 and tf) to get an OccupancyGrid for the step planner (local planner)

footstep_planner (with the Occupancy Grid, a local goal on the global path and tf) to finaly get footsteps.

I think the setup should be quite fine, but I'm not shure how to implement this in ROS.
I had a look at the move_base node and the BaseLocalPlanner interface from nav_core and thought to add the octomap_server and the footstep_planner as local_planner but the interface defined in the nav_core does not fit the needs of the foostep planner.
My second approach would be to use costmap2D and navfn as standalone nodes and write a new node that similar to move_base that is cooridnating the planning. But here I'm not sure if this isn't quite a lot of work to run all the nodes from navigation stack as standalone.
It would be great if anyone could give me some suggestions and feedback on the approach itself and what would be the best way to implement this in ROS.
Best Wishes
Johannes

Originally posted by Johannes on ROS Answers with karma: 75 on 2013-09-09
Post score: 3

A:

If you already use OctoMap for a 3D map, then you could also have a look at the humanoid_localization package. You could obtain more accurate estimates since you already use a 3D sensor (and throw information away by converting it to a fake laser scan).
Using the footstep_planner is a good starting point. You should be aware, however, that you will get sub-optimal results if you rely on navfn as a global planner, instead of just using the footstep planner. It will avoid obstacles, while there could be footsteps over / across them. Depending on your robot, this could not be a problem however.
In general I found the ROS nav stack not really suited for a walking humanoid and too complicated to set up, there were too many things that didn't work.

Originally posted by AHornung with karma: 5904 on 2013-10-17
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by AHornung on 2013-10-17:
Here's an example of using a static OctoMap, humanoid_localization, and a dynamically built OctoMap for obstacle avoidance with a humanoid: http://www.youtube.com/watch?v=srcx7lPoIfw

