Q:

Streaming RGB with asus and using houghlines algorithm

Im currently using Ubuntu and running on ROS groovy.
My intention is to live stream RGB images from Asus Xtion pro and run the houghlines transform algorithm from opencv. I created my own package and ran the code for the openCV houghlines codes and manage to detect lines from images that i put into it.
But how can i combine live stream image from asus with the houghline algorithm? I want to detect a marked out box on the floor using a Asus Xtion Pro and finding the center point of the box.
Can any one help me with this. I just started using ROS and OpenCV and went through the tutorial.

include "opencv2/highgui/highgui.hpp"
include "opencv2/imgproc/imgproc.hpp"

include <iostream>

using namespace cv;
using namespace std;

static void help()
{
    cout << "\nThis program demonstrates line finding with the Hough transform.\n"
            "Usage:\n"
            "./houghlines <image_name>, Default is Trapezium.jpg\n" << endl;
}

int main(int argc, char** argv)
{
    const char* filename = argc >= 2 ? argv[1] : "Trapezium.jpg";

    Mat src = imread(filename, 0);
    if(src.empty())
    {
        help();
        cout << "can not open " << filename << endl;
        return -1;
    }

    Mat dst, cdst;
    Canny(src, dst, 50, 200, 3);
    cvtColor(dst, cdst, COLOR_GRAY2BGR);

    if 0
    vector<Vec2f> lines;
    HoughLines(dst, lines, 1, CV_PI/180, 100, 0, 0 );

    for( size_t i = 0; i < lines.size(); i++ )
    {
        float rho = lines[i][0], theta = lines[i][1];
        Point pt1, pt2;
        double a = cos(theta), b = sin(theta);
        double x0 = a*rho, y0 = b*rho;
        pt1.x = cvRound(x0 + 1000*(-b));
        pt1.y = cvRound(y0 + 1000*(a));
        pt2.x = cvRound(x0 - 1000*(-b));
        pt2.y = cvRound(y0 - 1000*(a));
        line( cdst, pt1, pt2, Scalar(0,0,255), 3, CV_AA);
    }
    else
        vector<Vec4i> lines;
    HoughLinesP(dst, lines, 1, CV_PI/180, 50, 50, 10 );
    for( size_t i = 0; i < lines.size(); i++ )
    {
        Vec4i l = lines[i];
        line( cdst, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(0,0,255), 3, CV_AA);
    }
    endif
    imshow("source", src);
    imshow("detected lines", cdst);

    waitKey();

    return 0;
}

Originally posted by Azl on ROS Answers with karma: 3 on 2014-08-05
Post score: 0

A:

Hi there and welcome to ROS
You should check out the tutorial Writting a simple image subscriber, there you have a clear explanation on how to subscribe to an image topic and transform that to an OpenCV-compatible data structure using cv_bridge.
Then on the image subscriber callback you execute the routine that you implemented to detect HoughLines.
Avoid using cv::imshow and cv::waitKey inside the callback or be really careful using it. If you want to visualise the results I would recommend you to publish the result of your processing (cdst in the code that you posetd) into its own topic and use the package image_view to visualize it.
Then to start the Asus Xtion Pro run the command:
roslaunch openni2_launch openni2.launch

This will publish the topic /camera/rgb/image_raw (among others)
Then run the node that you will implement following the tutorial that I mentioned before, remapping the topic camera/image to /camera/rgb/image_raw.

Originally posted by Martin Peris with karma: 5625 on 2014-08-05
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by Azl on 2014-08-05:
Thanks for the prompt reply. Greatly appreciated.
I will start on the tutorial above.

