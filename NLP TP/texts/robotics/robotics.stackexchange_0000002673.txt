Q:

Passive ego-motion estimation vs active

I am doing research of ego-motion estimation and positioning in 6DoF space. And I found that apparently all systems are based on active RGB-D sensors, like Kinect. I understand, that such sensors provide greater accuracy, and requires less computational resources.
But if such systems will be used, for example, for augmented reality or robot navigation, how they are going to solve the problem of the interference of signals from different systems, operating in the same space? If many people will wear AR glasses with active sensors - they will interfere with each other, aren't they?
Are there big commercial projects, that use passive visual odometry with multiple camera units and IMU sensors? I found some good papers on this topic, but I have not found commercial application of such technology. I am going to make research of passive odometry method for AR, but is it actually a problem with active depth sensors, that i described earlier?
UPD:
The main question:
Is passive odometry, based on video flow analysis and IMU, worth to make deep research in this topic, or active sensors - is our future, and the signal mix is not a big deal, and passive odometry is a dead end of such kind of technology? Because it will be not very useful to make research in useless technology...

A:

Regarding interference of active sensors: Yes, this is a problem for Primesensor-based RGBD cameras (like the Kinect), but it does not make these sensors completely useless. There are even some clever hardware hacks to work around this problem. A much bigger problem of these sensors is exposure to direct sunlight. This has slightly improved with Kinect 2.0.
About your main question: The different approaches you mentioned all have different advantages and problems/failure cases. RGB-D sensors suffer from interference (the worst being interference with sunlight). A similar alternative is relying on stereo vision, but this is computationally more expensive and may fail in textureless environments. Monocular camera + IMU requires the least space/weight but is less accurate.
Neither option is going to become completely irrelevant in the near future, but the ideal approach depends on the exact problem you need to solve.

