Q:

Guessing the K matrix gain for the Optimal Control LQR?

I'm are going to create a LQR to control a system. The problem is to choose the Q and R weighting matrices for the cost function. The Q and R matrices are going to minimize the cost function so the system are going to be optimal.
I'm using Scilab and Scilab have a good library for optimal control. Scilab have a built function named lqr() to compute the gain matrix K, which is the LQ regulator. 
But the problem is still to choose those weighting matrices. I don't know here to start. I just might start with the identity matrix as Q and just a constant as R. But the gain matrix K does not make my model go smooth. No one can say that this is the real Q and R weighting matrices for the system. As a developer, I choose the weighting matrices. But why should I do that when I can choose the K gain matrix directly?
So I just made up my own numbers for the gain matrix K and now my model is very smooth. All I did just do was to guess some numbers for the gain matrix K and simulate and look at the result. Was it still bad, I might change the first element for the gain matrix to increase the position, or change the second element in the gain matrix K, to speed up the velocity for the position. 
This works great for me! Guessing and simulate and look at the results.
I choosing the LQ-technique for two main reasons: It gives multivariable action and can reduce noise by using a kalman filter. A PID cannot do that. 
But here is my question:
Will this method give me an optimal control just by guessing the gain matrix K and changing the values depending how the simulation results looks like?
I'm I happy with the results, I might quit there and accept the gain matrix K as the optimal LQR for the system.

A:

If you want to avoid having to deal with the non-uniqueness of a state space model representations of LTI systems and want to have some more control of the impact that changing $Q$ has on the resulting controller, then you could define the cost you want to minimize as
$$
J(u) = \int_0^\infty\left(y^\top\!(t)\, \hat{Q}\, y(t) + u^\top\!(t)\, \hat{R}\, u(t) + 2\,y^\top\!(t)\, \hat{N}\, u(t)\right) dt.
$$
If your state space model is of the form
$$
\left\{\begin{array}{l}
\dot{x} = A\, x + B\, u \\
y = C\, x + D\, u
\end{array}\right.
$$
then you can rewrite the cost function into a form which can be solved with LQR as follows
$$
J(u) = \int_0^\infty\left(x^\top\!(t)\, Q\, x(t) + u^\top\!(t)\, R\, u(t) + 2\,x^\top\!(t)\, N\, u(t)\right) dt,
$$
with
$$
Q = C^\top \hat{Q}\, C,
$$
$$
R = \hat{R} + D^\top \hat{Q}\, D + D^\top \hat{N} + \hat{N}^\top D,
$$
$$
N = C^\top \hat{N} + C^\top \hat{Q}\, D.
$$
Now you could start with $\hat{R}$ equal identity, $\hat{N}$ equal zero and $\hat{Q}$ diagonal (with only positive numbers on the diagonal), for example identity. Now by doing a simulation of your closed-loop system using the obtained LQR controller you can see if you have desired performance. If for example the $k$th output decays too slowly, you could increase the value of the $k$th diagonal element of $\hat{Q}$.
If you would also like to guarantee internal stability of the system you could also add an identity matrix multiplied by a small positive number to the expression for $Q$. In order to get some estimate of the size of this small number you could maybe use a couple of orders of magnitude smaller (say $10^{-6}$) than the largest eigenvalue of the initially obtained $Q$.
So using this transformation of $(\hat{Q},\hat{R},\hat{N})\to(Q,R,N)$ should give you some more intuitive tuning nobs when designing a LQR controller. This method should also not be affected by the state space realization you are using of the LTI system.

