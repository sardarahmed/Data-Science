Q:

Using Accelerometer, Gyroscope and any sensor to track speed, position,

Problem
Currently working on reverse engineering this application zepp.com/baseball. This is a wearable device that can track a users 

speed
positional tracking
when the object makes contact with another one 
3-D Rendering

Currently using an accelerometer and gyroscope to get the yaw, pitch, and roll(orientation) of the device, but do not know how to use that information to calculate speed, or if the device has collided with another object?

A:

You are essentially making your own IMU.  The way this works is essentially: 

the accelerometer gives you linear acceleration
the rotational gyro gives you angular velocity
integrate the rotational gyro over time to give you angular position
integrate the accelerometer over time to give you linear velocity
double integrate the accelerometer over time to give you linear position

Of course, integrations like this introduce errors, so that is why people typically combine estimates from many different sensors (and sensing modalities) with something like a Kalman Filter.  
Also note that these integrations don't work anymore if you max out the sensing range of your sensors.  For example, some cheap accelerometers won't measure over 3gs.  And I imagine that swinging a bat and hitting a ball will produce some pretty high gs.  And a low resolution (bit count) will also severely affect the accuracy.

