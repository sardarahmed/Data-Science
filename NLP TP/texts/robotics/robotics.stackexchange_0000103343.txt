Q:

Require Help Deriving correct formula to calculate object distance

I am trying to create a python scripted node which calculates object distance based on what is detected from an object detection library I'm utilizing. The node is subscribed to the /camera/color/image_raw which it obtains the color image. This data is fed to the object detection model and the bounding box information is obtained. The location of the bounding box center is calculated using formula:
Center_x = x + (width / 2)
Center_y = y + (height / 2)

where:

    (x, y) are the coordinates of the top-left corner of the bounding box.
    width is the width of the bounding box.
    height is the height of the bounding box.

This coordinate is converted to it's corresponding location in the depth image (The node is also subscribed to the camera\depth\image_raw topic).
This is the conversion formula I used:
scale_factor_x = width_depth / width_color
scale_factor_y = height_depth / height_color

x_depth = int(x_color * scale_factor_x)
y_depth = int(y_color * scale_factor_y)

Here is the code:
#!/usr/bin/python3
import rospy
from rospy.numpy_msg import numpy_msg
import numpy as np
from ultralytics import YOLO
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
import threading
from std_msgs.msg import Header
import cv2
#from yolov3.cfg import *

class camera_detect:
    def __init__(self):
        self.bridge = CvBridge()
        self.model = YOLO('yolov5s.pt')
        self.mutex = threading.Lock()
        self.cv_image = None
        self.result = None
        self.class_names = None
        self.boxes = None
        self.info = None
        self.distance = None
        self.c1_time_stamp = None
        self.c2_time_stamp = None
        self.Center_x = None # x coordinate of bounding box center
        self.Center_y = None # y coordinate of bounding box center
        self.color_image_height = None #Height of opencv color image
        self.color_image_width = None #Width of opencv color image
    def callback1(self,msg):
        image=msg
        self.c1_time_stamp=msg.header.stamp

        with self.mutex:
            print("callback1 gets lock")
            if self.distance is None:
                self.cv_image = self.bridge.imgmsg_to_cv2(image, desired_encoding='passthrough') #convert to opencv format
                self.color_image_height = self.cv_image.shape[0]
                self.color_image_width = self.cv_image.shape[1]
                self.result = self.model(self.cv_image, verbose=True)[0]
                self.class_names = self.result.names
                self.boxes = self.result.boxes.data.cpu().numpy()

                try:
                    for i in range(len(self.boxes)):
                        print("NUMBER: ",i)
                        class_index = int(self.boxes[i][5])
                        class_name = self.class_names[class_index]
                        print("CLASS_NAME: ",str(class_name) )
                        if  str(class_name) == "fire hydrant" or str(class_name) == "chair" or str(class_name) == "laptop":
                            self.info = self.boxes[i][0:4]
                            self.Center_x = self.info[0] + (self.info[2] / 2)
                            self.Center_y = self.info[1] + (self.info[3] / 2)
                        else:
                            self.info = None

                except IndexError:
                    pass
            print("callback1 releases lock")

    def callback2(self, msg):
        depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough') #convert to opencv format
        self.c2_time_stamp = msg.header.stamp

        #SCALE FACTOR RELATES COLOR IMAGE AND DEPTH IMAGE
        scale_factor_x = depth_image.shape[1] /  self.color_image_width
        scale_factor_y = depth_image.shape[0]  /self.color_image_height
        with self.mutex:
            print("callback2 gets lock")
            if self.info is not None:
                #RELATE THE LOCATION OF PIXEL OF CENTER OF BOUNDING BOX TO PIXEL LOCATION IN DEPTH IMAGE
                x_depth = int(self.Center_x * scale_factor_x)
                y_depth = int(self.Center_y  * scale_factor_y)
                print("X_DEPTH: ",x_depth,"Y_DEPTH: ",y_depth)
                self.distance = depth_image[x_depth][y_depth]
                print("DISTANCE: ", self.distance)

                time1 = rospy.Time(self.c1_time_stamp.secs,  self.c1_time_stamp.nsecs)
                time2 = rospy.Time(self.c2_time_stamp.secs,  self.c2_time_stamp.nsecs)
                # Calculate the time difference in seconds
                #time_diff = (time2 - time1).to_sec()
                #print("TIME_DIFF: ",time_diff)
                self.distance = None
            print("callback2 releases lock")
    def detect(self):
        rospy.Subscriber("/camera/color/image_raw", Image, self.callback1, queue_size=1, buff_size=2_000_000)

    def detect_depth(self):
        rospy.Subscriber("/camera/depth/image_raw", Image, self.callback2, queue_size=1, buff_size=2_000_000)

if __name__ == "__main__":
    try:
        rospy.init_node("test_node")
        tester = camera_detect()
        tester.detect()
        tester.detect_depth()

        rospy.spin()

    except rospy.ROSInterruptException:
        pass

I get this error:
0: 480x640 1 fire hydrant, 28.6ms
Speed: 4.0ms preprocess, 28.6ms inference, 9.8ms postprocess per image at shape (1, 3, 640, 640)
NUMBER:  0
CLASS_NAME:  fire hydrant
callback1 releases lock
callback2 gets lock
X_DEPTH:  1203 Y_DEPTH:  182
[ERROR] [1686621381.764477, 910.003000]: bad callback: <bound method camera_detect.callback2 of <__main__.camera_detect object at 0x7f4a82a332b0>>
Traceback (most recent call last):
  File "/opt/ros/noetic/lib/python3/dist-packages/rospy/topics.py", line 750, in _invoke_callback
    cb(msg)
  File "/home/philip/tests_ws/src/ml_test/src/camera_test.py", line 76, in callback2
    self.distance = depth_image[x_depth][y_depth]
IndexError: index 1203 is out of bounds for axis 0 with size 720

It would seem I'm not using the right formula to get what I want. I would be grateful for any help as to what I'm doing wrong.

Originally posted by distro on ROS Answers with karma: 167 on 2023-06-12
Post score: 0

A:

When accessing pixel values in an image in OpenCV, the convention is image[row][col] or image[y][x]. Currently it is [x][y] and that may be why you are getting the error (since you are accessing non-existent pixels).

Originally posted by sohai with karma: 16 on 2023-06-13
This answer was ACCEPTED on the original site
Post score: 0

