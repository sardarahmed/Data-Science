Q:

How to get real-world width & height of Kinect video patch?

Hello,
I am trying to compute the real-life size (width and height in meters) of a face patch that I have detected using a Kinect and OpenCV's Haar detector.  I know the pixel dimensions of the patch and I know the distance to the points in the patch.  My guess on how to get the approximate real-life dimensions of the patch is to simply multiply the average distance to the patch by the arc lengths subtended by the width and height of the patch.  To get the arc lengths in radians, I use the size of the FOV of the Kinect which is around 57.8 degrees for the IR image and 62.7 degrees for the RGB image (http://www.ros.org/wiki/kinect_calibration/technical).
Is this the best way to do this, or is there a way I can use the calibration data from the Kinect's camera_info topic to do the same thing more directly?
Thanks!
patrick
EDIT: I am using Python which limits my use of PCL for this task.

Originally posted by Pi Robot on ROS Answers with karma: 4046 on 2011-05-30
Post score: 3

A:

If I understood the question correctly, then there's a much cleaner solution:
The openni_camera driver outputs the data in two formats - as an image, and as a PointCloud. The point cloud is structured like an image - it's a 640x480 array, and each item in the array has RGB color as well as (x, y, z) coordinates. You can perform your detection on the image, and then look up the corresponding pixels in the PointCloud. The points in the pointcloud have the real-world values for (x, y, z) in meters, so you can get the size from there, without going through trigonometric computations.

Originally posted by Ivan Dryanovski with karma: 4954 on 2011-05-30
This answer was ACCEPTED on the original site
Post score: 5

Original comments
Comment by Pi Robot on 2011-05-30:
And a followup question: I am using /camera/depth/image to get my distance values for an x-y point in /camera/rgb/image_color.  Do you happen to know if these two images are registered?
Comment by Pi Robot on 2011-05-30:
Thanks Ivan.  I'm using Python for my ROS node and so I'm not sure I have access to the necessary PCL structures to do it this way.  For example, after subscribing to /camera/rgb/points and setting up a callback, how would I extract the z coordinate from a point based on its x-y coordinates in the image plane?

