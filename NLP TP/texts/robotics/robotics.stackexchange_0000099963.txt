Q:

how can i check bottle neck in my code while node is running?

So i have a node that subscribes pointcloud2 msgs which generated from moving line scanner. (about 200hz publish rate)
I tried to concatenate(add) pointcloud every subscribe callback but it seems very slow.
about 20hz, i tested by publish back from callback function which could make little slow yet 20hz seems too slow.
(i used ros::spin.)
There is definitely bottle neck in my code. Is there anyway i can check the code bottle neck while ros node is running?
Only idea i have is to print curret time every line that matters in the code, but this seem very tedious.
so if there is any solution it would be great! any idea is also  welcome :)
thx.
more general info about what i am trying to do
each pointcloud has 800 point (xyz)
pointcloud data will be added and when node is finished it will save total point cloud.

Originally posted by benthebear93 on ROS Answers with karma: 17 on 2021-08-27
Post score: 0

A:

Finding bottlenecks in code is called Profiling and is interesting in many fields. There are many tools to do it, but none which work fairly automatically - they all require some fiddling with, so they are not necessarily easier to do than printing current time and working backward, but they likely will tell you more. Perhaps you can use http://wiki.ros.org/roslaunch/Tutorials/Profiling%20roslaunch%20nodes as a start, and continue to search for tutorials on how to use tools like gprof to make your code high performant.
That said, accumulating 800 3D points into an (ever growing) storage 200 times per second sounds like a very compute heavy process. In particular, arrays can typically not be resized in any performant way. If you think you resize an array, it is more likely that you allocate another array of the new size and copy all data from the latest iteration into there. Copying data, by the way, is a very expensive process as well. I don't think you should expect to get all 200 scans accumulated every second.
So, what can be done in this situation? Think about your problem for a moment - what are you trying to do? Do you actually need 800 points in every scan? Perhaps some filtering can be done to reduce that number? Do you need 200 scans per second, or could you make a sufficiently good image with 100 or 50 scans? What about the accumulation - could you pre-allocate the memory that you need so that you don't have to resize arrays when live? Can this process be parallelized? Is ROS the right network of choice here, or can you get a faster connection by editing the source code to the driver? There are many avenues to explore, and I hope you find a good solution for your problem.

Originally posted by Per Edwardsson with karma: 501 on 2021-08-27
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by benthebear93 on 2021-08-28:
Thx a lot! I will look into the link that u gave me and also try to look into the different method to save computational expense.

