Q:

Is RTAB-Map SLAM Possible with My Robot's Current Configuration?

Hello,
I am currently trying to accomplish autonomous navigation with a simple four-wheeled differential drive robot by building a static 2D binary occupancy map using the RTAB-Map SLAM package and having it navigate from some initial pose to a goal pose in that pre-saved map. The robot possesses a Raspberry Pi 4 that interfaces with both an Intel Realsense D435 RGB-D Camera and 360-degree LIDAR sensor for mapping and odometry purposes. The robot, however, does not possess wheel encoders that would also contribute to odometry measurements, but to my understanding, it may still be possible to accomplish my goal without them. At this point, though, I am having trouble finding a clear solution to achieving this. If anyone could point me in the direction of an article or paper that describes this type of problem and a solution, I would truly appreciate it. Both the Raspberry Pi 4 and the remote laptop (Dell G5 15) interfacing with the robot are operating on Ubuntu 20.04 with ROS noetic.

Originally posted by Devin1126 on ROS Answers with karma: 7 on 2022-12-29
Post score: 0

Original comments
Comment by gvdhoorn on 2023-01-02:
Unfortunately this appears to be a duplicate of #q410850.

A:

I think RTABMap can generate visual odometry from camera instead of /odom from wheels, it's right in the tutorial page:

http://wiki.ros.org/rtabmap_ros/Tutorials/SetupOnYourRobot#Kinect

Originally posted by martinerk0 with karma: 36 on 2022-12-30
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by Devin1126 on 2022-12-30:
Thank you! I will look through this article to hopefully gain a better understanding.

