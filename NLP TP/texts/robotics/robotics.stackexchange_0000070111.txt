Q:

Using Robot localisation without odometry values

I am looking to use the EKF node of the Robot localization package to localize my quadcopter but I do not have a odometry sensor on my robot. I have the following - Pose values obtained from visual odomtery and another set of pose values from Hector SLAM.
Is it that the process model of the package is based on the odomtery values and wont work without them.
The diagnostics topic say that no event has been recorded. Can I do something like pusblishing these pose messages as nav_odometry messgages?
Can I get some more clarity on using this package?
EDIT:
In response to Tom's answer :- I kind of recognized the mistake a while ago. I have made the following changes - I no longer use Hector slam values. I am using the visual odometry as the odom message and imu data on my robot as well. The following is my latest launch file
<launch>

    <node pkg="robot_localization" type="ekf_localization_node" name="ekf_localization" clear_params="true">

      <param name="frequency" value="10"/>

      <param name="sensor_timeout" value="0.1"/>

      <param name="two_d_mode" value="false"/>

      <param name="odom_frame" value="vo"/>

      <param name="base_link_frame" value="imu_f"/>
   
      <param name="world_frame" value="vo"/>
      
      <param name="transform_time_offset" value="0.0"/>

      <param name = "odom0" value = "/vo"/>
      <rosparam param="odom0_config">[true,  true,  true,
                                      true, true, true,
                                      false, false, false,
                                      false, false, false,
                                      false, false, false]</rosparam>

      <param name = "imu0" value = "/imu_data_frames"/>
      <rosparam param="imu0_config">[false,  false,  false,
                                      true, true, true,
                                      false, false, false,
                                      true, true, true,
                                     true, true, true]</rosparam>

      <param name="odom0_differential" value="false"/>
      <param name="imu0_differential" value="false"/>

      <param name="odom0_relative" value="false"/>
      <param name="imu0_relative" value="false"/>

      <param name="print_diagnostics" value="true"/>

I am publishing the visual odometry(pose from the AR marker) on the odom frame and the imu data(orient, ang vel, lin acc) on the imu topic. With regards to the frames - I have removed the map frame since I dont have one. Since my goal is trying to estimate the pose of the AR marker with respect to the camera I want the imu values in the camera frame as well and hence  I publish a static transform from imu_f(imu frame) to vo(camera frame) as follows
<node pkg ="tf" type="static_transform_publisher" name="my_broadcast" args="0.44 0 0.22 0 0 1.57 imu_f vo 100" />

I am getting values on /odometry/filtered but with the above configuration, the covariance on the pose just explodes. Is it because the package itself provides a tranform from odom to base_link and with me providing the opposite transform, it just messes up. Any suggestions on how I can set it right?

Originally posted by nagsaver on ROS Answers with karma: 13 on 2015-10-28
Post score: 0

A:

No, the node doesn't care what the data source is, as long as it's in one of the accepted ROS messages and conforms to REP-103 and REP-105.
The topic name can be whatever you want it to be. Just set the <param name = "pose0" value = "/my_pose"/> parameter to whatever the topic name is.
Looking at your pose data, the first thing that jumps out at me is that its pose is given in the /head/camera frame, which is the base_link_frame for your robot. Pose data should not be reported in the base_link_frame (or a child frame of that frame). It should be in the world_frame or a frame that is a child of that frame (other than the base_link_frame). See my ROSCon presentation at around 4:20 or so. I'd change your base_link_frame to base_link, and then create a static transform from map to /head/camera. Also, do you have some other node publishing the odom->base_link transform? If you don't, this setup won't work.
EDIT 1

I publish a static transform from imu_f(imu frame) to vo(camera frame)

First, yes, what you surmised about the transforms must be causing at least some of your problems. robot_localization has two outputs: an odometry message with your current vehicle state, and a transform from your world_frame to your base_link_frame. In your case, your world_frame is vo and your base_link_frame is imu_f, so r_l is going to publish a vo->imu_f transform. Therefore, you have some kind of strange circular relationship in your transform tree, and I have no clue how tf will handle that.
Second, are you fusing the pose of the marker with your robot's IMU, or is some node giving you your robot's pose based on the known marker pose, and you're fusing that value with the IMU?

Originally posted by Tom Moore with karma: 13689 on 2015-11-12
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by nagsaver on 2015-11-12:
Thanks for your reply Tom. please see my edited question and suggest inputs, if any.
Comment by nagsaver on 2015-11-13:
I removed the transform from imu to vo. Now the covariances seem alright.
Comment by nagsaver on 2015-11-13:
Also I understand your point about fusing robot poses and ar marker poses. I was just checking whether the robot localisation works ok. As you rightly pointed out, I need to do an inverse transformation to get the camera poses wrt Marker and then fuse IMU values. Thanks again.

