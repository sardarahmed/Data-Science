Q:

Sharing CUDA pointers between nodes

Looking through all the answers, I see one solution is to use Nodelets to share data easily, but thinking about a more general solution I can see a number of ways of doing it, so I'm wondering if any of these exist and/or are advisable:

Pretend the CUDA memory pointer is just a value and cast it at either end.

This falls over if the message gets published to a different device, although I could add something like a Publisher device ID to detect this, for instance.

(or 1.5) Limit message propagation to the same device.

Can ROS actually do this?

Write a smart Publish/Subscribe routine that will transparently copy the GpuMat to a standard Mat if it detects the target is a different device.

Has someone tried this? It seems like the best solution, but quite a lot of effort.

Some other technique I am not aware of

Any hints towards the best course of action are most welcome.

Originally posted by KenYN on ROS Answers with karma: 541 on 2016-01-18
Post score: 1

A:

This StackOverflow post seems to indicate that it isn't possible to share CUDA pointers between processes.
Since nodes are different processes, I don't think it's possible to share CUDA pointers across nodes.
You might be able to share CUDA pointers between nodelets in the same process, but even then, you'd have to share not just the pointer, but the entire CUDA context, and that seems like it will be somewhere between awkward and intractable.

Originally posted by ahendrix with karma: 47576 on 2016-01-19
This answer was ACCEPTED on the original site
Post score: 1

