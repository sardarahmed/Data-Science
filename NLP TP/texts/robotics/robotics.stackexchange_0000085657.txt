Q:

SLAM localizing methods based on camera?

Are there any SLAM methods that can create a map from the camera output based on colors in ROS?
Im working on a project where I can only get an absolute position by using lines that are drawn on the floor, just like a football field.
Most SLAM methods Ive seen like this one: https://vision.in.tum.de/research/vslam/lsdslam rely a lot on depth-perception.
I am just wondering which slam methods can detect (big & long) lines on the floor. I cant rely on walls or objects being detected mostly because the robot sometimes has to navigate in huge halls where the walls are really far away.

Originally posted by HaroldVD on ROS Answers with karma: 13 on 2018-03-05
Post score: 0

A:

You are not able to apply Gmapping directly for this application because it does not give a promising result when enough features are not available in the sensor field of view. RGB-D SLAM also will not work as you have repetitive patterns on your RGB images.
I think your problem seems easy than general SLAM problem. You can extract those line segments using a line detector from RGB image. Then use ICP algorithm to align those frames.
If you need a more robust result, you can use the same method with  Rao-Blackwellized particle filter that is used in Gmapping. But you need an accurate data association strategy to work with RBPF.

Originally posted by Gayan Brahmanage with karma: 929 on 2018-03-05
This answer was ACCEPTED on the original site
Post score: 1

