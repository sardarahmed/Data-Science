Q:

How can I improve ZED Camera precision?

I'm using Stereolabs ZED camera for my computer vision project. I did a small research about several sensors on the market and ultimately we decided to go with the ZED Camera. 
However I'm finding that the precision of the camera isn't that great. And the Point Cloud takes too much storage space. Anyone found the same problems? And if so, how did you managed them?

A:

I don't know what you mean by "precision" and how do you measure it. The sensing 
accuracy will probably go back to the camera calibration precision and the stereo matching algorithm used. If they ship the device "calibrated" then no one knows what happened after the camera was calibrated in factory and before you got it (mechanical shock, temperature swings) - so you better re-calibrate it yourself (with OpenCV, Matlab etc.).
If you are interested in the depth accuracy from stereo vision itself then see the following equation:
dz = (z^2 * de) / (f * b)
where dz is the depth error in meters, z is the depth in meters, de is the disparity error in pixels, f is the focal length of the camera in pixels and b is the camera baseline in meters. The main message of the equation above is that the depth error grows with the square of depth (distance from camera) itself.
You get better depth accuracy the bigger f and b are. Given the ZED camera has both of these relatively small - baseline is "just" 120mm and f will be pretty small given the quite large FOV of 110 degrees in diagonal (f is "FOV inverted", so wider FOV gives smaller f). What is good for you is the high resolution which should mean smaller disparity error which could compensate for the bad f and b values.
Regarding point cloud size - this goes back to the rather high sensor resolution of the ZED camera. High resolution may not really be needed for stereo because 1) the stereo matching takes long time 2) the point cloud is huge 3) the depth accuracy may not be much better since the disparity is usually determined with sub-pixel precision anyways. So see what angular resolution you need for your project - you can calculate how many pixels per angle (horizontal, vertical) your camera (=sensor+lens) has. If that is too much, you can lower the angular resolution (=lower sensor resolution) without harming your computer vision results.
Hope this helps!

