Q:

Prosilica Stereo Calibration

As an introduction, I am working as part of a team with a few other students to integrate a pair of stereo cameras onto a robot as part of a course project.
We are using a modified version of the Prosilica drivers for each of our cameras.  During individual camera calibration we are able to calibrate the cameras quite well.  The cameras we are using Prosilica GC750C cameras.
However whenever we try to calibrate the two cameras in stereo our 'rectified' images end up being highly zoomed in.  We have tried using two different calibration boards including board with 22.5 mm squares and a second board with 93 mm squares.  Due to the position of our cameras during stereo calibration we are only able to calibrate about ~60% of the camera space on each camera.
When attempting to "scale" the calibration the "scale" feature only seems to pan across the image rather than scale the viewable area as expected from the tutorial.
A final note is that after stereo calibration, the "epi" value simply reads a "?" rather than a value.
I am curious if anyone has any recommendations on how we might solve this calibration oddity or that might have an idea of where we might look for a solution?
Please let me know if any other information would be helpful for finding a solution.

A few other notes that might assist with finding the solution.  Our original purpose in pursuing this project was to launch rviz through vslam in order to produce a point cloud map.  With our current calibration, we have been unable to produce output through vslam and rviz.  Our rxgraph, (which I will try to provide a link for later today) shows proper connections for rviz and vslam however as mentioned no outputs occur.
Similarly we have also tried constructing a stereo_view out put through the stereo_image_proc node without getting any visual output from stereo_view.  This lack of output includes the left and right rectified video.  As a debug we tried to see if we could hook into the stereo_image_proc output via single image_viewers in order to determine if the stereo_image_proc was outputting any valid images.  We found that both left and right rectified images were viewable this way however using the disparity_viewer did not allow for an disparity output using this method either.

Originally posted by cnmorse on ROS Answers with karma: 1 on 2011-05-03
Post score: 0

A:

vslam is experimental research code. It is not actively being supported, and should be used at your own risk, but patches are welcome.
If you would like a robust method of localization and mapping with a stereo camera or kinect, use the 2D slam_gmapping stack. See the pointcloud_to_laserscan package from the turtlebot stack and the SLAM Gmapping with Kinect Tutorial for the turtlebot.

Originally posted by Helen with karma: 261 on 2011-09-02
This answer was ACCEPTED on the original site
Post score: 0

