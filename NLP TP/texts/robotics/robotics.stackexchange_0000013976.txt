Q:

How would i implement position and heading readings into my SLAM system?

I am trying to build a low-cost SLAM system with an MPU-6050 and GY-271 (magnetometer). Currently, i have a robot with an Arduino that collects the sensor data and a Raspberry Pi that (hopefully) will do the SLAM calculations. 
I want my robot to be able to use all three sensor readings in SLAM to create a 2D map of the environment. However, considering that i want a 2D map, i will not need all the axis readings correct?
I read another post on here where one of the answers said that only the yaw from the gyroscope, and the x and y from the accelerometer would be needed.

My question is, how would i implement this into my SLAM robot? I was thinking of passing the accelerometer and odometry readings through a kalman filter on the Arduino and then the same for the gyro and magnetometer readings. Would that be correct?
Would i also need to use all the axis (x, y, and z) readings from the magnetometer? Or just one or two axis?

Thanks.

A:

Based on your comments thread, I think what you want is a Kalman filter. I think this ahrs implementation will be helpful for you. If you search "mpu6050 ahrs" you'll also find a dozen or so other implementations to look through. If you want you can modify it so that it explicitly sets the Z coordinate to zero, but it should actually figure that out automatically. 
To map the room (and do SLAM), you will need a sensor which can tell you how far away the walls are. Sonor tends to be a good low-cost entry point, though it has plenty of implementation difficulties.

