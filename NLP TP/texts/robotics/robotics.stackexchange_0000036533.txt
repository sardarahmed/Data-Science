Q:

dynamic-laser-map-octomap-ros

Hi everybody
What do I have?
1.-I have a laser running under ROS, with the use of "rosrun hokuyo_node hokuyo_node" I can get the stream data.
2.-I have a tf node that can transform and broadcast  /laser (which is the laser frame)  to /base_link (which is in a fake center of the robot) frames respectively, tf_broadcaster.cpp
3.-I have a node that can transform laser scans to pointcloud2 and then it publishes the topic cl.
4.- I run the command "roslaunch octomap_server octomap_mapping.launch" then in RVIZ I can see the  voxels-map. But the voxels are not in 3D, they have 2D shape. Moreover, when I move the laser it does not really build the octree map, instead, it fills all over the map with 2D voxels.
What I want?
1.- I want to build dynamically the octree-map and visualize the process in RVIZ. I mean, I want to fuse the individual octree-maps that correspond to a single laser reading  and build up the octree map, and I want to see that process on RVIZ or in octavis.
2.-How can I do that? Is that possible in octomap-ros? Do you have some code?
In advance thank you.

Originally posted by acp on ROS Answers with karma: 556 on 2011-12-15
Post score: 0

A:

I don't know octomap-server, but I guess it's a 3D SLAM algorithm, right? If so, what you still need is some odometry information which you can obtain by using laser_scan_matcher. Otherwise ROS won't know the laser is moving. This will provide a /odom -> /base_link transform, ie. will estimate 2D odometry for your laser sensor.

2.-I have a tf node that can transform and broadcast /laser to /base_link
frames respectively.

Please describe (in your original post) what is the source of this transform -> the rest of the answer depends on this.
EDIT: If you haven't yet, then I first suggest you read REP 105 to understand what tf's are, what are they for and how to best use them. Then, I'd suggest to start off by running laser_scan_matcher to obtain an odometry source - you will be able to see your laser scanner moving around in 2D in rviz. Then maybe try it together with gmapping to obtain 2D maps of your surroundings. You should already know what more you might be missing to obtain 3D voxel grid maps by then.
This will help you with your question, I'm sure. I'm sorry I cannot give you an exact answer for your needs, I don't know octomap-server package.

Originally posted by tom with karma: 1079 on 2011-12-15
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by acp on 2011-12-16:
Hi Tom, thank you for your answer, well, I dont know much octomap-server either,  but well hope I can find a solution, I will read what you suggested.  I can already obtain and fused 3D laser voxels in octomap-ros. My problem now is to see the fusion process dynamically. I mean to see the map building in real while sacnning the environment either in octavis or rviz.
Comment by acp on 2011-12-15:
It is just a static transform publisher
Comment by tom on 2011-12-15:
By source of transform I meant if you're using an IMU to do that (in case of a moving head of a robot, or simply hand-held laser) or just a static transform publisher. Which one is it?
Comment by acp on 2011-12-15:
My idea is to build up a laser octree map using octomap-ros and then a vision octree map using also octomap-ros, then I want to take the fused laser+vision coordinates to localize the robot.
Comment by acp on 2011-12-15:
Hi Tom, I have edited it, well I never thought about SLAM :), I think octomap uses pure Bayes integration formula to update and build up the octree map.  Well, my idea was to define a   "Pointcloud v" then define an origin  "point3d origin (0, 0, 0)" then populate    "point3d  punto(cl.points[i].x, cl.points[i].y,cl.points[i]);" and then  "v.push_back(punto)" and after that somehow visualize it in RVIZ. Well, I am not sure if this will work in octomap-ros. As you can see I am lost :)

