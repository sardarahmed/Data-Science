Q:

Localization with Triangulation (pozyx)

I'm trying to use [Pozyx hardware] (http://pozyx.io) to localize my robot in a map.
With the use of a EKF_localization_node I want to fuse AMCL and Pozyx data and localize the car. This to make sure that even when AMCL does not have any reference points to localize (in a open space without walls) I still know where my car is moving.
However, the orientation of the X- and Y-axis are translated and rotated compared with each other.
Is there a possibilty to use the robot_localization package without initial calibration from my side? I feel like there is a huge error to be obtained when trying to figure out the translation and rotation with physical measurements.
Hopefully my question is clear!
Kind regards,
Mitch

Originally posted by seth on ROS Answers with karma: 1 on 2019-07-02
Post score: 0

A:

Please include input messages from all sensor inputs, as well as your EKF config.
In the meantime, however, I can tell you that your are trying to fuse pose data from two different coordinate frames. Unless you tell the EKF how those frames are related (i.e., by publishing a transform), it's not going to know how to fuse them properly.

Originally posted by Tom Moore with karma: 13689 on 2019-07-03
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by seth on 2019-07-03:
Yes that is exactly what I thought. I know that if the frames are only translated you can take the speed from one instead of overall location and just take it as a relative source. However, how would you tackle this problem when the two frames are also rotated? Just try to measure the rotation angle as precise as possible with some sort of calibration?
Comment by Tom Moore on 2019-08-22:
If you turn on differential mode for the less accurate sensor, it will convert its pose data to velocity in the robot's base_link frame.

