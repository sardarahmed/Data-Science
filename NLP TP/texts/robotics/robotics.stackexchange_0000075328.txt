Q:

How is odometry used in gmapping?

Hello,
I working on gmapping to map a huge area. I have basic knowledge of ROS i.e how to publish,subscribe,writing launch files. As i have to map a huge area i don't want to drive the robot manually, so i wrote a simple obstacle avoidance code to move around the space without hitting anything. And when i robot moves i save the laserscan data and tf data into a bag file. and ofter than i follow this tutorial to make a map. As a trail run, i just made the robot to go around a small cubical (rectangle in space)and mapped the environment offline. You can see the output below:

As you can see the map is REALLY REALLY bad :( .
I did some research and played with gmapping parameters, i was able to improve the mapping a little bit. Output after changes gmapping parameters:

As you can see it improve a little bit. :) . But i am not satisfied with the result. I want to make it more perfect, so i kept on reading tutorials and watching videos on gmapping but most of the information doesn't make any sense to me especially on tf frames. I have following question:

when i record data into a bag file i just record laserscan and tf. So, how is odom data is considered in mapping the environment?

Is there any other high level way (rather than play with gmapping parameters) to improve gmapping?

whenever i collect data from my robot i go around with my robot and i can see that sometimes it bumps into things and make sudden movements. i think these movements effect the quality of data. Is there anyway i can make my robot go smoother?

And damn what doe this means map -> odom -> base_link . I know it's a transformation from one frame to another frame, like in low level how is map frame different from odom and base_link and which frame is used in gmapping?

Can someone please throw some light on these questions?
P.S: why understanding about odom and base_link is obom drifts over time, but base_link isn't. Please correct me if i am wrong.
Thanks.

Originally posted by krishna43 on ROS Answers with karma: 63 on 2016-07-20
Post score: 1

Original comments
Comment by pallavbakshi on 2017-01-16:
Hi Krishna,
Your questions are really appropriate. I have just started making something similar to turtle bot's autonomous navigation system. However, I don't have odometry data. Is there any way I can still build the car using gmapping alone?

A:

odom is used when ROS is calculating the TF transform for your laserscan data however to make it work properly you need to setup your TF frame. http://wiki.ros.org/tf/Tutorials

Originally posted by metRo_ with karma: 58 on 2016-07-20
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by krishna43 on 2016-07-20:
Aren't TF frame already setup in a turtlebot? I am using off-the-shelf turtlebot.
Comment by metRo_ on 2016-07-20:
And did you set up a tf frame for your laser?
Comment by krishna43 on 2016-07-20:
I think i did, because whenever i run:
  rosrun tf view_frames 

in the generated pdf i can see a link between laser_link and base_footprint
Comment by metRo_ on 2016-07-21:
Can you share the code where you are publish the laserscan?
Comment by krishna43 on 2016-07-21:
I am not publishing the laserscan. I have a kinect with me, i getting data off the kinect, so i am subscribing to /scan topic.

