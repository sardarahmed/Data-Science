Q:

2D SLAM with gmapping and openni_kinect

I know it's possible to do 2D SLAM with Kinect using slam_gmapping, eg. because of this post. Could anyone please tell me how exactly to do that?
I've already installed pointcloud_to_laserscan, slam_gmapping, turtlebot and turtlebot_apps. But after running roslaunch turtlebot_navigation gmapping_demo.launch all I'm getting is an info saying: "Still waiting on map". What and in which order should I execute to obtain a map like in turtlebot_navigation's tutorial?

Ok, I think I partially got it. There were some errors in the default pointcloud_to_laserscan launchfile. My working version below.
<launch>
  <!-- kinect and frame ids -->
  <include file="$(find openni_camera)/launch/openni_node.launch"/>

  <!-- Kinect -->
  <node pkg="nodelet" type="nodelet" name="openni_manager" output="screen" respawn="true" args="manager"/>

  <!-- fake laser -->
  <node pkg="nodelet" type="nodelet" name="kinect_laser" args="load pointcloud_to_laserscan/CloudToScan openni_camera">
    <param name="output_frame_id" value="/openni_depth_frame"/>
    <remap from="cloud" to="cloud_throttled"/>
  </node>

  <!-- throttling -->
  <node pkg="nodelet" type="nodelet" name="pointcloud_throttle" args="load pointcloud_to_laserscan/CloudThrottle openni_camera">
    <param name="max_rate" value="2"/>
    <remap from="cloud_in" to="/camera/depth/points"/>
    <remap from="cloud_out" to="cloud_throttled"/>
  </node>
</launch>

When I now run rosrun gmapping slam_gmapping I get a warning saying:
[ WARN] [1300374330.893690231]: MessageFilter [target=/odom ]: Dropped 100.00% of messages so far. Please turn the [ros.gmapping.message_notifier] rosconsole logger to DEBUG for more information.
[DEBUG] [1300374332.317853661]: MessageFilter [target=/odom ]: Removed oldest message because buffer is full, count now 5 (frame_id=/kinect_depth_frame, stamp=1300374331.992896)
[DEBUG] [1300374332.318014019]: MessageFilter [target=/odom ]: Added message in frame /kinect_depth_frame at time 1300374332.311, count now 5
[DEBUG] [1300374332.376768593]: MessageFilter [target=/odom ]: Removed oldest message because buffer is full, count now 5 (frame_id=/kinect_depth_frame, stamp=1300374332.060879)

I think the problem might be there is no tf tree between /openni_camera and /map defined - how do I achieve this?
Any help appreciated, Tom.

Originally posted by tom on ROS Answers with karma: 1079 on 2011-03-16
Post score: 2

A:

Hi Tom,
This does not answer your gmapping question, but the launch file you posted above does not work for me.  It runs without error but it does not produce a "/scan" topic for the fake laser scan.  In other words, run your launch file, then in a separate terminal run the command "rostopic list | grep scan".  It should return "/scan" but in my case it returns nothing.
The following modified version of your launch file does work for me:
<launch>
  <!-- kinect and frame ids -->
  <include file="$(find openni_camera)/launch/openni_node.launch"/>

  <!-- openni manager -->
  <node pkg="nodelet" type="nodelet" name="openni_manager" output="screen" respawn="true" args="manager"/>

  <!-- throttling -->
  <node pkg="nodelet" type="nodelet" name="pointcloud_throttle" args="load pointcloud_to_laserscan/CloudThrottle openni_manager">
    <param name="max_rate" value="2"/>
    <remap from="cloud_in" to="/camera/depth/points"/>
    <remap from="cloud_out" to="cloud_throttled"/>
  </node>

  <!-- fake laser -->
  <node pkg="nodelet" type="nodelet" name="kinect_laser" args="load pointcloud_to_laserscan/CloudToScan openni_manager">
    <param name="output_frame_id" value="/openni_depth_frame"/>
    <remap from="cloud" to="cloud_throttled"/>
  </node>
</launch>

The important difference is that the two nodelets now wait on openni_manager rather than openni_camera.
Using this launch file, I can add a Laser Scan display in RViz and select the "scan" topic and see the scan points.
Regarding your gmapping question, you don't mention what kind of robot you are using.  Is it an iRobot Create?  If so, are you using an IMU with it?  Also, have you run through all the Navigation tutorials starting here: http://www.ros.org/wiki/navigation/Tutorials?
--patrick

Originally posted by Pi Robot with karma: 4046 on 2011-03-17
This answer was ACCEPTED on the original site
Post score: 4

Original comments
Comment by tom on 2011-03-20:
I'd like to use SLAM to navigate a quadrotor UAV in an indoor env and create a floor plan. I'd like to do it with an IMU and a Kinect. However an IMU on a VTOL w/o ext aiding drifts in yaw direction. So I guess a scan matcher must be used to provide yaw correction. Do I stand a chance / any hints?
Comment by Pi Robot on 2011-03-18:
Yeah, the navigation stuff has a lot of parts but is very nicely laid out in the tutorials.   Then, to build a simple robot to do all the cool gmapping stuff, you could use an iRobot Create or something home grown based on the ArbotiX or Serializer controllers, to name a couple.
Comment by tom on 2011-03-18:
Ok, I'll go through the tutorial above, probably everything becomes clear then. Thanks all.
Comment by fergs on 2011-03-18:
Just a Kinect is not enough -- gmapping requires an odometry tf transformation. You might look at using the canonical_scan_matcher to estimate an odometry transformation -- although I somewhat doubt that the Kinect data will work with it (due to the lack of features, because of the narrow fov).
Comment by tom on 2011-03-17:
Thanks Patrick. I'm not using any robot, I just have a Kinect sensor. Is it not enough to create a map of a non-changing environment? For the beginning it would suffice to obtain a map by just rotating the sensor in the yaw axis assuming no pitch or roll or translation. Is it not possible?

