Q:

ardrone2.0s coordinate system

Hy community!
I am writing my thesis at the university about Localization and navigation of ARDrone 2.0. I have read all of the available topics and documentations for the ros support of ardrone, but i have a problem which i could not solve yet.
I know, that i can get the position data from ardrone's /ardrone/odometry topic. And i know that too, that if i get an msg object on that topic, the position data is in the msg->pose.pose.position field!
But can somebody explain to me HOW THIS POSITION DATA IS DETERMINED??? How does the drone's coordinate system works? HOw can i get this coordinate system?
This is important to me, because i have an indoor localization system, and with the help of it i plan the start and end point of the path. But thanks to the turbulance and the noise of the drone, the provided data of the localization system is very noisy during the "travelling".
So i figured out that i have to transform the indoor localization data (start coordinate, end coordinate, orientation) into the drone's coordinate system. But this is not clear to me how this inner coordinate system works. And i could not find any info about it either ... yet.
So i hope you could help me! This is very important, because it is the last step of my work to finish it! My mathematic model is perfect, and i coded it properly. But the  perception of "did the drone reached the destination" doesn't perfect.
I'm using Indigo Igloo in Ubuntu 14.04 virtual machine! And ardrone_autonomy as well.
Thank you in advance! Yours,
Steve

Update:
Thank you for answering this fast lads! I appreciate it!
So is there any way to "visualize" / draw up any kind of coordinate system to my calculations? I would like to do some kind of "coordinate transformation" on my own in order to get the destination coordinate in the Drone's coordinate system.
The aim of this calculation is to supervise the drone's travelling to the destination point: if the drone not turned enough and started to travel to a wrong direction, i could shut down the process automatically. OR if the drone has arrived to the destination's environment (for example 30 cm distance from that point), i could send a signal to the drone which tells it to STOP, YOU JUST ARRIVED TO YOUR DESTINATION!

Update2
I am so sorry that ARDrone autonomy's documentation is so imperfect. I mean the coordinate frames chapter is only 1 page long... And there is not any concrete documentation of how drone frames is related to each other, how or when odom tf is set up... Why do i have to take the time to figure out such important things like that???
Why can't be just one man or a team who write the documentations RESPONSIBLY? It is very annoying!!!

Originally posted by Steve_RosUsr on ROS Answers with karma: 15 on 2018-01-26
Post score: 1

Original comments
Comment by jayess on 2018-01-26:
@Steve_RosUsr: it's considered bad form to say something like "this is urgent" or to give deadlines so I removed that from your question.
Comment by jayess on 2018-01-27:
@Steve_RosUsr: I deleted your "answer" and moved the text to your question. Please don't use answers to provide more information. This isn't a forum.
Comment by jayess on 2018-02-13:
Many of the projects that are available were made as part of a person's or groups research (such as ardrone_autonomy). The project was then graciously released to the community so that everyone can benefit. We should feel fortunate that we can "stand on others' shoulders" and focus on our ...
Comment by jayess on 2018-02-13:
research and not have to write drivers and other software that isn't directly related to our research/job. Sometimes documentation isn't the best (ardrone_autonomy's is quite good actually), but since this is open source you can... read the source!
Comment by jayess on 2018-02-13:
There's also plenty of books, articles, and documentation (and this site) that explain a lot of ROS (which is what you're having trouble with). ROS has a very large ecosystem and takes a lot of reading (including source code) to understand how everything works. Good luck and keep asking questions!
Comment by gvdhoorn on 2018-02-13:
@jayess: we should be glad we can re-use, but a dump of source code with an implicit "but you can read the source" is obviously not very helpful. The ardrone pkgs are not like that, but I can understand the frustration of the OP.
In this case, I believe the authors expect (whether that is ..
Comment by gvdhoorn on 2018-02-13:
.. ok or not, I don't know) a certain level of understanding from their users, and they show a TF tree + add a link to REP-103. For someone 'in the know' wrt ROS tf frames (and probably drones), this should be sufficient to understand what is going on.
For newcomers this might not be enough.
Comment by jayess on 2018-02-13:
@gvdhoorn: Agreed. An answer of "read the source" isn't productive nor what I was arguing for. What I was arguing for was instead to remember that many of the packages that we use aren't written by big companies with time/budgets to write extensive documentation. And, that there are many ...
Comment by jayess on 2018-02-13:
approaches to understanding.
Comment by Steve_RosUsr on 2018-02-13:
There's also plenty of books, articles, and documentation (and this site) that explain a lot of ROS (which is what you're having trouble with).
KAPPA :/
Comment by gvdhoorn on 2018-02-13:
Again: I understand your frustration, but package developers cannot keep explaining every piece of ROS they use. That would be infeasible. TF has plenty of tutorials and there are a large nr of questions here on ROS Answers. We have to start to rely on existing/background knowledge at some point.
Comment by Steve_RosUsr on 2018-02-13:
ROS tutorials should think about the real starters (n00bs) for the robotics: they don't have x years of experience of robotics. And as i realize, many of the tutorials are in "intermediate" level: they do not start to explain things in a way real starters would understand such basic concepts...
Comment by Steve_RosUsr on 2018-02-13:
ROS should think about this user group too. If they do that, ROS could become even bigger and bigger
Comment by gvdhoorn on 2018-02-13:
I haven't been involved in this particular question, but perhaps if you can clearly explain what it is that you don't understand, other posters can try and explain it.
I would suggest to open a new question -- clearly link to your old one(s) (this one) -- and clearly explain what you're after.
Comment by gvdhoorn on 2018-02-13:\

ROS tutorials should think about the real starters (n00bs) for the robotics: they don't have x years of experience of robotics

I'm not sure, but I feel that is not the goal of ROS. The goal of ROS is to make creating complex robotics applications easier. Not to make robotics as a whole easier.
Comment by Steve_RosUsr on 2018-02-13:
I clearly explained in my comments and question... i cannot do this better i think. I give my best to this thesis and my jobs! This is all i can do...
Comment by Steve_RosUsr on 2018-02-13:
and just a comment for the open source saga: documentation is PART OF CODING AND EVERY JOB!!! But as i see, many of the programmers give a d*mn about this. But in my opinion you are doing half of a job if you dont do every aspect of it in your best !!!
Comment by gvdhoorn on 2018-02-13:
@Steve_RosUsr: I'm not trying to provide an excuse for any developers that did not write sufficient documentation. I just hypothesised that perhaps the documentation that is there is so 'minimal' is because of the assumption of existing knowledge/experience.
You're right that documenting work is ..
Comment by gvdhoorn on 2018-02-13:
.. part of writing good software.
The (sad) reality is though that 'everyone' is busy and has deadlines (just as you did when you posted this question) and unfortunately documentation tends to take a lower priority then.

A:

The coordinate frames for ardrone_autonomy are given in the documentation and conform to the conventions given in REP-103.
As for how the odometry is calculated, again, from the documentation:

Odometry data

New in version 1.4.

The driver calculates and publishes Odometry data by integrating velocity estimates reported by the drone (which is based on optical flow). The data is published as nav_msgs/Odometry messages to ardrone/odometry topic. The corresponding TF transform is also published as odom -> base transformation.

So, basically the odometry is calculated using dead reckoning. It's noisy because that's just the nature of dead reckoning.

Update:
You can add a tf frame and visualize that in RViz. Please refer to the tf tutorials to learn how to do that.

Originally posted by jayess with karma: 6155 on 2018-01-26
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by Steve_RosUsr on 2018-01-29:
Thank you! :) Just one more question, because it is difficult for me to understand, and i am confused right now: is there already an odom tf frame and base tf frame for the drone? How can i access them directly?
Comment by jayess on 2018-01-29:
If you look at the first link in the answer you'll find the tf tree that the driver creates. You can also examine it by using rqt_tf_tree while the driver is running.
Comment by Steve_RosUsr on 2018-01-30:
So somehow i have to create a tf frame for the indoor localization system, and after that this transformation will be easy.
Comment by jayess on 2018-01-30:
It depends on your setup. We have a VICON system and use the vrpn_client_ros package which can broadcast transformations for you.
Comment by Steve_RosUsr on 2018-01-30:
I use Marvelmind indoor ultrasonic localization system.
Repository link
ROS integration
Comment by jayess on 2018-01-30:
I don't know about that package. Go through the tf tutorials that I linked to and see if you can do it if that package doesn't provide the transformation for you. You can ask another question about that package and maybe someone will know about it.
Comment by Steve_RosUsr on 2018-01-31:
I have just asked them too :) thanks for the help lads!

