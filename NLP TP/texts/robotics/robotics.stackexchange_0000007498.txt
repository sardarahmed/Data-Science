Q:

Measurement and physics model fusion

I am combining two position measurements of a ball from two sensors in real time to obtain one triangulated position in x,y,z coordinates. As the data exchange of the measurements carries some latency, the data has to be extrapolated be able to obtain the current position. Due to extrapolation an error appears in the triangulated data.
I know that when the ball is in the air, the velocity of the ball should be constant in x and y directions and the velocity in the z direction should decay with g. The velocities in x and y however oscillate as function of time around a mean value which is the actual x respectively y velocity. The same goes for when I compute the acceleration in the z direction. It oscillates as function of time around g.
Given that I know how the ball should behave, i.e. that vx and vy should be constant and that the acceleration in the z direction should be z, how can I impose these conditions to better estimate the triangulated position? 

A:

Kalmnan filters are typically used for sensor fusion. You create a model for what you expect the process to look like, use your sensors as inputs, and the output is the filtered estimate. I'm not going to go over implementation in detail as there is plenty of information about these filters available online; I hope this points you in the right direction and if you have a specific question about it then by all means make a new question and I or someone else here can answer it. 
I'm interested in your use of two sensors to triangulate (trilaterate) a ball. How are you using two sensors to fix a 3 dimensional coordinate? 

