Q:

Has hierarchical learning been embodied in a robot before?

I've been reading about hierarchical reinforcement learning (HRL) and it's applications. A well-written literature review on the subject can be found here. However, I was wondering if research has ever been done where an HRL system has been implemented on an individual robot? This paper seems to imply that it has been, by saying that the delivery task that it models "is commonly used in HRL, both in computational and experimental settings". However, my Google Scholar searches haven't turned up any fruit as to what this real-world experimental setting might be. Help would be appreciated for finding either model-based or model-free implementation of hierarchical reinforcement learning in a robot.

A:

HRL has been embodied in a robot in multiple cases.

In a reaching, shelving robot.
In a robot learning how to stand-up.
In robot navigation.

However, how HRL applied in each of these cases varies. The first uses HRL to manipulate Dynamic Movement Primitives, while the second, older method focuses moreso on learning state space values.

