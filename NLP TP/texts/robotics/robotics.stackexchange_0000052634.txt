Q:

gmapping and navigation beyond range of LIDAR sensor

I am trying to use gmapping and the navigation stack to navigate around a large mostly empty room. I have two problems:

When building my map free areas are
only mapped between the robot and
obstacles. This leaves the center of
the room unmapped. Later the
navigation stack tries to navigate
around the completely empty center
of the room. How do I map the empty space where my Lidar returns inf?
I'm worried that while I'm driving through the middle of the
room, because I'm essentially dead
reckoning, errors will propagate and
I will loose a decent position
estimate by amcl. Is my only
solution to get a sensor with more
range?

Cheers!

Originally posted by patrick_hammer on ROS Answers with karma: 283 on 2013-07-09
Post score: 3

A:

#1: From the documentation about gmapping parameters:

~maxRange (float)

The maximum range of
the sensor. If regions with no
obstacles within the range of the
sensor should appear as free space in
the map, set maxUrange < maximum range
of the real sensor <= maxRange.

#2: I haven't played with amcl/gmapping very much, but isn't that the desired behavior? You should be able to tweak parameters such that the estimated error matches how good your robot's odometry (and/or inertial sensor) is, but when moving in the absence of sensor data, your pose estimate should degrade.

Originally posted by lindzey with karma: 1780 on 2013-07-09
This answer was ACCEPTED on the original site
Post score: 5

