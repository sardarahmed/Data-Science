Q:

OWI 535USB Robotic arm

I am looking for information on how I can get this arm to work with ROS. I am new to C and C++ but have programmed a little with Java and PHP. I'd like to get the arm to function with some other ROS Arm scripts if possible. I am just wondering if someone could help point me in the right direction.
From the manufacture:

The RAI-Pro USB robotic arm interface
kit connects the OWI's 535 Robotic Arm
Edge to a Windows personal computer
USB port. The interface software
allows real time interactive control,
plus contains a built-in interactive
script writer. A user may write a
script that contains up to 99
individual robotic arm functions
(including pauses) into a single
script file. Script files may be saved
and loaded from disk just like any
other standard computer file.

Originally posted by xalu on ROS Answers with karma: 68 on 2011-07-09
Post score: 2

A:

Just a warning ahead: this is going to be a lot of work.
Step 1: controlling the arm from code
You need a way to control the motors from code, ideally under Linux (since ROS is best-supported under Linux). Luckily for you, somebody already has reverse-engineered the USB protocol, so you will probably be able to use that.
First, I would write a small test program that can move any motor of the arm to a desired joint angle and publishes JointState messages for each joint on the /joint_states topic (ignore the gripper for now, that's going to be easy later). I'm not sure how well that's going to work, since the arm doesn't measure the joint angles, and the only available commands seem to be "start/stop movement in some direction". You'll probably have to time the commands and compute the resulting joint angles.
Step 2: create an URDF model of the arm
This can be done in parallel to the first step; follow the URDF tutorials. It would be great if you had CAD models of your arm, but for the beginning just using some cylinders/boxes instead should do. Ideally, after completing both steps, you should be able to control the joints of the arm and visualize the result in RViz. You could even point a Kinect camera at your arm, add that point cloud to RViz and check how well the actual arm movements and the URDF model match up.
Step 3: arm navigation
The first two steps should have kept you busy for some while. :-)
By now, just by using the joint angles, you should already be able to do some interesting stuff with the arm. Also, you should have a feeling for the arm, and what can be done with it and what not. If you want to go further, you could try to follow this tutorial to get arm navigation running. This would enable you to pick and place objects recognized in a point cloud (e.g. from a Kinect) while avoiding obstacles. However, this is going to be a real lot of work, and I'm not sure if your arm is maybe too inaccurate (especially when the joint angles can only be computed using some dead reckoning) to do that. Perhaps you need to go for some simpler solution.
Feel free to ask more questions. I'm really looking forward to see how your project is going.

Originally posted by Martin GÃ¼nther with karma: 11816 on 2011-07-10
This answer was ACCEPTED on the original site
Post score: 3

Original comments
Comment by xalu on 2011-07-12:
Well I will have to try it. The arms is just too cheap to not at least try. $70 including the usb controller. I'll update when/if I have I have made progress than add it to the wiki
Comment by Abhinavgandhi09 on 2020-11-05:
Has anyone had any success creating a Gazebo simulation for the robot or URDFs for the robot?
Thanks!

