Q:

odometry precision required for a good navigation

I have been using a neato XV-11 base with an Asus Xtion Pro Live 3D sensor mounted on it for mapping and navigation.
Now I am willing to move to another platform: a cmRobot "the Element" board for motors control and sensors readings.
This board would allow me to use a large range of motors and motors encoders.
But what is the motor encoder precision required for a good odometry, and successful navigation / mapping ?
I have found this wheels and encoders kit:
http://www.active-robots.com/motors-wheels/wheel-kits/motor-mount-wheel-kit.html
But the specifications states: "36 encoder positions per revolution; approx 0.5 inch resolution with 6" diameter wheel".
It does not seem to be very precise (36 encoder positions per revolution). For example, this other wheel kit: http://www.active-robots.com/motors-wheels/wheel-kits/complete-robot-drive-system.html has "360 Encoder counts per output shaft turn." (as said in the downloadable EMG30 documentation)
So how to chose the right encoders and wheels for indoor navigation (small office) ?
Your advices will be much appreciated.

Originally posted by micmac on ROS Answers with karma: 141 on 2013-03-05
Post score: 0

A:

It is difficult to answer that, as "good odometry" is quite a subjective measurement. Besides that, in any system that relies on the use of encoders to estimate the travelled trajectory you are going to have accumulated errors, no matter how good they are.
To mitigate that effect you should have a sensor that takes measurement from external features, as a laser range finder or RGB-D as the one you mention. With that kind of sensors, you will be able to correct the drift of your encoders and have "good" navigation and mapping.
One test that you can do with your current robot: turn off your odometry (either by changing the topic name or by hardware), then see how it works using only your camera for mapping and navigation. I bet it will work just fine.

Originally posted by Procópio with karma: 4402 on 2013-03-05
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by micmac on 2013-03-05:
[ WARN] [1362558417.751254021]: Waiting on transform from /base_link to /map to become available before running costmap, tf error:
Comment by micmac on 2013-03-05:
I can not turn off odometry, I tried to disable odometry publishing in the neato python driver: the navigation gives me the following error [ WARN] [1362558417.751254021]: Waiting on transform from /base_link to /map to become available before running costmap, tf error:.
Comment by micmac on 2013-03-05:
And I can not run gmapping either, it gives me the following error: [ WARN] : MessageFilter [target=/odom ]: Dropped 100.00% of messages so far. Please turn the [ros.gmapping.message_notifier] rosconsole logger to DEBUG for more information. Gmapping doc says it requires base_link->odom transform.
Comment by micmac on 2013-03-05:
I see that I could use laser scan matcher to provide "fake" odometry. http://answers.ros.org/question/35924/slam-without-odometry-gmapping-or-hector_slam/ . I'll give it a try. I don't know if it works for navigation too.
Comment by Procópio on 2013-03-05:
which module are you using with your camera? which are the messages it publish? have you tried amcl to perform localization?
Comment by micmac on 2013-03-05:
I am using fake laser scanner from ardros project: kinect_laser_launch, it publishes a /scan topic. Right now localization does not work if I remove odometry (my project already uses amcl), but I don't know what to change in amcl to make it work without odom.
Comment by Procópio on 2013-03-05:
I think my suggestion only complicated things. I just remembered I had a robot that worked with amcl but had no /odom being published, but I am not sure about the details. Now I am using hector_slam to localize with laser and no odometry. the first part of my answer, however, still holds.
Comment by micmac on 2013-03-06:
ok thank you, I'll try hector_slam

