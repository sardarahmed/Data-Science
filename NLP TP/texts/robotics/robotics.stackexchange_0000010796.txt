Q:

How can we solve the problem of robot size in sensor based motion planning?

As you know in Bug algorithm there is a simplifying assumption that says the robot has no size and can fit between any arbitrarily small gap in the map. How can we overcome the challenge of robot size. As we don't have any per-calculated map (in sensor based navigation), can we still tackle the problem in configuration space?
For example, let's assume that the type of the sensor is Hokuyo URG-04LX Laser Rangefinder. Hence we can visualize the sensor measurements by the visualization matrix $V$:
\begin{equation}
V_i  =\begin{pmatrix}cos(\theta_i )* d_i, \quad sin(\theta_i )* d_i\end{pmatrix}\\
\end{equation}
Where $D= [d_1,d_2,\dotsc, d_n]$ is the set of distances, and $\theta_i$ can be calculated as:
\begin{equation}
\theta_i = \theta_{i-1} + {0.36}^\circ,\qquad \theta_1 = 0
\end{equation}
All the information we have about the robot's surrounding at each moment is $V$. I strongly believe that there is no well-formed formula which can define the robot size in this configuration, and also as we don't have any map, but a simple visualization, growing the obstacles by the radius of the robot size in the configuration space just doesn't make sense.

A:

If you are able to sense obstacles with a sensor pattern that is circular (eg laser scanner, contact sensors on a circular body, etc), and you can rotate the robot pose without translation, then you can satisfy the assumptions of the Bug algorithm. 
If you use a point model for your robot in the map, then you grow the obstacles by the radius of your robot.
If your sensors are not circular, then you will need to create an algorithm for local movement that moves the sensors in a manner that will detect the obstacles without putting the robot in a trapped position. This will probably prevent your robot sensing narrow but valid paths through the obstacles. 
EDIT: You have a circular sensor. If you have differential drive, then you can pick the smallest sensor radius that your robot fits inside and use that. If you have ackerman steering then there is a radius within which you can rotate in place with forward-backward motions. You can use that radius.
All of this is focused on the Bug algorithm. You should use a different, or layered algorithm if you cannot meet the basic assumptions of the bug algorithm.
Also, you can sense the contents of the gap between consecutive points of set $D$ by rotating the robot.

