Q:

How to get pose from rtabmap rgbd_odometry with Kinect

Hi,
I am having trouble using rgbd_odometry from rtabmap_ros package.
I would like to subscribe to the published topic odom (nav_msgs/Odometry) so that I can compute the pose of my robot over time.
Using laser_scan_matcher and hokuyo, for example, I subscribe to a topic named pose_stamped (geometry_msgs/PoseStamped) with this same goal.
I don't care about mapping right now. I just want the pose over time, in order to plot the path my robot displaced.
I am typing the following commands:
roslaunch openni_launch openni.launch`

and
rosrun rtabmap_ros rgbd_odometry rgb/image:=/camera/rgb/image_raw dep/image:=/camera/depth/image rgb/camera_info:=/camera/rgb/camera_info

I can echo the three remaped topics above, but i keep receiving this warning about the base_link.
[ WARN] [1521072121.902733559]: odometry: Could not get transform from base_link to camera_rgb_optical_frame (stamp=1521072121.798015) after 0.100000 seconds ("wait_for_transform_duration"=0.100000)! Error="canTransform: target_frame base_link does not exist.. canTransform returned after 0.100796 timeout was 0.1."

Topic /odom shows nothing.
Could anyone please give me a hint how to start solving it?
I use Ubuntu 16.04 and ROS Kinetic.
Thank you in advance.

Originally posted by EduardoCota on ROS Answers with karma: 3 on 2018-03-14
Post score: 0

Original comments
Comment by jayess on 2018-03-14:
Are you sure that base_link exists? Can you post your tf tree?
Comment by EduardoCota on 2018-03-15:
Thank you for answering! @matlabbe suggestion worked for me.

A:

Try:
$ rosrun rtabmap_ros rgbd_odometry rgb/image:=/camera/rgb/image_raw depth/image:=/camera/depth/image rgb/camera_info:=/camera/rgb/camera_info _frame_id:=camera_link

However, make sure the depth image topic is registered to RGB camera. Like in this tutorial:
$ roslaunch openni_launch openni.launch depth_registration:=true
$ rosrun rtabmap_ros rgbd_odometry rgb/image:=/camera/rgb/image_rect_color depth/image:=/camera/depth_registered/image_raw rgb/camera_info:=/camera/rgb/camera_info _frame_id:=camera_link

Originally posted by matlabbe with karma: 6409 on 2018-03-15
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by EduardoCota on 2018-03-15:
Thank you very much, @matlabbe! It worked and now I can subscribe to /odom and plot the position over time.
However, is there any way to improve visual odometry executed with Kinect? Results are poor by now.
Comment by matlabbe on 2018-03-16:
The source version can give slightly better results. Keep in mind that scanning surfaces without strong visual features will make the odometry drift a lot more. See more scanning tips here.
Comment by EduardoCota on 2018-03-16:
Do you mean the source version from the rtabmap_ros package? I already built from source.
Thank you for the tips!
Comment by matlabbe on 2018-03-16:
Yes this is what I meant. You can also try playing with GFTT parameters: $ rosrun rtabmap_ros rgbd_odometry --params | grep GFTT/. Like adding parameter: `_GFTT/QualityLevel:=0.001". Increasing GFTT/MinDistance can give more uniformly distributed features in images.
Comment by EduardoCota on 2019-01-28:
@matlabbe, Thank you again!!!
I get the odometry, but it stills stopping during some tests.
First, I thought was moving the robot too fast that the VO could not match the features. But it occurs even moving slowly.
Since I'm using a Intel NUC, would you say it stops because of my system capacity?
Comment by matlabbe on 2019-01-29:
If there are no visual features in the field of view of the camera, even if you move very slowly, VO will fail.
Comment by EduardoCota on 2019-02-14:
Ok! Thank you very much, @matlabbe! Have you published any paper that explains how VO with Frame-2-Map works?
Comment by matlabbe on 2019-02-14:
Search "RTAB-Map as an Open-Source Lidar and Visual SLAM Library for Large-Scale and Long-Term Online Operation", link to preprint is on the project page: http://introlab.github.io/rtabmap/

