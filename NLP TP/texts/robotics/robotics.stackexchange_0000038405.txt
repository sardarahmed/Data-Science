Q:

Kinect calibration: disparity or depth?

Reading the technical description in ROS wiki (http://www.ros.org/wiki/kinect_calibration/technical), one would think that kinect devices produce disparity images (with a specific normalization) and efforts should be done to estimate a baseline separation between IR camera and IR projector and a specific constant offset. However, by ROS code inspection, it appears to me that the driver gives a depth map rather than disparity and no baseline/offset calibration is used.
Is ROS kinect calibration currently based only on a zero distortion calibration of the IR camera (thus assuming an accurately measured depth and estimating real-world XY), or am I missing something?
Thanks.

Originally posted by dlopez on ROS Answers with karma: 3 on 2012-03-01
Post score: 0

A:

The device actually sends something akin to a disparity image over USB. Both OpenNI and libfreenect are capable of converting that to a depth image using parameters reported by the device (baseline, focal length, and distance to reference plane, IIRC).
The kinect_calibration package dates from the early days of Kinect hacking, when libfreenect could only return the disparity image and OpenNI was not yet released. So calculating the disparity->depth conversion was a crucial part of calibration.
These days we can trust the driver to return an accurate depth image and work from there. openni_launch is our stable driver package. It allows you to calibrate both the IR and RGB cameras as described at http://www.ros.org/wiki/openni_camera/calibration; otherwise a default calibration is used. The lens on the IR camera is low-distortion, so modeling the distortion only slightly improves accuracy.

Originally posted by Patrick Mihelich with karma: 4336 on 2012-03-02
This answer was ACCEPTED on the original site
Post score: 3

