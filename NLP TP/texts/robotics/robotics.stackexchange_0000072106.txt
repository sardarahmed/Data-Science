Q:

Using tf to connect camera observed tag to base_link

Dear community members,
I have a legged robot that walks around a floor and is being tracked by an overhead camera. This tracking is done with the ar_tag_alvar package which supplies me with a pose of the tag in camera frame. Please note that in a pose message no child frame is broadcasted. I would like to fuse this information with IMU data and odometry and to do this I use the robot_localization package. My understanding is that this package accepts all poses with covariance but assumes that the pose observed is the pose of the base_link in a certain frame. However, the tag I am using is statically attached on top of the robot so that a transform exists between the base link and a link that I will call "tag link". The full set up is drawn in the following figure.

In which: C = Camera frame, T = Tag frame, B = Base frame.
It is clear that knowing the pose of the tag in camera frame implies knowing the pose of the base in camera frame. Mathematically this is not a hard problem to solve when using, for example, homogeneous transformation matrices. This, however, looks like a problem that is so common in ROS that I am assuming tf is able to help me solve it instead of me coding out equations for a homogeneous transformation matrix.
How would I proceed solving this problem with tf? Or am I not seeing a functionality in robot_localization that will handle this, just like it does with the IMU?

Originally posted by hhhhhhhhh on ROS Answers with karma: 1 on 2016-02-16
Post score: 0

Original comments
Comment by Tom Moore on 2016-03-01:
In what frame would you like the output data to be reported? Are you assuming the camera frame is your "world" frame?
Comment by hhhhhhhhh on 2016-03-01:
There exists a static transformation between the camera and the world frame. I would like to know the position to be reported in world frame, yes.

A:

I had a similar issue with navsat_transform_node and GPS sensors that are not mounted at the origin. You'll need to look up the transform from the base frame to the tag frame, rotate it by the robot's orientation in the world frame, then remove that rotated offset from the tag pose, and then fill out a new pose message with the output (change the frame_id to your world frame for that message) and then use that as input to the EKF.
Alternatively, you can create a new frame_id called tag_frame_world or something, and use the logic above to output the rotated base_frame->tag_frame as a transform from the world frame. In other words, you'd constantly broadcast a dynamic transform from odom (or whatever your world_frame is) to tag_frame_world. Then just change the frame_id in your messages to be tag_frame_world. Note that this would still require a new node or modified code in ar_tag_alvar.

Originally posted by Tom Moore with karma: 13689 on 2016-03-07
This answer was ACCEPTED on the original site
Post score: 0

