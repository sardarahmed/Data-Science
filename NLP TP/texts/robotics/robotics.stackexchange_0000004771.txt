Q:

tracking robot in a room

I'm trying to track a simple robot (e.g. arduino, raspberry pi, even toys) in a room using fixed location kinect sensor(s) and cameras at different parts of the room.  How might one usually use to do this?
Edit 1:  More specifically, I want to know the position (and if possible, orientation) of an moving object in the room using one or more cameras or depth sensors.  I'm new to the area, but one idea might be to use blob or haar to detect the moving object and get its location from kinect depth-map, and I'm trying to find what package I can use for that end.  But for navigation to work I'd have to pre-map the room manually or with kinect.  I can put some sensors on this tracked moving object, e.g. IMU, sonar, but not a kinect.  I am allowed full PCs running ROS/opencv/kinect sdk in the environment, and I can wirelessly communicate with the tracked object (which is presently a raspberry pi running ROS groovy on wheels)

A:

With fixed cameras, background subtraction will get you 90% of the way there.  (Assuming you don't have lots of other moving things around your room).
You should consider tagging your robot with color blobs like they do for RoboCup SSL.  Color segmentation is easy, and can be made to be very fast.
But then you need to write some custom code to recover the pose of your robot.  If you put more standard fiducials on the robot like ARTags, then you get this pose directly.
But then you need potentially large and ugly fiducials on the robot.  If you go with a motion capture system like Vicon or OptiTrack, you only need put some small IR retroreflective markers on the robot.  Then you get the pose of your robot with mm accuracy at hundreds of Hz.

