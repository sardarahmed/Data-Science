Q:

Visual servoing with ROS

I'm trying to develop a visual servoing application using ROS, AR.Drone and ardrone_autonomy package. For that I'm planning on tracking a four red dots target to use as reference for the error function but I'm having some trouble tracking those targets. Here's what I tried so far:
1 - Use cv::HoughCircles and track dots' centroid.
2 - Using some blob detection.
I can segment the dots using both methods but I can't track the dots correctly. Let me explain: As the AR.Drone moves, the image changes (obviously) and the reference dots change position on the image. Then I loose track of which dot is which. This way the error functions eventually won't work throughout servoing.
I want to focus on control problems and not on programming and computer vision right now. So I'd like to know if you have any suggestions for a different approach or even some advice I may be missing on the approach I'm using. Is there any out of the shelf solution for this so I can focus on control at once?
Thank you.

Originally posted by perr0 on ROS Answers with karma: 3 on 2012-08-27
Post score: 0

A:

The visp_tracker package wraps a library meant for visual servoing tasks and tracks objects based on contour lines extracted from images. As you're having problems with data association during tracking it might also make sense to look at AR marker or QR code tracking solutions. With those every marker can be unique. What you could look at are ar_track_alvar, ar_pose and april_tags_node.

Originally posted by Stefan Kohlbrecher with karma: 24361 on 2012-08-27
This answer was ACCEPTED on the original site
Post score: 4

