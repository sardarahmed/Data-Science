Q:

Visual Odometry and Mapping in Google Tango?

Hi,
I am interested to know what are the algorithms used for visual odometry or the MAGIC behind Google Tango Project.

What is the algorithm behind pose estimation/visual Odometry ?

Do they have a loop closure mechanism ? What is the method behind it ?

In the video they show a reconstruction of stairs of a multi storey building..thats awesome. How are they able to reduce the error/drift accumulation in their visual odometry pipeline ?

If they have a loop closure method, then how are they able to successfully reject the loop closures that may occur in similar places in the multi storey case ? Is it by checking the places in an area close to their current pose ?

Do they use other sensors like IMU ? If yes, then how do they able to couple that sensor to visual odometry pipeline ?

Can it work in both indoors and outdoors ? What is the range upto which depth reconstruction can take place ?

Can it work in completely dark environment without any illumination ?

Thank you so much for your time...

Originally posted by sai on ROS Answers with karma: 1935 on 2014-05-14
Post score: 7

Original comments
Comment by sai on 2014-05-18:
@dirk thomas @tfoote sorry to disturb you, but I guess you people might know the answer.
Comment by ahendrix on 2014-05-18:
I'm pretty sure the answers to most of these questions are not yet public, and I'm pretty sure that the people responsible have seen this question and have chosen not to respond. You may be able to answer a few of these for yourself by watching the demo videos closely.

A:

hey, if u r interested in Project tango, maybe it's pretty good to read some paper: Fast Visual Odometry and Mapping from RGB-D Data by Ivan, and his codes: https://github.com/ccny-ros-pkg/ccny_rgbd_tools
It shall be mostly related with Ivan's Tango work:
http://www.youtube.com/watch?v=3BNOsxMZD14

Originally posted by Lili Meng with karma: 286 on 2014-07-03
This answer was ACCEPTED on the original site
Post score: 1

