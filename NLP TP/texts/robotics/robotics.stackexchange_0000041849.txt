Q:

Create Semantic Maps using RGBDSLAM + OctoMaps?

Hello everyone!
I'm interested in using RGBDSLAM and OctoMaps with the Kinect camera to create 3D maps. Using generated 3D maps and combining it with object recognition code I've written using OpenCV, I would like to create semantic maps of the environment. For clarity, when I say semantic maps, I just mean having maps are able to highlight or pinpoint recognized objects in the environment.
I hope to do this in 'real-time' - it would be nice if the final product was able to update at a rate of at least 5Hz on my dual-core laptop.
I'm new to ROS/ RGBDSLAM/ OctoMaps so I was wondering whether anyone can provide feedback or suggestions? Is there anything I should watch out for? Are there any easier ways of going about this? Is this in fact possible!?
As far as I can tell from my research, this is the best way to go about this.
I'm also open to suggestion for 2D maps as well, although would prefer 3D at this stage.
Thanks!!!

Originally posted by cleros on ROS Answers with karma: 15 on 2012-07-01
Post score: 1

Original comments
Comment by cleros on 2012-07-16:
I have also posted a similar but slightly more generalized question to this one at http://stackoverflow.com/questions/11489939/creating-semantic-maps-using-opencv-openslam

A:

Regarding the integration of semantic information, here's my thoughts:
The easiest way (maybe not the most efficient though) to do this, is should be to have your recognition software subscribe to the rgb image and point-cloud, do recognition, recolor the point cloud, e.g. red points for class 1, green for class 2, black points for unclassified. then send the rgb image and the recolored cloud to the topics rgbdslam listens to (you can modify them via parameters). Then the point cloud colors will be integrated into the map and can be seen as labels.
To make things efficient, you would integrate your software into rgbdslam and call it from the callback methods in openni_listener.cpp (e.g. kinect_callback, noCloudCallback).
A cleaner way is to use a point cloud type that contains semantic information. Therefore you would need to redefine the point cloud type in rgbdslam (src/parameter_server.cpp) to one that contains your semantic information. Note that, if you omit the color (i.e. the point.rgb field), there will be errors in compiling glviewer.cpp. These should be easily solvable though.
Then you need to adapt the octomap server to use a voxel leaf that stores semantic information. This has been done, but I don't know how.

Originally posted by Felix Endres with karma: 6468 on 2012-07-19
This answer was ACCEPTED on the original site
Post score: 1

