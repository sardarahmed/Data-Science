Q:

URDF for a real robot

I have been making robots in ROS/Gazebo simulation before, which makes use of the URDF to understand the robot model, different frames and transformations. For a real robot, do I need a URDF as well? I have a robotic platform with a lidar and an IMU. Do I need to create links in the URDF file in order to define respective frames?
The confusing thing is that how do I associate a frame within ROS with a real sensor mounted on the system and then perform static and dynamic transforms?

A:

For a real robot, do I need a URDF as well?

It is not necessary to create a URDF for a real robot, but it's highly recommended. Many of the tools are designed to leverage it. For example the robot_state_publisher will take in joint states and generate the tf transform tree using the mapping provided by the URDF. All the motion planning and other libraries are designed to query the URDF to get many parameters of the robot.

Do I need to create links in the URDF file in order to define respective frames

That's the recommended way. You can do it manually too, but that's going to create more work in the long run.

The confusing thing is that how do I associate a frame within ROS with a real sensor mounted on the system and then perform static and dynamic transforms?

The sensor driver should take an argument of it's frame_id which you should match to the frames defined in the URDF. And with the robot_state_publisher active you'll have all the necessary transforms available.

