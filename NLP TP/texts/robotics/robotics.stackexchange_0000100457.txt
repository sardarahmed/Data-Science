Q:

Messages drop on slow subscriber although queue not full / empty

Problem
Setup: ROS noetic, Ubuntu20.
I have a slow pose estimation node which subscribes to incoming images with a low frequency of only 2Hz. The images are published by a rosbag with 20Hz. The bag contains about 800 images (colored, 1280x1024px) , so they should easily fit into the 10k elements queue of the publisher (rosbag play --queue=10000) and subscriber (message_filters.TimeSynchronizer([image_sub, info_sub],10000)
I would expect that the subscriber queues the incoming images so that every single image can be processed one after another.
But instead, already after 3 image messages the dropping of messages starts so that in the end ~60% of the messages are dropped.
While debugging the message_filter.TimeSynchronizer (synchronizes CameraInfo and Image subscriber) I could see that the
image queue is never longer than 1, while the camera info queue grew proportional to the published messages.

Originally posted by belorenz on ROS Answers with karma: 16 on 2021-11-04
Post score: 0

Original comments
Comment by gvdhoorn on 2021-11-04:\

The problem I am describing here is already solved. Nevertheless I want to describe it and its solution here, because I think it is a common problem for which I could not find any solution online.

posting this here is perfect, so +100 for that, but could you please post the solution as an answer instead of a section in your question?
If you then accept the answer, it will be completely clear the issue was resolved.
Right now we only see a new and unanswered question on the index page.
Comment by belorenz on 2021-11-04:
Added an answer but was not able to accept it as correct since I have < 10 points.

A:

Solution
While searching for a solution I learned that message transport in ROS happens with TCP/UDP.
Through this hint to the TCP\UDP send buffer I could stop the dropping by increasing the initial and maximum size of the TCP read and write memory (tcp_rmem and tcp_wmem) with the help of this blog post.
The second number is the initial size and the third number is the maximum size of memory of the TCP buffer in bytes.
I increased the initial and maximum value by adding the following lines to /etc/sysctl.conf:
net.ipv4.tcp_rmem= 10240 1258291200 2058291201  
net.ipv4.tcp_wmem= 10240 1258291200 2058291201  

I choose arbitrary values which simply worked for me (28GB RAM), you might need to adjust these values to your problem.
After saving the file I applied the changes with
sudo sysctl -p

Originally posted by belorenz with karma: 16 on 2021-11-04
This answer was ACCEPTED on the original site
Post score: 0

