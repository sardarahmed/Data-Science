Q:

SLAM from partly occluded LiDAR sensor

I am building my first project which will use 2D LIDAR for SLAM and the robotic platform is a small car. However the LIDAR is hidden inside and it's occluded by 4 cylinders which connect the roof with the floor of the platform. Is it possible to reliably map the environment and the position of the robot when the lidar is occluded like that? I would be very thankful for recommending some of the simplest possible algorithms to handle this problem. 
For clarity, I sketched what the robot looks like from 2 sides:

The environment of the robot is not known a priori. The robot only knows the direction and distance to the waypoint and its goal is to navigate to it and plan its motion as it is progressing and discovering new obstacles.

A:

This is definitely possible and rather normal. You should set the respective measurements to zero or NaN and most algorithms should be able to handle these cases. Laserscans almost always have incomplete data (e.g. due to maximal distance or a object with very high or low reflectivity)

