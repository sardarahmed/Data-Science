Q:

Reinforcement learning on bag files?

At my university, we've been setting up a new subject on intelligent robotics right now. We want to do all the labs in ROS and on real data from our robot.
Now I've been thinking about what would be the best task for the students to be solved in ROS to exercise reinforcement learning.
We've got a UGV, but we just can't make it available for all the 60 students. So we think about what task can be solved provided only a recorded bag file without any interaction with the robot.
We know this isn't the best setup for reinforcement learning; on the other hand, just learning a value/Q function from a recording seems also as a possibility. We also need the result of the learning to be verifiable without running the students' codes on the robot.
Do you have any ideas on what task do try?
Our ideas:

Doing something with the camera data (some simple vision task)
Taking odometry and accelerometer data as training and try to learn when it is not advisable to go straight forward

Thanks for your ideas.

Originally posted by peci1 on ROS Answers with karma: 1366 on 2014-01-15
Post score: 3

A:

If you could provide the students with a Gazebo simulation, they could solve a real reinforcement learning task. I'd stick with some very simple wheeled robot, so the simulation doesn't get too slow. One idea for a task would be learning to follow a corridor (or maybe even a maze) using a laser scanner. We have a working simulation of our six wheeled robots as part of our kurt_driver stack, maybe you can modify that for your needs.

Originally posted by Martin GÃ¼nther with karma: 11816 on 2014-01-26
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by peci1 on 2014-01-27:
Thanks, Martin. Gazebo really seems like a good way. But the problem is we don't have (and don't want to create :) ) a physical model of our robot. But we'll keep considering Gazebo and let the students solve the task on a virtual robot, which could also be great experience ;)

