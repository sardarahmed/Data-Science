Q:

Obstacle avoidance algorithm for turtlebot

I need information on using RGB D-SLAM for obstacle avoidance in turtlebot. If I launch kinect+rgbdslam.launch in one terminal after launching openni.launch in different terminal, if I use rostopic pub cmd_vel for moving turtlebot, will it traverse detecting obstacle and avoiding it ? As obstacle avoidance algorithm is already implemented in RGBD-SLAM ?

Originally posted by Devasena Inupakutika on ROS Answers with karma: 320 on 2013-03-17
Post score: 3

A:

No, RGBD SLAM only provides localization and mapping.  That is, it tries to build a map and figure out where the robot is within that map.  What you're talking about is path planning.  If you look at the diagram on this page, it's the move_base package that does that planning.
I think this would be a good question to read: http://answers.ros.org/question/9712/how-to-use-rgbd-6d-slam-for-path-planning-and-navigation-with-kinect/.
-Jon

Originally posted by Jon Stephan with karma: 837 on 2013-03-17
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by Devasena Inupakutika on 2013-03-18:
Hi Jon, Thanks a lot for the information. I have gone through the tutorials related to setting up and configuring navigation stack for robot. I just want to put it down here, please let me know if I am missing something here:  I will be creating a separate package specific to the robot I am working
Comment by Devasena Inupakutika on 2013-03-18:
on , then create a robot configuration file and make changes to the launch file based on sensor nodes my robot makes use of  and sensor_msgs type (point cloud for kinect etc.) , build it and then try running the launch file for my robot navigation stack. This is how I should proceed ?
Comment by Jon Stephan on 2013-03-18:
I think so, pretty much.  I don't know what you've done already, but it makes sense to first make sure you can drive the robot around.  Then make sure you get the robot working with RVIZ.  Then make sure you can get the laser scan working in RVIZ.  Then gmapping.  Then the autonomous navigation.
Comment by Jon Stephan on 2013-03-18:
If you jump right into the navigation stack, it will be difficult to debug any problems.
Comment by Devasena Inupakutika on 2013-03-19:
Hi Jon, I have tried all the steps (laser scanning (since I am not using planar laser instead using Kinect, hence I have done the point_cloud to laser package for laser scanning, TF and publishing odometry ) and got all of them working on RVIZ. Hence, I think I can now get SLAM working now through
Comment by Devasena Inupakutika on 2013-03-19:
SLAM gMapping.
Comment by Devasena Inupakutika on 2013-03-22:
Hi Jon, For SLAM to work with kinect, I have created three launch files as follows --> one for kinect_laser to transform point cloud data to laser scan data, one for link between kinect and base_link (static_transform_publisher) and one for slam gmapping with all the required parameters.
Comment by Devasena Inupakutika on 2013-03-22:
And everything worked fine and I could save the map using map_saver. I think I can now do the autonomous navigation of this known map. Thanks a lot for the help and links for 2D SLAM with kinect.
Comment by Devasena Inupakutika on 2013-03-22:
For other's reference I have followed above specified links and below one which helped me in fixing issues and get SLAM working:  http://www.hessmer.org/blog/2011/04/10/2d-slam-with-ros-and-kinect/

