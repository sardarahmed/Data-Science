Q:

Detect Nao robot in Kinect

I am not sure if this has been tried before but I am trying to use Kinect and detect gestures made by the Nao robot.
I have made a Kinect application, a gesture based picture viewer and it detects humans fine(Obviously it does!) What I wanted to try was (lazy as I am), to see if I could use some (say, voice) command to tell the Nao to do a Swipe Right gesture and have my application identify that gesture. The Nao can easily identify my command and do some gesture. The problem however is, when I put the Nao in front of the Kinect sensor, the Kinect does not track it. 
What I want to know is, are there some basics behind Kinect's human body motion tracking that essentially fails when a robot is placed in front of it instead of a human?
PS: I have kept the Nao at the right distance from the sensor. I have also checked if the entire robot is in the field of view of the sensor.
EDIT: This has been posted on stackoverflow and on msdn by me so as to target a large audience as this problem has not been encountered by anyone in the past.

A:

You should read the paper published by Microsoft research on the actual algorithm behind the human motion tracking.
Real-Time Human Pose Recognition in Parts from a Single Depth Image, Shotton et. al,
http://research.microsoft.com/apps/pubs/default.aspx?id=145347
It relies on large labeled training data from the human body. That is why the Nao cannot just be tracked with the same method out of the box. To achieve that, you would need to re-train the algorithm with labeled data from the Nao in different poses.

