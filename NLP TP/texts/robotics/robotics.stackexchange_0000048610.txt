Q:

How to use IR range finder with navigation stack?

How do you use an IR range finder with the navigation stack?  I got my eddiebot-like robot all set up, and added the range finders to costmap_common_params.yaml, but it just tells me:
[FATAL] [1361591285.796743183]: Only topics that use point clouds or laser scans are currently supported

So I'm thinking it wouldn't be too translate my range finders into laser scan messages, but that seems like a kludge.  It seems like this must have been done before (for example on Eddiebot. What have others done?

Originally posted by Jon Stephan on ROS Answers with karma: 837 on 2013-02-23
Post score: 0

A:

With the current navigation stack, you have to either convert to PointCloud, PointCloud2, or LaserScan (I would avoid PointCloud as that message might go away some day and is superceded by PointCloud).
The sensor_msgs/Range message is actually fairly new, and while you could certainly go add that capability to the navigation stack, you would have to edit the costmap_2d, possibly AMCL, etc, and so it is more straightforward to just write a node that creates a laserscan out of your sensor data.
Note however, that you may actually want to interpolate in between your range finders or tune the costmap grid size, otherwise you may have serious issues clearing the costmap if you don't have enough other sensors on the robot.

Originally posted by fergs with karma: 13902 on 2013-02-28
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by Jon Stephan on 2013-03-01:
Thanks, I changed my code to output a Range message along with an equivalent LaserScan message.  I do also have a Kinect, these are just to sense the things that are too close for the Kinect to see.

