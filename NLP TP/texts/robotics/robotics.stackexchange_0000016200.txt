Q:

EKF localization data association

I am working with ROS indigo and clearpath huskyA200 and wanted to implement the EKF localization with unknown correspondences with my own hokuyo lidar data for a school project. Giving the algorithm in page 217 of the probabilistic robotics book by Thrun. (Picture of the algorithm is given below), what does step 9 mean by “for all observed features”, does it mean all the raw data in a lidar scan? Or does it mean to process the raw data first to find the features? If it’s the latter, what would be some technique to process the raw data to find features?
This stackoverflow post helped me understand this algorithm a lot better, but now, i am just not sure how to provide the observed feature with my own lidar scan data.
Any help is appreciated, thank you.

A:

It should be processed features. Extracting features from raw data is usually called as front-end in SLAM. The easiest forms of features in cased of 2D LiDAR are corners, edges, and lines. You can run RANSAC algorithm to find line segments. Corners are found by intersection of lines and edges are ends of lines. Corners should be enough for a uni project.
ICP can be utilized to register raw scans but that becomes a different type of SLAM.

