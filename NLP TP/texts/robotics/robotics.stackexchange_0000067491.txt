Q:

How to get pointcloud2 data from usb_cam or Pointgrey camera?

Hello, experts~
I am a new in ROS. And recently, I am trying to get image and make it detected by the node ar_track_alvar. However, this ar node requires sensor_msgs/PointCloud2 data. Firstly I tried to use usb_cam_node and I got sensor_msgs/Image. The same situation happened using Pointgrey camera with its driver: pointgrey_camera_driver.
After searching some files, I find that it might work if I can use openni to get the image, after all it is discribed in wiki: "Launch files to open an OpenNI device and load all nodelets to convert raw depth/RGB/IR streams to depth images, disparity images, and (registered) point clouds."here.  And after I run the command: " roslaunch openni2_launch openni2.launch " it says there is no device. I really don't know how to make it out. Can anyone help me answer the following question:

Can pointgrey camera be directly used by openni launch file?
Can common USB camera be used by openni launch?
If the answer of both is negative, how can I get pointcloud2 data with what kind of device and with which driver?
P.S.
Here is what shell says after I run roslaunch openni2_launch openni2.launch
[ INFO] [1431337093.836048605]: No matching device found.... waiting for devices. Reason: std::string openni2_wrapper::OpenNI2Driver::resolveDeviceURI(const string&) @ /tmp/buildd/ros-indigo-openni2-camera-0.2.3-0trusty-20150327-0611/src/openni2_driver.cpp @ 623 : Invalid device number 1, there are 0 devices connected.

Originally posted by david059 on ROS Answers with karma: 13 on 2015-05-11
Post score: 0

A:

For using openni package and also for generating point cloud you should have Kinect or Asus Xtion ( Depth Sensor). OpenNI wont work with normal usb camera. usb_cam package is to capture rgb image using usb camera.
For generating pointcloud u can use either Kinect with freenect package or rgbdslam ( available for electric Older version of ROS)
If you are only interested in creating 3D, you can use lsd_slam or ORB slam, it will give nice 3d in real time but it wont publish any pointcloud message.

Originally posted by KDROS with karma: 67 on 2015-05-11
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by david059 on 2015-05-11:
WOW! So quick! Thank you very much for your guidance! So now I understand what can be used for OpenNI and what cannot. But can I take it that the pointcloud can just only be generated by OpenNI which means I have to have devices you mentioned? Is there any other way I can get pointcloud with uabcam?
Comment by KDROS on 2015-05-11:
Yup I mentioned, lsd_slam and ORB_Slam you can get good pointcloud, but for very good pointcloud either use lsd_slam with global shutter camera with fish eye lens or Kinect/Asus Xiton with freenect/openNI2 package.
Comment by david059 on 2015-05-11:
I think you just really did me a great favor! Even though I can't find LSD_SLAM nor ORB_SLAM in http://www.ros.org/browse/list.php, I find them in github! I will try them right now and I hope this time I can make it. Thank you, KDROS!
Comment by KDROS on 2015-05-11:
Thanx, Yup It is not available in ROS, check this links lsd_slam.
You can ask if you will be in trouble.
Comment by david059 on 2015-05-12:
Hey KDROS, after reading about what it says in github, I realize the problem you mentioned , LSD_SLAM indeed can not be used for live-pointcloud use in ROS. ButI think I find another way to get PointCloud2 data. By using image_proc
Comment by david059 on 2015-05-12:
I will talk in more detail in my answer below

