Q:

What's the best way of dealing with the Kinects "blind spot"?

I'm wondering what the best way of dealing with the minimum scan distance limitations of the Kinect (i.e within ~0.6m it can't detect objects). Specifically I'm attempting to use explore and slam_gmapping packages to search a room. This works when the robot starts in the center of the room (or at least more than 0.6m from a wall), however if the robot starts in a hallway where the walls are closer, the map and by extension exploration goals get completely messed up.
I realise this can't be fixed as it's a hardware limitation, but what are good parameter values to minimise the effect on the map/navigation? I've found setting the slam_gmapping param "maxUrange" to 6.0 helps, are there any others I should look at?
As a follow up question, I'm using a LEGO Mindstorms NXT kit for the robot. At the moment I'm just using the two motors that come with the kit as a base, would it be possible to add the sonar sensor to compensate for the Kinects blind spot in some way?

Originally posted by Tadhg Fitzgerald on ROS Answers with karma: 98 on 2013-02-18
Post score: 4

A:

You might even decrease the maxUrange -- I think it is something like 3.0 on the turtlebot as readings have higher error at longer range (something that gmapping really doesn't take into account, as it assumes an error model more like a laser scanner). In general, I suggest that people look at turtlebot_navigation as a good starting point for parameters to use on a base with only a kinect, and limited odometry.

Originally posted by fergs with karma: 13902 on 2013-02-18
This answer was ACCEPTED on the original site
Post score: 4

Original comments
Comment by Tadhg Fitzgerald on 2013-02-19:
Great thank you, I'll have a snoop about in those:)

