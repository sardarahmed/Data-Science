Q:

Navigation of mobile robot in 3d map

Hello,
I'm working on a project where we want to be able to navigate a robot trough a field with uneven terrain, using a laser scanner and/or Kinect (Kinect version 1). I am looking for the best solution to do this. Our plan is to map the field before we start driving. Next, we want to set goals for the robot to drive to.
Available hardware for navigation:

360 degrees 2d lidar scanner
Microsoft Kinect
6-DOF IMU.

of course, we have a complete URDF file and drivers for publishing data into ROS.
What would be the best way to make the robot do successful navigation. Is there a stack or package available that takes all this data and outputs the desired speeds for the robot?
I hope to get a reaction soon!
Kind regards,
Jesse

Edit: Hello @M@t!
Thank you for this quick and extensive response! I never expected that!
I have enough information for now to get started thanks to you. If you like to know more about my project, read below.
Project
We are going to compete in the FieldRobotEvent in Britain this year. The task is to design a robot that is able to drive through a set of lanes of corn plants, such as the image below.

The event is divided into 5 tasks. Each one gets harder. We mainly want to focus on task 1 and 2 because we cannot do 3, 4 and 5 without the basis of task 1 and 2.
What we have
A team member is currently designing the hardware.
In a couple of weeks, we will have a robot equipped with encoders on all wheels, a (2D) LiDAR scanner, a 6DOF IMU and a Kinect (360).
I am fully responsible for the software.
Problems to solve
Task 1 and 2 are the tasks where we need to drive trough the lanes of corn as quickly and accurately as possible. this has to be done fully autonomously.
The robot thus needs to know where it is and how to drive trough the lanes. applying an RANSAC algorithm or something is so-so okay, but does not work in practice (I saw that last year with a robot from another team).
Why ROS
I figured, if we can obtain the map beforehand we can autonomously drive through it.
The next logical thing would be to use ROS to solve the navigation, goal and pose problems.
The problem here is that while localization algorithms like AMCL like a stable ground. In practice and in the competition the robot can tilt up to 10 degrees sideways (or forward for that matter). This would, for instance, cause problems with the laser scanner because the scanner won't scan the flat plane anymore.
Again, thank you for your elaborate response!

Originally posted by feignedjesse2 on ROS Answers with karma: 33 on 2017-03-14
Post score: 3

Original comments
Comment by gvdhoorn on 2017-03-14:
Reading "field" and "uneven terrain" reminded me of the questions by @M@t. Perhaps he can share his experiences. I would definitely check out some of his questions & answers here on ROS Answers.
Comment by gvdhoorn on 2017-03-15:
One more suggestion:

In a couple of weeks, we will have a robot [..]

try to start creating a simulation model of your robot and the target environment now / as soon as possible. That will allow you to start working immediately, but also makes experimentation really trivial.

A:

Hi @feignedjesse2, sounds like you're doing something similar to me, so I'll try help you out as best I can. Your problem is pretty general so I can't give you specific advice without knowing more about your project and what you're trying to achieve. As always, I'll assume that you or anyone else reading this is just starting out with ROS. Let's break down what you want to do into three parts (all of the below have ROS integration):
SLAM
You want to map your environment and you need a 3D map, you're often wanting to localize your laser scanner or robot at the same time - i.e. Simultaneous Localization and Mapping (SLAM) Below are some ROS-compatible options.

Gmapping is the most-integrated SLAM algorithm you can use with ROS, so it works well with the ROS navigation stack (below). It's essentially a ROS wrapper for the Gmapping algorithm you can find on OpenSLAM. Only does 2D SLAM but is a probably the best starting point for anyone new to ROS.
Google Cartographer Google very recently released this 2D/3D SLAM package that will take laser and/or point cloud data and give you an occupancy map. You can find ROS integration here and Github code here. Not sure how they represent the map internally. Cartographer includes loop-closure.
Berkley Localization and Mapping (BLAM) is another 3D LiDAR SLAM package. This doesn't have any papers on it that I am aware of, and it isn't being maintained (last commit was over two years ago). This uses the open-source and ROS-compatible Point Cloud Library for some of it's processing. Also does loop-closure
Laser Odometry and Mapping (LOAM) is another 3D LiDAR SLAM package written by a PhD student. The source code is old and outdated because the student went on to commercialize their code with the company Kaarta. You can find a (somewhat) working version of the LOAM source code here. Does not perform any loop closure, so it's long-term use is quite limited.
hector_slam/hector_mapping gives you LiDAR-based SLAM for systems with poor/no odometry (may suit you since you don't have wheel encoders). Also outputs an occupancy map. From memory I think this uses an elevation map (someone correct me If I'm wrong)

Of these options, I've played with Cartographer, BLAM, LOAM and Gmapping. If you're starting out with ROS and you only need 2D SLAM, I'd recommend Gmapping. If you are experienced with ROS and/or SLAM concepts, I think the 2D version of Cartographer is more accurate and robust than Gmapping. If you need a 3D solution, Cartographer is quite hard to setup, tune and use, but it is still maintained and probably a better solution long-term than BLAM. Can't recommend the LOAM code.
Mapping only
There are some packages that don't do SLAM and are only used for pure mapping (i.e. you'll have to use something else to localize the laser scanner or robot)

Libpointmatcher While not strictly part of the ROS ecosystem, you can export clouds to a format LPM can then read. LPM is developed and maintained by a group working out of ETH Zurich. The developers have produced a decent number of papers on LPM, so you can get a good idea of what it is capable of by reading those (start with papers by Fran√ßois Pomerleau).
Point Cloud Library PCL is not a mapping program. It is a collection of libraries for point cloud processing. But it includes many functions for positioning and registering (matching) LiDAR scans. PCL works well with ROS (it started life as a ROS library IIRC) and has more options than anything else out there, but it doesn't have an established mapping process, so you have to build your own mapping program. Having gone this route myself it is definitely an "advanced users only" option.
elevation_mapping Takes in a point cloud and gives you a robot-centric elevation map.
voxel_grid the ROS navigation stack does have code for implementing a voxel map, but it's not supported officially so I'd do some thorough research before choosing this option. Uses a voxel grid (obviously).
octomap/octomap_mapping Implements a 3D octomap (basically a hierarchical voxel grid). Not sure about the level of support though.
rtab_mapping This is a pretty comprehensive package that will do a lot for you. It has support for kinect and also includes a few things like visual odometry which you will find useful for...

Localization
Many of the packages above implement SLAM which will do your localization for you. I see you don't have a GPS so I presume that you don't care about earth-referenced positioning. If you do need other localization packages:

AMCL from the navigation stack provides implementation for a particle filter. Otherwise...
robot_localization is an excellent package that can implement an EKF or UKF for you, and also includes support for GPS. I have a fair bit of experience with this package so I can help you if you end up using it. The author Tom Moore is also very helpful and responsive.

Navigation
Finally, for navigation your best option is the ROS navigation stack. It's one of the most-used packages in ROS and also one of the most extensive. It requires a 2D occupancy map to navigate obstacles, and can implement a bunch of different path-planning algorithms (A*, trajectory rollout, Dynamic Window Approach etc). You basically give it a point in the world to navigate to and the stack will do the rest. It does this by specifying a desired linear and angular speed and sending this command to your robot's motor drivers.
The nav stack is pretty extensive so I suggest you start by reading the documentation and tutorials thoroughly. Seriously, I could have avoided 75% of my own navigation problems if I'd read the documentation properly.
If you want help on queuing up multiple move goals and getting the robot to move in more complicated trajectories I've discussed something like that in this question.

Hopefully this helps and will give you some starting points. If you give more specific details on what you want and are tying to achieve I can give you more specific advice.

Originally posted by M@t with karma: 2327 on 2017-03-14
This answer was ACCEPTED on the original site
Post score: 17

Original comments
Comment by raultron on 2017-11-21:
Amazing answer. Thank you very much.
Comment by Amina23 on 2020-03-05:
thank you . you're awsome !
Comment by darshb34 on 2021-01-10:
Hi @M@t, Can you please suggest how to integrate 3D slam algorithms like cartographer or hdl_graph_slam with NavStack for navigation purposes? I understand we can setup tf for localization, but how how do we do path planning on 3d maps (we do not get grid maps).
Thank you for the help and appreciate your contribution.
Comment by M@t on 2021-01-12:
@darshb34, that is a question with a very long and complicated answer. Far too long to discuss in the comment section, and possibly too broad even to properly answer in a forum thread. I suggest you create a new question, and try to define what you want to achieve as succinctly as possible.

