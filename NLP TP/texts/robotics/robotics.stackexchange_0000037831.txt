Q:

PrimeSense User Tracker Viewer with Openni_tracker

Hello,
First off nice new design for the website, I love it!
This question has been asked many times here, however I didn't quite find the answers useful with many providing different ways of doing it and it ended up not really working. I do have a working solution and was wondering if there is an easier way.
I am trying to use the openni_tracker to track a human and get access to all the transforms provided by it. Openni_tracker by itself seems to work (i.e. it tracks the user after calibration). However, without visual confirmation it is difficult to see what is going on. I do not know how to launch the Prime Senser User Tracker Viewer from ROS as the nite package within the openni stack is pretty much empty. There is nothing in the bin directory and everything in the CMakeLists.txt is commented out.
In my hunt for a viewer, I came across this website: Kinect on Ubuntu with OpenNI. I was able to follow the instructions and install Openni, SensorKinect and NITE. In the Openni bin directory there is an executable by the name Sample-NiUserTracker which does the same thing as openni_tracker from ROS while also providing the viewer. This is fine, except I don't have access to all the convenient transforms that the ROS package publishes and I (right now) do not know how to extract tracking data from the kinect running the Sample-NiUserTracker software.
There is also another executable by the name of Sample-NiUserSelection which basically seems to just provide the viewer with the skeleton. So, currently I am running the openni_tracker on one terminal and the Sample-NiUserSelection on another terminal so that I can see what is being tracked along with having access to easy tracking data provided by ROS.
My question is, am I complicating things too much or is there an easier way by which we have a ROS node with basically launches the viewer?
Any help is much appreciated!
Thanks.

Originally posted by Sudarshan on ROS Answers with karma: 113 on 2012-02-13
Post score: 0

A:

I would say use rviz!
There are at least two ways I know of to visualise the tf frames and kinect's rgb image stream at the same time:

Add a tf and a camera display. After choosing the right topics, you should see the rgb image with an overlay of the tf frames in the camera window.

Add a tf and a point cloud display: After choosing the right topics (remember to set the colour transformer of the point cloud to RGB8), you should see the point cloud with the rgb image mapped on it and the tfs.

Does that suit your needs?

Originally posted by bit-pirate with karma: 2062 on 2012-02-14
This answer was ACCEPTED on the original site
Post score: 1

