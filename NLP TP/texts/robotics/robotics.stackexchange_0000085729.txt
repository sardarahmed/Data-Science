Q:

Does size matter when doing Gmapping with Kinect?

I want to know how big of a robot have people successfully implemented slam using a cheap inexpensive Kinect sensor .
I am currently building a robot as big as jackal platform from clearpath.
All the robots I have seen (mounted with Kinect ) is generally small sized . (Turtlebot , lino bot , pioneer...)
I have simulated the robot on gazebo but the error rate seems to be too high .
How much of an improvement can I expect if I were to use intel realsense D435 ?
I know that visual odometry in this case would be more reliable , but at this point I am kind of inclined towards more off a classical (encoder odometry) based slam approach.

Originally posted by chrissunny94 on ROS Answers with karma: 142 on 2018-03-08
Post score: 1

A:

The accuracy of SLAM mainly depends on the range of the sensor, size of the environment compared to sensor Field of view (FoV) and uncertainty of motion and measurements. Generally, Kinect sensor is a low FOV (57 degrees) and short-range sensor (max 5.5m).
Gmapping builds locally consistence map using scan matching and builds a globally consistent map by fusing Rao-blackwellized particle filter. It needs some features ( objects) in the FoV to build a consistent map.  If enough features are not available in sensor FoV for few frames, the local estimation will not give a good accuracy.
Also, the noise of the sensor is a quadratic function with the range of measurements. This also leads the wrong estimation of local maps. Therefore, Kinect can provide a promising result with Gmapping for small-scale environments.
You can use a higher number of particles to get more accurate maps. But, very large number of particles also may lead to diverge the estimation, because, there a higher probability to pick particles with low weights at resampling step.

Originally posted by Gayan Brahmanage with karma: 929 on 2018-03-09
This answer was ACCEPTED on the original site
Post score: 3

