Q:

Best Practices in ROS. (Making FRC->ROS Tutorial)

Hello!
I am learning ROS and want to teach it to my (and every) FRC team in few months.
I plan on doing this make a “ros walkthrough” to demo the “correct” way to use ros.
For the example, we will make an autonomous (click and go) ROS-Powered robot from start to finish using best practices.
I want the finished code to also be a sturdy starting/sanity point for exploring ROS for the 350,000+ FRC students using equipment available to FRC teams.

Example Hardware:

Drivebase: Old FRC Differential Drive Kit bot
Motor Controllers: Serial -> Arduino ->“RC-Style” PWM -> “Talon SR Speed Controller”
Encoders: Serial <- Arduino <- US-Digital Quadrature Encoder E4P
IMU: Serial to Arduino to 3 axis accel + 3 axis gyro
Sensor: Kinect
Brain: A laptop running Ubuntu 14.04 LTS
Input: another laptop.

Software: How should I do it? I think:

I should use ros indigo because it is the ‘current’ release.
I should use navigation instead of nav2d
navigation_tutorials are for hydro and are mostly hardware dependent.
I do not want to use obsolete things.
I want to make reusable code. I do not want to reinvent the wheel.

Config

sensor transforms: make a node that publishes  the transform base_laser → base_link
sensor source: for kinect use freenect_stack
I make a node that reads from the encoders and publishes an odometry source or the encoder position. (which?)
Should I use robot_localization?
imu: arduino publishes “imu” (sensor_msgs/Imu)
encoders: arduino publishes “wheel_encoders” or “wheel_odom” (nav_msgs/Odometry)
base controller: Should use diff_drive_controller? Should the arduino subscribe to a motor_speed, motor_power, or cmd_vel?

Thank you very much for using your expertise to advance the human condition!
prosa

Originally posted by prosa100 on ROS Answers with karma: 56 on 2014-08-05
Post score: 2

Original comments
Comment by daalt on 2016-06-19:
prosa100,
It's been a while since you posted this question but I was just wondering how your project to teach ROS to the FRC community turned out.  Did you develop any tutorials or packages?  Can you please contact me at altemir .at. verizon dot net and let me know?

A:

Here's my insight:
Software:
--Currently only Indigo is supported on 14.04. You can build the source from scratch for hydro, but its simpler to just use indigo.
--The Nav Stack that already comes with ROS is what you should use.
-- If your talking about the actual tutorials for the nav stack, here it is. If you are talking about a downloadable ros package, I personally really like clearpath robotics husky package. Although its not named tutorial, there are multiple launch files with various configurations for almost all purposes (odom only, odom and gmapping, amcl, etc...). They also give you a already set up model of their husky robot ready to be used in gazebo. I use it myself if i dont feel like plugging in my robot. If you have any questions about that let me know. Ill be glad to help.
Config
-- For people who are new to ROS, I would recommended writing a tf_publisher node that broadcasts all of the transforms from your sensors to your base_link frame. That way they will clearly see where all their data will be going.
-- Make a node that grabs your encoder ticks (motor controller node) and then make a geometry_msgs/Twist message out of that. Then send that to your odometry node, where you can follow the ros tutorial how to get position x, y, z and velocity vx, vy, vz.
-- I currently am using robot_pose_ekf for kalman filtering, but being a beginner and not understanding at all how and why robot_pose_ekf works the way it does with not publishing a odometry message but pose with covariance stamped (PWCS), Robot_Localization would be alot easier for students to understand. Unlike robot_pose_ekf, it does not limit you to the amount of sensors you can have as inputs to the filter. Also, it publishes a odometry message (versus PWCS), which will cause a lot less confusion after going through the navigation tutorials for the first time.
-- Arduino imu should be okay. If you are going to use it, I can give you some advice on how to use it in robot_localization since that imu may be noisy, and how to configure it for your scenario.
-- For encoders, its pretty much a repeat of what I said before. Personally, I like to keep wheel_encoder data in its own node, and odometry as its own node as well.
-- Not fimiliar with using ros on arduino, so can you explain what you want with the base_controller part a little more?
Hope this helps.

Originally posted by l0g1x with karma: 1526 on 2014-08-06
This answer was ACCEPTED on the original site
Post score: 5

