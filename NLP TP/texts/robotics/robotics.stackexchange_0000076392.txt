Q:

errors in using robot_localization package

Hello ROS gurus,
I am trying to use robot_localization package to better localize my turtlebot in my lab environment. But it seems like it is not able to do what it is meant to do, i am not able to figure out what the problem is. Here is the description of what i have done and required files:
I am using ROS Indigo, Ubuntu 1404 on a turtlebot which is controlled with a joystick. I have configured robot_localiztion package after going through the wiki and some questions related to the package. I drove the robot around in a rectangular grid and collected data in a bag file and played it later. This is the launch file i am using and these are the results i got.
  <param name="frequency" value="30"/>  

  <param name="sensor_timeout" value="0.1"/>  

  <param name="two_d_mode" value="true"/>

  <param name="odom_frame" value="/odom"/>
  <param name="base_link_frame" value="/base_footprint"/>
  <param name="world_frame" value="/odom"/>

  <param name="odom0" value="/odom"/>
  <param name="imu0" value="mobile_base/sensors/Imu_data"/>

  <rosparam param="odom0_config">[false, false, false, 
                                  false, false, true, 
                                  true,  false, false, 
                                  false, false, false,
                                  false, false, false]</rosparam>

  <rosparam param="imu0_config">[false, false, false, 
                                 false,  false,  false, 
                                 false, false, false, 
                                 false,  false,  true,
                                 false,  false,  false]</rosparam>

  <param name="odom0_differential" value="false"/>
  <param name="imu0_differential" value="false"/>

  <param name="imu0_remove_gravitational_acceleration" value="true"/>

  <param name="debug"           value="false"/>
  <param name="debug_out_file"  value="debug.txt"/>

</node> 

Here is the tf frames out when i ran below command
rosrun tf view_frames

And this is the result of odometry plotted in Rviz (red is /odom from turtlebot green is /odometry/filtered from robot_localization)

I plotted odom data using python, here is the result. You can see that both odom(red) and odom_filtered(blue) are overlayed on each other

I am not getting any errors while using robot_localiztion package and tf frames looks right to me. I am not able to figure out what the problem is. Can anyone help me? And here is the bag file i am using.
bag file
NEW PLOTS:

tf frames
Also i ran the command rosrun tf tf_echo /gyro_gram /base_link_fram and i was able to see the output.
UPDATED ON 10/03/2016 4:10 PM
Here is my launch file:
<node pkg="robot_localization" type="ekf_localization_node" name="ekf_localization" clear_params="true">

<param name="frequency" value="30"/>
<param name="sensor_timeout" value="0.1"/>
<param name="transform_time_offset" value="0.0"/>

<param name="two_d_mode" value="true"/>

<param name="map_frame" value="/map"/>
<param name="odom_frame" value="/odom"/>
<param name="base_link_frame" value="/base_footprint"/>
<param name="world_frame" value="/odom"/>

<param name="odom0" value="/odom"/>
<param name="imu0" value="mobile_base/sensors/imu_data"/>

<rosparam param="odom0_config">[false,false,false,false,false,false,true,true,true,false,false,false,false,false,false]</rosparam>

<rosparam param="imu0_config">[false,false,false,true,true,true,false,false,false,true,true,false,true,true,true]</rosparam>

<param name="odom0_differential" value="false"/>
<param name="imu0_differential" value="false"/>

<param name="odom0_relative" value="false"/>
<param name="imu0_relative" value="false"/>

<param name="imu0_remove_gravitational_acceleration" value="true"/>

<param name="print_diagnostics" value="true"/>

<param name="odom0_queue_size" value="10"/>
<param name="imu0_queue_size" value="10"/>

<param name="debug" value="false"/>
<param name="debug_out_file" value="debug.txt"/>

</node> 

<!-- ######################################   Kinect Bring up    ###################################### -->
<include file="$(find turtlebot_bringup)/launch/3dsensor.launch"/>

<!-- ######################################       Gmapping       ###################################### -->
<include file="$(find gmapping)/launch/gmapping_real.launch"/> 

<node pkg="rosbag" name="record" type="record" args="-O $(find autonomous_navigation)/src/data.bag /tf /scan /odom /odometry/filtered /mobile_base/sensors/imu_data"  />

OUTPUT FROM /ODOM TOPIC
header:  seq: 1650   stamp: 
    secs: 1475621890
    nsecs: 547252111   frame_id: odom child_frame_id: base_footprint pose:   pose: 
    position: 
      x: 0.0
      y: 0.0
      z: 0.0
    orientation: 
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0   covariance: [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7976931348623157e+308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7976931348623157e+308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7976931348623157e+308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2] twist:    twist: 
    linear: 
      x: 0.0
      y: 0.0
      z: 0.0
    angular: 
      x: 0.0
      y: 0.0
      z: 0.0   covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

OUTPUT FROM /ODOMETRY/FILTERED TOPIC
header: 
  seq: 1627
  stamp: 
    secs: 1475621911
    nsecs: 842503548
  frame_id: odom
child_frame_id: base_footprint
pose: 
  pose: 
    position: 
      x: 0.0
      y: 0.0
      z: 0.0
    orientation: 
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
  covariance: [2.7114388649166092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7114388649166092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2993134255839545e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.267956922382893e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.267956922382893e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007585541496240116]
twist: 
  twist: 
    linear: 
      x: 0.0
      y: 0.0
      z: 0.0
    angular: 
      x: 0.0
      y: 0.0
      z: 0.0
  covariance: [1.305441858742643e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.305441858742643e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.283322530806801e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1636776575304084e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1636776575304084e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03712041041276108

OUTPUT FROM /mobile_base/sensors/imu_data TOPIC
header: 
  seq: 3768
  stamp: 
    secs: 1475621932
    nsecs: 816497812
  frame_id: gyro_link
orientation: 
  x: 0.0
  y: 0.0
  z: 0.0
  w: 1.0
orientation_covariance: [1.7976931348623157e+308, 0.0, 0.0, 0.0, 1.7976931348623157e+308, 0.0, 0.0, 0.0, 0.05]
angular_velocity: 
  x: 0.0
  y: 0.0
  z: 0.0
angular_velocity_covariance: [1.7976931348623157e+308, 0.0, 0.0, 0.0, 1.7976931348623157e+308, 0.0, 0.0, 0.0, 0.05]
linear_acceleration: 
  x: 0.0
  y: 0.0
  z: 0.0
linear_acceleration_covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

OUTPUT I GOT WHEN I RAN THE BELOW  COMMAND
rosrun tf tf_echo /gyro_link /base_footprint

At time 1475621971.286
- Translation: [-0.056, -0.062, -0.030]
- Rotation: in Quaternion [0.000, 0.000, 0.000, 1.000]
            in RPY (radian) [0.000, -0.000, 0.000]
            in RPY (degree) [0.000, -0.000, 0.000]
At time 1475621971.686
- Translation: [-0.056, -0.062, -0.030]
- Rotation: in Quaternion [0.000, 0.000, 0.000, 1.000]
            in RPY (radian) [0.000, -0.000, 0.000]
            in RPY (degree) [0.000, -0.000, 0.000]
^CAt time 1475621972.486
- Translation: [-0.056, -0.062, -0.030]
- Rotation: in Quaternion [0.000, 0.000, 0.000, 1.000]
            in RPY (radian) [0.000, -0.000, 0.000]
            in RPY (degree) [0.000, -0.000, 0.000]

It seems like it is working, because filtered odometry is a little better tha raw odometry, but still it is not converging
Here is the rviz screen shot( red = raw odom, green = filtered odom)
.

Originally posted by krishna43 on ROS Answers with karma: 63 on 2016-09-20
Post score: 1

Original comments
Comment by krishna43 on 2016-10-03:
@Tom Moore Can you please look into this?
Comment by Tom Moore on 2016-10-04:
Did you fix your launch file? Can you please post it and a sample input message from each sensor? I still don't think your IMU is getting integrated.
Comment by krishna43 on 2016-10-04:
I added the requested info. Happy to provide if any additional info is required.
Comment by jerryzhchao on 2016-11-29:
@krishna43 Hi I am doing the similar experiment. However, I found the /odom in TF is always produced by the bag file but not the ekf node. So that make the estimation and the odom the same. I saw your TF tree is correct. Any suggestions?
Comment by rezenders on 2021-04-30:
@krishna43 did you have to set up the covariance values of the /odom topic?  The /odom readings I am getting with my turtlebot have 0 covariance.
I am trying to use turtlebot with robot_localization to fuse /odom with an IMU but the /odom and /odometry/filtered are overlaping, it looks like it is not being corrected by the imu. I am wondering if this 0 covariance may be the problem

A:

Here's your configuration:
<param name="imu0" value="mobile_base/sensors/Imu_data"/>
Here's the topic name in the bag file:
/mobile_base/sensors/imu_data
ROS topics are case-sensitive (see the capital I in the r_l config), so I'm guessing it's not subscribed.
rostopic info and rosnode info are useful tools for determining when nodes aren't receiving data from one another.
Also, your tf tree image is cut off, but make sure something is publishing the base_link->gyro_link transform.
EDIT 1 in response to update:
That plot looks like it may be correct. Just because you're fusing sensor data doesn't mean the output of that fusion will be perfect. There will still be drift over time, unless you fuse a source of pose data that is externally referenced, e.g., from amcl or a GPS. Also, you're fusing your magnetometer data from your IMU, which can be inaccurate. Go back to your original IMU configuration:
<rosparam param="imu0_config">[false, false, false, 
                               false, false, false, 
                               false, false, false, 
                               false, false, true,
                               false, false, false]</rosparam>

EDIT 2 in response to comments:
Tuning covariance can be a pain. A simple method for calculating variance is to drive your robot and have a means of ground-truthing the real value for that variable. For example, measure distances on the floor and lay down tape, then drive the robot. Look at the reported position and velocity, and compare that with the distance and velocity the robot actually drove. This is a bit naive and ignores off-diagonal correlations between variables in the covariance matrix, but seems to work well in practice. A less elegant method involves hand-tuning the values until the covariance matrix that is output by r_l grows at a realistic rate. There are much more sophisticated methods in the literature, but I think most users get good results using one of the two methods above.
The state estimation nodes in r_l will fuse data from any number of sensors, so long as they produce one of the supported message types. Since amcl can produce a PoseWithCovarianceStamped, its output can be fused into r_l. You might want to use a two-tier setup similar to the one suggested for integrating GPS if you go this route, as amcl poses may jump, so you wouldn't want to execute local path planner motions using that state estimate.

Originally posted by Tom Moore with karma: 13689 on 2016-10-04
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by krishna43 on 2016-10-09:
Thanks Tom, I will edit my launch files and do some testing again. Are there any certain steps that i can follow to tune co-variance matrices?
I have a question: If i have an external reference such as a per-built map, doesn't amcl package help me to localize the robot even there is drift in (1/2)
Comment by krishna43 on 2016-10-09:
odometry. So, how does using robot_localization package help if i already have a prior information (Map) of where the robot is. I though you can use it only when the robot doesn't know where it is.(2/2)
Comment by krishna43 on 2016-10-09:
That make sense. Thank you very much for spending your valuable time for providing valuable answer!
Comment by Tom Moore on 2016-10-10:
You're welcome, and I apologize for the delay in response.

