Q:

Why models are not perfect to represent robotic environments?

Sebastian Thrun says in his paper on Particle Filters that - no model however detailed fails to represent the complexity of even the simplest of robotic environment. What does he means by this? Can someone please elaborate?

A:

A model of the environment in this context is an abstraction of the real world, which should be adequate for the task of the robot. For example, if you have a robot that needs to navigate an office building, you can make the abstraction that your model only needs to be in two dimensions. Further, for the task of navigation you could discretize your space in a regular grid, and just model if cells of your grid are occupied by dense matter (e.g. walls, chairs, people) or by light matter (air) above the ground. This environment representation (model) is usually called a map. 
What Thrun refers to is likely that your model only records particular aspects of your environment. Its an abstraction. This is good, to make it manageable from a computational and representational aspect. However, and this is in my opinion the key of the statement, its limited in the real world. For the office building example given above, you can easily come up with examples where the models breaks. How do you represent for example a table. A robot of a certain height may actually go underneath. How do you represent the temporal aspects. A chair might be at another position at another time. All possible to manage, but you will always find exceptions to your chosen abstraction in the real world. 
Interesting in this context is for example the work from Brooks. He postulated to use the world itself as a model instead of a using abstractions that ultimately fail to represent the world adequately.

