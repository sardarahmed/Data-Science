
Supervised Learning

Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. 
It infers a function from labeled training data consisting of a set of training examples. In supervised learning, 
each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). 
A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. 
An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. 
This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way.
Types of supervised learning algorithms include Active learning, classification and regression.

### Active Learning
Active learning is a subfield of machine learning that focuses on reducing the number of labeled examples needed to
train a model. It is especially useful in cases where labeling data is expensive or time-consuming. In active learning,
the algorithm selects the most informative examples to label. The model is then trained on these examples, and the
process is repeated iteratively. By selecting the most informative examples, active learning can achieve high
performance with fewer labeled examples than traditional supervised learning.

### Classification  
Classification is a type of supervised learning algorithm that categorizes input data into two or more classes. The
goal of a classification algorithm is to accurately predict the category of a given input data point. Common
classification algorithms include logistic regression, support vector machines, and decision trees.

#logistic regression
Logistic regression is a classification algorithm used to predict the probability of a binary outcome. It is a type of
linear regression that uses a logistic function to model the relationship between the independent variables and the
dependent variable. Logistic regression is commonly used in binary classification problems, where the output variable
has two classes (e.g., yes/no, true/false).

#Support Vector Machine
Support Vector Machine (SVM) is a supervised learning algorithm used for classification tasks. It works by finding the
optimal hyperplane that separates the data into different classes. SVM is effective in high-dimensional spaces and is
widely used in text classification, image recognition, and bioinformatics.

#Decision Tree
Decision tree is a supervised learning algorithm used for classification and regression tasks. It works by recursively
splitting the data into subsets based on the value of a feature. The goal is to create a tree-like model that predicts
the target variable based on the input features. Decision trees are easy to interpret and can handle both numerical and
categorical data.



### Regression
Regression is a type of supervised learning algorithm that predicts continuous values. The goal of a regression
algorithm is to predict a continuous output value based on input data. Common regression algorithms include linear
regression, polynomial regression, and support vector regression.

#Linear Regression
Linear regression is a supervised learning algorithm used to predict a continuous output value based on input features.
It models the relationship between the independent variables and the dependent variable using a linear equation. The
goal of linear regression is to find the best-fit line that minimizes the sum of squared errors between the predicted
and actual values.

#Polynomial Regression
Polynomial regression is a type of regression algorithm that models the relationship between the independent variables
and the dependent variable as an nth-degree polynomial. It is used when the relationship between the variables is
nonlinear. Polynomial regression can capture complex patterns in the data but may be prone to overfitting.

#Support Vector Regression
Support Vector Regression (SVR) is a regression algorithm based on Support Vector Machines. It works by finding the
optimal hyperplane that minimizes the error between the predicted and actual values. SVR is effective in high-dimensional
spaces and can handle both linear and nonlinear relationships between the variables.

### Best fit line
Best fit line is the line that best represents the relationship between the independent and dependent variables.
