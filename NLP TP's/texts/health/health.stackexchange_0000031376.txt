Q:

Does this paper report miscalculated metrics?

During a literature search I stumbled upon this paper, which evaluated the diagnostic accuracy of ultrasonography for the detection of gallstones (compared to the gold standard cholecystectomy).
Their data looks as follows:

TP: 1549
FP: 274
FN: 0
TN: 46

According to wikipedia, sensitivity is calculated as TP / (TP + FN) and specificity as TN / (TN + FP). So if we plug in the numbers, we get:

Sensitivity = 1549 / (1549 + 0) = 1
Specificity = 46 / (46 + 274) = 0.14375

Yet in the abstract they state that they found a

sensitivity of 0.85 and a specificity of 1 for ultrasound in the
identification of gallstones

Is this just wrong or am I missing something? Would be glad if somebody could help!

A:

As the other answer points out, the authors here have clearly calculated the positive and negative predictive values (PPV and NPV) rather than sensitivity/specificity. They report these clearly in their results section, but everywhere else use the words sensitivity and specificity.
There is a reason that it might not make a lot of sense to consider sensitivity and specificity in this study. Those measures are meant to be real-world measures that are most meaningful when you consider them in light of actual prevalence.
However, look at prevalence here: only 320 people didn't have gallstones, and 1549 did! This is kind of ridiculous - about 80% of people have gallstones! How can this be? Well, the other problem with their study is that they're relying on a gold standard metric that simply isn't available for most people without gallstones.
Why? Their sample is people underwent laparoscopic cholecystectomy - they had their gallbladders removed. Specificity is always going to be terrible in this sort of selected group, because you're missing all the people who didn't have their gallbladders removed, most of whom likely would have been negative on the ultrasound.
My guess is that they calculated specificity and sensitivity to start, got numbers that didn't agree with the literature, and went to a statistician or colleague for an explanation. Someone told them that PPV and NPV are likely better measures for this particular situation, and they sloppily edited the paper without changing the other sections, perhaps because they didn't realize (or it was explained incorrectly to them) that these are actually different than sensitivity/specificity.
I'll note that based on their affiliations, the authors seem likely to be physicians. They probably have minimal training in research and statistics; it's possible one or both were even medical students when they wrote the paper.

