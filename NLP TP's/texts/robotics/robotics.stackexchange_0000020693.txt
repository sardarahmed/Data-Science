Q:

Setting up rewards to account for UAV crashes (Reinforcement Learning)

I am working on a project to implement a collision avoidance algorithm on a real UAV. I'm interested in understanding the process to set up a negative reward to account for scenarios wherein there is a UAV crash. This can be done very easily during simulation(if the UAV touches any object, the episode stops giving a negative reward). 
Any ideas will be highly appreciated.

A:

From what I understand this is quite easy and you don't have to use reinforcement   learning. You can also use standard ANNs.   
Algorithm:  
For as long as you want:
  If Touch (sensor. Maybe a button???) == 1
  Update network (the network should output the probability of crashing in the       next step. You can also use markov chains for multiple steps (just an idea))  
I hope this answers your question.

