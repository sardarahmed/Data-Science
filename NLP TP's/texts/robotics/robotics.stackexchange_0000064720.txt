Q:

Use data from IR sensor to build a costmap

Hi,
I'm working on Turtlebot2. I will use cover for my robot, so I moved Kinect to the front of the robot to make a smaller holes in cover. But now I have a blind area in front of the robot, between 0 and 45 cm. I decided to mount some IR sensors. I made transformation for (yet) only one sensor
#include <ros/ros.h>
#include <tf/transform_broadcaster.h>

int main(int argc, char** argv){
  ros::init(argc, argv, "irring_tf");
  ros::NodeHandle n;

  ros::Rate r(100);

  tf::TransformBroadcaster broadcaster;

  while(n.ok()){
    broadcaster.sendTransform(
      tf::StampedTransform(
        tf::Transform(tf::Quaternion(0, 0, 0, 1), tf::Vector3(0.135, 0.0, 0.2)),
        ros::Time::now(),"base_link", "base_irring"));
    r.sleep();
  }
}

next I receive data from sensor and publish it as a LaserScan message (I create two points from one sensor, because I will use this code for more sensors, in this case it is no matter)
    ros::Time scan_time = ros::Time::now(); 
    sensor_msgs::LaserScan scan;
    scan.header.stamp = scan_time;
    scan.header.frame_id = "base_irring";
    scan.angle_min = -0.05;     //rad
    scan.angle_max = 0.05;      //rad
    scan.angle_increment = 0.10 / num_readings;     //rad
    scan.time_increment = (1 / laser_frequency) / (num_readings);   //sec
    scan.range_min = 0.20;       //meters
    scan.range_max = 1.15;     //meters

    scan.ranges.resize(num_readings);
    scan.intensities.resize(num_readings);
    for(unsigned int i = 0; i < num_readings; ++i){
      scan.ranges[i] = atof(buf) / 100.0;   //data from arduino
//      scan.intensities[i] = 1; //data from arduino
    }

    scan_pub.publish(scan);

It works, I can visualize data in correct place using Rviz (white line is data from Kinect, red dots data are taken from IR sensor)
https://www.youtube.com/watch?v=woMNOnIB2bo&list=UUclHPTMTlaW_M55gYhp_ylQ
Next I want to use this data to build costmap, so I add to costmap_common_params.yaml my irring_scan, changed map_type from voxel to costmap (because I want to clear obstacles detected by IR sensors by Kinect, I want to use 2d map)
max_obstacle_height: 0.60  # assume something like an arm is mounted on top of the robot

# Obstacle Cost Shaping (http://wiki.ros.org/costmap_2d/hydro/inflation)
# robot_radius: 0.20  # distance a circular robot should be clear of the obstacle (kobuki: 0.18)
footprint: [[-0.25, 0.25], [0.25, 0.25], [0.25, -0.25], [-0.25, -0.25]]  # if the robot is not circular

map_type: costmap

obstacle_layer:
  enabled:              true
  max_obstacle_height:  0.6
  origin_z:             0.0
  z_resolution:         0.2
  z_voxels:             2
  unknown_threshold:    15
  mark_threshold:       0
  combination_method:   1
  track_unknown_space:  true    #true needed for disabling global path planning through unknown space
  obstacle_range: 2.5
  raytrace_range: 3.0
  origin_z: 0.0
  z_resolution: 0.2
  z_voxels: 2
  publish_voxel_map: false
  observation_sources:  scan bump irring_scan
  scan:
    data_type: LaserScan
    topic: scan
    marking: true
    clearing: true
    min_obstacle_height: 0.25
    max_obstacle_height: 0.35
  irring_scan:
    data_type: LaserScan
    sensor_frame: base_link
    topic: irring_scan
    marking: true
    clearing: true
    min_obstacle_height: 0.25
    max_obstacle_height: 0.35
  bump:
    data_type: PointCloud2
    topic: mobile_base/sensors/bumper_pointcloud
    marking: true
    clearing: false
    min_obstacle_height: 0.0
    max_obstacle_height: 0.15
  # for debugging only, let's you see the entire voxel grid

#cost_scaling_factor and inflation_radius were now moved to the inflation_layer ns
inflation_layer:
  enabled:              true
  cost_scaling_factor:  5.0  # exponential rate at which the obstacle cost drops off (default: 10)
  inflation_radius:     0.5  # max. distance from an obstacle at which costs are incurred for planning paths.

static_layer:
  enabled:              true

Next I changed in local_costmap_params.yaml from
name: obstacle_layer,      type: "costmap_2d::VoxelLayer"

to
name: obstacle_layer,      type: "costmap_2d::ObstacleLayer"

I did the same for global_costmap_params.yaml
But as you can see below

costmap is built only using data from Kinect, there is no obstacles marked around IR points.
I'll be very glad if you tell me what I should add, change or remove to get it working.
Edit:
Solution is to set z_voxels variable to 3, because we use 3 sources of data, not 2. You can also play with correct obstacle heights.

Originally posted by dawid.wolski on ROS Answers with karma: 3 on 2014-12-18
Post score: 0

Original comments
Comment by sobot on 2015-05-03:
Hi, so with regards to the "Edit", did you finally successfully implemented the mapping with IR sensor(s)? may i ask what IR sensors (make and model) did you use? im trying to practice the same implementation on my Turtlebot. Thanks!
Comment by dawid.wolski on 2015-06-10:
Hi, sorry for my late response, but now I'm not working with the robot. Yes, my mapping using IR sensors and other sensors works well. I use 9 Sharp GP2Y0A21YK or similar sensors. For me the most important parameter is the minimal range.

A:

Hi, we added both an IR ring and a sonar ring to the turtlebot. Code for the sonar ring using and Arduino Mega can be found here. I use Bosch drivers to interface with arduino. There's also code to read Sharp IR (is basically the same, apart that the sonars need to be triggered). And 3D models to nicely mount a ring on the TB2 can be downloaded here
Hope this helps.

Originally posted by jorge with karma: 2284 on 2015-06-10
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by sobot on 2015-06-17:
Thank you!
Comment by jorge on 2015-06-18:
I have changed the way I interact with the arduino, because as I read 15 sensors, using a Bosch driver for each one makes reading very slow. I have now wrote my own very simple arduino firmware that collects all data and send through serial port. The driver just read it at convert into ROS Range msg

