Q:

Path Planning in ROS

Hi,
I am currently working on a project that involves 2 external stereo cameras and a Parrot AR drone.
I wish to 3D map (in progress) and then plan a path, avoiding static obstacles, for the Parrot AR drone.
I have come across several options but am unable to find the correct one (based on above scenario) -

ROS Navigation stack - From what I have seen, it only makes sense to use this for moving robots with a kinect on them (note: Kinect has a small range). Hence this is NOT suitable for my use case. (Please correct me if I am wrong).
Open Motion Planning Library (OMPL) - It seems that RRT  (Rapidly exploring Random Tree) algorithm or it's modifications are being used in several places ( see this  example ) for path planning. I have heard that the library is hard to deal with, in terms of documentation, etc. Is that correct ? Are there other alternative libraries that might fit in nicely with Gazebo + ROS ?

Kindly provide
Thanks a lot !

Originally posted by malharjajoo on ROS Answers with karma: 121 on 2018-02-20
Post score: 0

A:

I don't see why the ROS Navigation stack should only be used with robots with a kinect. The most common usecase is actually having a robot with laser scanners. You can configure the costmap (this is where sensor data is used) the way you want, also specifiying a maximum range to use. So this should work for your use case as well. The question is rather if this is really suitable for 3D path planning (which I am assuming you want to do). IMO, the ROS navigation stack is mainly for 2D, though some experiments have been made with 3D. Googling led me to the two following links, which look promising: 1, 2 (please note though, that I personally don't have any experience there).

Personally, I have good experience with OMPL. However, I cannot judge was is considered "hard to deal with", as this is highly subjective, IMO. An alternative would be sbpl

Originally posted by mgruhler with karma: 12390 on 2018-02-20
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by malharjajoo on 2018-02-25:
Hi @mig, thank you for your help and advice. The 1st link (https://www.wilselby.com/research/ros-integration/3d-mapping-navigation/) you provided looks quite promising. However, most of the example use onboard sensors (kinect, laser,etc ).
Comment by malharjajoo on 2018-02-25:
My key concern is whether it's applicable to my use case. I am using 2-3 external stereo camera setup to provide the depth and point cloud map.
Comment by mgruhler on 2018-02-26:
So you don't have any onboard sensors? I assumed you do. Do you use the external Stereo sensors to track the position as well? You could still make that work, given that your drone (i.e. whereever the navigation happens) has access to the point clouds, a correct tf, as well the drone is filtered out
Comment by malharjajoo on 2018-02-26:
HI @mig, I am using the external stereo cameras to track 3D coordinates (using triangulation).
I am currently working on 3D mapping (if even possible to a good level using calibrated external stereo cameras). I don't have any sensors onboard the drone, only the built in ones (IMU, 2 cameras,etc)
Comment by malharjajoo on 2018-03-31:
Hi @mig, would you recommend using ROS moveit! framework ?
Comment by zubair on 2018-08-04:
ROS moveit seems to be working for laser scan and depth cameras, i am working with obstacle avoidance with mono cam and indeed do not want to scan the environment prior. In my opinion ROS moveit is not an option , although if someone knows any path planning tool for image_raw info it will be good

