Q:

How to split a recorded rosbag file?

Ubuntu 12.04 and fuerte
I have a bag file of 400 seconds length.
I would like to split it into two bag files of 150 seconds and 250 seconds.
There is an option to split bag files while recording using option --split, but now I already have a recorded one.
What can be done?
Thanks

Originally posted by sai on ROS Answers with karma: 1935 on 2013-11-10
Post score: 13

Original comments
Comment by jdlangs on 2013-11-11:
Is it not possible to just play back the bag and rerecord the topics using the --split option?

A:

My answer is pretty redundant coming three years late, but for anyone else who asks this another option is to use the rosbag filter command, e.g.
rosbag filter input.bag output.bag "t.secs <= 1284703931.86"  

You can use the standard greater-than-or-equal-to (>=) and less-than-or-qual-to (<=) operators to keep all data before or after your cutoff point. Keep in mind that ROS time-stamps each message with Unix time, rather than the time of the message relative to the start of the record. So you'll need to find the start and end times of your record and do a bit of basic math to find the 150 sec point.
For other filter commands, take a look at rosbag/Commandline

Originally posted by M@t with karma: 2327 on 2016-05-09
This answer was ACCEPTED on the original site
Post score: 35

Original comments
Comment by ubuntuslave on 2018-02-20:
I think the misleading part could be the use of seconds in this case because I believe the time-stamp is given in the computer's epoch time.
Comment by M@t on 2018-02-22:
Is Unix time and a computer's epoch time not one and the same?
Comment by KH - 219Design.com on 2018-07-13:
for bounding with a startpoint and an endpoint, the expression looks like this:
rosbag filter input.bag output.bag "t.secs >= 1531425960 and t.secs <= 1531426140"

Comment by max11gen on 2019-12-06:
Please consider changing t.secs to t.to_sec(), because your version will be rounded and if you need higher time precision, you will and up having some issues.
Comment by lukehutch on 2020-08-15:
Thanks @max11gen, I just ran into this exact issue.

