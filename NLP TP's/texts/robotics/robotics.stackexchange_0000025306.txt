Q:

performance: what hardware works best?

I have just installed drcsim1.0 on a machine with
Intel® Xeon(R) CPU 5160 @ 3.00GHz × 4,
3.9 GiB memory,
64-bit Ubuntu 12.04 LTS,
NVIDIA Corporation NV44 [Quadro NVS 285] (rev a1)
I get about 0.95 Real Time Factor at best (it varies) and the window keeps getting dark
and then light. Everything else I installed drcsim on got much worse Real Time Factors, but only greyed out and then brighted once (on startup).
What hardware should I buy (including CPU chip model and graphics card/GPU) to run Gazebo most effectively? How many cores, etc?
I think people would be interested in two answers:

Something that cost around $3000.
2) A cadillac that cost around $15,000

UPDATE: I changed the graphics card to a
NVIDIA Corporation G92 [GeForce 9800 GT] (rev a2)
Now I get a 0.97 Real Time Factor and the display has stopped darkening and brightening after
the first time.

Originally posted by cga on Gazebo Answers with karma: 223 on 2012-10-27
Post score: 0

A:

I don't think there will be much more than consensus on what hardware works "best", especially since gazebo isn't the only thing that affects how gazebo appears to operate. But I few would disagree the more cores the better (4+ might make most happy), as much ram as you can afford (4G RAM might makes most happy).. Check here for a conversation about graphics cards.. but remember that everyone's expectations/needs aren't the same..
The most important thing I think you should do, regardless of your hardware, is make sure your software plays nice.. and this include your window manager (eg. instead of unity, use gnome-session-fallback and then use classic no effects.... or use xfce).. also take a look at parameters like the near and far clip in your world files... and also pay attention to the other applications that you're running and their CPU utilization (especially if you're using less than 4 cores)..
If you're a ROS user you can tweak the rates of the other nodes that share the processor(s).
Finally, take the factor metric with a grain of salt.. in general simulation time is "squishy" and deriving the factor involves averaging over a window and then dividing by simulation time, by a sampling of real time, it's still a "squishy" metric. It's all we appear to have right now though..

Originally posted by SL Remy with karma: 319 on 2012-10-30
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by nkoenig on 2012-10-30:
This is a great answer. I'd like to add is that we are continually working on improving performance. For GPU's we recommend nvidia, which have worked much better in linux than ATI.

