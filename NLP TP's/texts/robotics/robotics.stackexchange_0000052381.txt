Q:

Turtlebot Laser Scan Error

I have a turtlebot 1 (create base) with groovy installed and ubuntu precise (12.04 LTS) on both the laptop and the workstation. After following through the tutorial I got stuck on the 3-d visualization portion. I am using a kinect camera and when I ran
roslaunch turtlebot_rviz_launchers view_robot.launch
The rviz program allows me to see the camera data correctly so I know the kinect is powered up. However the laser data gave me an error.
For frame [/camera_depth_frame]: No transform to fixed frame [/base_footprint]. TF error: [Lookup would require extrapolation into the future. Requested time 1372440640.091899911 but the latest data is at time 1372440636.899976015, when looking up transform from frame [/camera_depth_frame] to frame [/base_footprint]]
This was under the Transform [sender=/camera/camera_nodelet_manager]. Which was under status. I got Topic as ok and point as blank. The weird thing was the laser scan was working the run before and I was getting points being received but I couldn't get them to display anywhere.
I want to confirm the laser data was being read because when I ran the calibration I was getting Please find wall error. Reading around the site it seem that the issue may come from the laser data not working.
I also encountered this from time to time
Unhandled exception in thread started by
sys.excepthook is missing
lost sys.stderr
when running rviz, which would force close it either when I start up rviz and when I try to view the image from the camera. But it seem to fix itself when I close the terminal and rerun it.
The tutorial I used was:
http://ros.org/wiki/turtlebot_bringup/Tutorials/groovy/3D%20Visualisation
http://ros.org/wiki/turtlebot_bringup/Tutorials/groovy/TurtleBot%20Bringup   -> To change the laptop and workstation to the create base.
http://ros.org/wiki/turtlebot_calibration/Tutorials/Calibrate%20Odometry%20and%20Gyro  ->Stuck at step 3

Originally posted by req09 on ROS Answers with karma: 16 on 2013-06-28
Post score: 0

A:

The TurtleBot simulates laser data from the Kinect data.  To get laser data out you need to have the depth clouds coming in and then depthimage_to_laserscan running to generate the laser scan.  This does not run by default, but is turned on when youdo calibration and by the follower.  If you want to do a different demo or application make sure to include the launch file which turns on the depth camera and does the laser conversions.

Originally posted by tfoote with karma: 58457 on 2013-08-12
This answer was ACCEPTED on the original site
Post score: 0

