Q:

How can I check if the node is using cuda at run-time?

I have successfully built autoware.ai from source with CUDA enabled. The rosbag demo also runs properly.
My question is: will the node like lidar_euclidean_cluster_detect automatically utilize gpu so long as it compiled with cuda? Is there any way to check whether the node is using gpu at run-time? Thanks!

Originally posted by runtao on ROS Answers with karma: 27 on 2021-01-23
Post score: 0

A:

You can run nvidia-smi in your terminal and see what processes are using your gpu. Combine this with watch and you can get pseudo real-time resource usage. watch -n 1 nvidia-smi

Originally posted by Akhil Kurup with karma: 459 on 2021-01-24
This answer was ACCEPTED on the original site
Post score: 3

Original comments
Comment by RevatiNaik on 2021-02-11:
To confirm if your docker is compatible with GPU, run nvidia-docker run nvidia/cuda:10.0-base nvidia-smi.
Do this check only if you are using a docker to run your application.

