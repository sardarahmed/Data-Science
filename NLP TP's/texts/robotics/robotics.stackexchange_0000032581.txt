Q:

how to access old transforms tf

Let's say I have an algorithm that takes timestamped data and processes it, with the processing taking > 10 seconds. Not exactly blazing fast, I know, but for arguments sake let's say the code is well written and optimized :)
If the tf buffer is only set to 10 seconds, then publishing or listening to tf with the original timestamp will fail.
Is there a way to control the size of the tf buffer, or is tf not the tool for applying transforms in this case?
Has anybody else ran into this issue? I would not be surprised if this came up for the UCB clothes folding app.

Originally posted by phil0stine on ROS Answers with karma: 682 on 2011-06-27
Post score: 4

A:

You can indeed control the size of the tf buffer that your code uses. When creating the TransformListener, you can pass in a ros::Duration object that sets the length of the transform cache. See the TransformListener constructor docs for more info and the specific ordering of arguments and such.
This is assuming you are using the cpp version of the tf library. If you are using Python, feel free to examine the Code API for the Python version, as there is likely an analogous constructor for Python.

Originally posted by Eric Perko with karma: 8406 on 2011-06-27
This answer was ACCEPTED on the original site
Post score: 9

Original comments
Comment by Eric Perko on 2011-06-27:
Nope, no global cache. Each TransformListener instance maintains its own cache. It fills that by simply listening to the /tf topic.
Comment by phil0stine on 2011-06-27:
Thanks! This will help, although it reinforces the fact that I don't really understand how tf works. I would have guessed that there was a global cache that tf would use for all nodes in the environment, but actually each node stores its own tf cache?
Comment by zkytony on 2016-09-13:
Thanks tom temple!!!

