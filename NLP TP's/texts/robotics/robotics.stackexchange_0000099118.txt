Q:

Problem with reading point clouds

Dear community,
I have following problem while trying to convert PointCloud2 message to actual point cloud:
    points_list = list(pc2.read_points(msg, skip_nans=True, field_names=field_names))
  File "/opt/ros/noetic/lib/python3/dist-packages/sensor_msgs/point_cloud2.py", line 96, in read_points
    p = unpack_from(data, offset)
struct.error: unpack_from requires a buffer of at least 660022 bytes for unpacking 22 bytes at offset 660000 (actual buffer size is 660000)

I am running my nodes on server in Docker (unfortunately, I don't have opportunity to run them on server without Docker). To be more precise, I have two containers - one with Gazebo simulation from where the point clouds are published, and another one with training the agent which is subscribed on that topic. I use following keys when running both containers:
docker run --rm -it --gpus all --ipc=host --network=host
What is also strange is that previously everything was working well with same setting, and seems that there weren't any updates in server configuration. Also everything works well on my local machine with same running process with Docker. The version of the ROS is Noetic.
Does anyone have any ideas, where this problem can come from? Thank you in advance!

Originally posted by TimeEscaper on ROS Answers with karma: 16 on 2021-05-26
Post score: 0

Original comments
Comment by ruffsl on 2021-05-29:
Is the container running out of memory (RAM)? Encountering any new memory leaks perhaps?

A:

The problem was solved by complete re-building the image from scratch, with removing existing layers. I don't even know was it the problem with ROS or with Docker.

Originally posted by TimeEscaper with karma: 16 on 2021-05-29
This answer was ACCEPTED on the original site
Post score: 0

