Q:

How to do real time hand detection on Kinect V2/ROS

I am very new to Kinect V2 and ROS Indigo. I have installed libfreenect2 and iai_kinect2 from the GitHub pages. After running rostopic list I get a list of topics published by Kinect. I wrote a small code so that it subscribes to a specific topic and displays the camera i.e image_mono
file.py:
#!/usr/bin/python

import roslib
import rospy
import cv2
import sys
from std_msgs.msg import String
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

class PositionTracker:

    def __init__(self):
        # subscribe to kinect image messages
        self.sub = rospy.Subscriber("kinect2/qhd/image_mono", Image, self.image_callback, queue_size=1)
        self.bridge = CvBridge()

    def image_callback(self,data):
        try:
            cv_image = self.bridge.imgmsg_to_cv2(data)
        except CvBridgeError as e:
            print(e)
        cv2.imshow("Image window", cv_image)
        cv2.waitKey(3)

def main(args):
    ic = PositionTracker()
    rospy.init_node('kinect_tracker')
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main(sys.argv)

How do I perform real time hand detection and save data sets to a folder with the camera that was opened.
If I type, rostopic echo /kinect2/qhd/image_mono, it gives a 1D array. Any resource/tutorial will be really helpful.

Originally posted by hassanyf on ROS Answers with karma: 11 on 2018-01-18
Post score: 0

Original comments
Comment by PeteBlackerThe3rd on 2018-01-19:
Hand detection from RGB-D data is still an active area of research. This is a non-trivial question!

A:

Hello,
For real time hand pose detection I'd take a look at this code. It performs humand body (including hand) body tracking in real time. The software is based on the detection of keypoints on single images.
It has a C++ wrapper, so it is posible to used it with ROS, and it provides several different outputs.
https://github.com/CMU-Perceptual-Computing-Lab/openpose
Best,
David

Originally posted by dasanche with karma: 83 on 2018-01-20
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by jayess on 2018-01-20:
Can you please provide more details about why they should take a look at it?
Comment by dasanche on 2018-01-20:
Because that code performs humand body (including hand) body tracking in real time.
The software is based on the detection of keypoints on single images.
It has a C++ wrapper, so it is posible to used it with ROS, and it provides several different outputs.

