Q:

Will AIs ever be as advanced as the human brain?

I'm reading a book about a hypothetical economy in which robots work for us because they eventually became able to do everything we do ("Our work here is done, visions of a robot economy" by Nesta).
I was wondering though: is it theoretically possible for a human brain (an extremely complex  artificial intelligence the way I and many others see it) to comprehend itself in its deepest details and produce an artifical intelligence which is exactly identical? It sounds unlikely. If not then, how close can we get?
This is not a philosophic question, the ideal answer would be a rigorous demonstration based on metrics simplifying the problem to be able to answer it, however objective answers with valid arguments are always interesting, too.

A:

There are many things that humans can do that computers have never been able to do.
Every year people manage to get computers and robots to do something they have never done before.
Those builders and programmers are usually surprised at how much code and hardware it required to get it to work, and long it took to build and debug that code and hardware.

is it theoretically possible for a human brain ... to comprehend
  itself in its deepest details and produce an artificial intelligence
  which is exactly identical?

If you are asking if it's possible for a single human brain, simply through introspection, to figure out enough about what's going on inside to build an artificial intelligence that is exactly like that same single human brain (at some point in time), the answer is no.
We now know that human brains do a lot of work in the visual system and other areas that is completely inaccessible to conscious introspection.
However, the reason we know this is because there are other ways to learn something about what is going on in there.

If not then, how close can we get?

As of 2014, no one knows.
Many of the tasks that were once thought of as "higher-level" thinking can now be done by computers -- symbolic mathematics, chess, music composition, writing stories (a) (b), etc.
And yet -- many other tasks that were once thought of as "simple" still cannot be reliably done by computers -- distinguishing photos of cats from photos of dogs (c), much less remembering a human's name when seeing what that human's face looks like today (slightly older than any other time that human has ever been seen), etc.
I personally suspect that it is unlikely humans will build a machine that "thinks like a human", and even less likely that humans will build a machine that thinks like some particular human.
And yet I think it is very important for researchers to continue to try to do that, because -- whether they eventually discover some insurmountable barrier, or else (against my expectations) build a machine that actually does think like a human -- either way, I think we will find out some very interesting things about what it means to be human.
As a secondary benefit, it is a goal that is highly likely to, as a side effect, produce machines that will do other very useful things, long before the question is resolved one way or the other.

a small part of
"Navigating 50 years of philosophical debate -- Robert Horn's seven 'Can Computers Think?' debate maps"

