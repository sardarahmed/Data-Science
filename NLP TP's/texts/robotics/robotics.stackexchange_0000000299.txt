Q:

How can the inverse kinematics problem be solved?

The forward kinematics of a robot arm can be solved easily. We can represent each joint using Denavit–Hartenberg transformation matrices.
For example, if the $i^{th}$ joint is a linear actuator, it may have the transformation matrix:
$T_i = \left[\begin{matrix}
1&0&0&0\\
0&1&0&0\\
0&0&1&d_i\\
0&0&0&1
\end{matrix} \right]$
where the extension length is defined by $d_i$
whereas, a rotating link may be:
$T_i = \left[\begin{matrix}
1&0&0&L\\
0&\cos\alpha_i&-\sin\alpha_i&0\\
0&\sin\alpha_i&\cos\alpha_i&0\\
0&0&0&1
\end{matrix} \right]$ where $\alpha$ is the angle, and $L$ is the length of the link.
We can then find the position and orientation of the end effector by multiplying all the transformation matrices: $\prod{T_i}$.
The question is, how do we solve the inverse problem?
Mathematically, for a desired end effector position $M$, find the parameters $d_i$, $\alpha_i$ such that $\prod{T_i} = M$. What methods exist to solve this equation?

A:

Back in the day, when I was learning, making this up as I went along, I used simple gradient following to solve the IK problem.
In your model, you try rotating each joint each joint a tiny amount, see how much difference that makes to the end point position error. Having done that, you then rotate each joint by an amount proportional to the benefit it gives. Then you do that over and over again until you're close enough.
Generally, this is known as gradient following, or hill following. Imagine a robot arm with two degrees of freedom:

Rotating joint A a tiny bit moves the end point in direction a. Rotating joint B a tiny bit moves the end point in direction b.  Both of these move us closer to the target by about the same amount, so we should rotate both joints at about the same speed.
If we were to plot a graph of the distance to the target versus joint angles, it would look like this:

I have coloured in some contours just to help. We can see the path this algorithm takes. What you'll notice is that in joint space, the path taken does not look optimal. It takes a curve. However, in real space, you would see the end point taking a fairly straight line to the target. You can also see that there are actually two solutions to the problem, and the algorithm has just found the closest one.
This is not the only way to solve the inverse kinematics problem. It's certainly not the best way either.
Pros:

It's conceptually simple, so great if you're just learnig this.
It's easy to implement, even if the sight of Denavit–Hartenberg transformation matrices gives you the frights.
It's very general, allowing you to use all kinds of joints: rotary, linear, something else, as long as you can estimate how they cause the end point to move.
It copes well, even when there are zero or an infinite number of solutions. 

Cons:

It's slow, taking many iterations to find the solution. However, it's fine if you can just have the real arm follow the progress of the algorithm as it's calculated.
It can get stuck in local minima. I.E. It might not find the best possible solution, if it finds a good enough one.

There are more details about it on my very old web site: The good-looking textured light-sourced bouncy fun smart and stretchy page.

A:

There a number of solutions to this problem that center around the Jacobian Matrix. This slideshow covers the Jacobian methods and also mentions a Cyclic Coordinate Descent method, which I am unfamiliar with. 
There are a plethora of resources on the subject - if you ask google for "inverse kinematics Jacobian".
Also, check out Chapter 5.3 of the lecture notes from MIT's Open Course on Introductory Robotics.

