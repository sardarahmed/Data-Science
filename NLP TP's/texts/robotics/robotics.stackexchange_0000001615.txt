Q:

Why can Humans single out audio in a crowd? What would it take for a robot to do the same?

I was at a Robotics conference earlier today and one of the speakers mentioned robots not being able to function as well in a crowd because they can't single out audio like a person can.  
Why can people single out audio so well?  And what would it take for a robot to do the same?
I'm aware of Active Noise Reduction (ANR) like on Bose Aviation headset, but that is not what I'm talking about.  I am thinking about the ability to take everything in but process only what you feel is important. 

A:

What the speaker said at the conference was not accurate.  Perhaps they meant "our robot can't single out audio like a person can", but the statement "[robots] can't single out audio like a person can" is false.  
Here is a partial list of systems that can determine the source of an audio signal, and track it:

Conference phones (and many cell phones), with technique(s) described in papers this one
Gunfire locators
Underwater robots with towed microphone arrays, e.g. the AUV described in this paper
Mobile land-based robots

The term you're looking for is a "phased array" of microphones (see also: Matlab phased array toolbox).  NASA uses phased arrays to localize the noise coming from spinning rotor fan blades.

