Q:

How to select cameras for a stereo vision system?

I am in the process of building a stereo vision system to be used on a UGV. The system is for a robot that will be used in a competition wherein the robot is teleoperated to find relatively small colored rocks in a large outdoor field. I understand how to calibrate such a system and process the data for a stereo vision system. I do not however know how to select cameras for such a system. What are the best practices for picking cameras for a stereo vision system?

A:

Off the top of my head I would go by the following selection criteria

color/b&w - usually b&w is better, since the stereo algorithms only use one channel anyway
baseline - this really depends on the scene. With the baseline you control how much accuracy you get with distance. Wider baseline results in higher disparity values and thus less noise on the distance estimation. Higher baseline also means that you will get a reduced overlap between your field of views. Most importantly though, the wider the baseline the harder the matching between the two views. So the quality of the result goes down.
shutter - always use a global shutter for anything with computer vision on mobile robots
resolution - most stereo algorithms are computationally expensive. And you will likely not need that many 3d points. In the near field the sampling density is usually enough, and the far field your error from the low disparity is more of a problem than sampling density. 640x480 is fine in most cases. Some chips have a wider aspect ratio, which is favourable for the overlap, but you can get the same with using a sub-window of your chip.
lens/field of view - for mobile outdoor robots I prefer a wide field of view over narrow field of view. More or less for the same reasons as the resolution. Make sure your lenses are rigid and have a means to fixate any moving parts e.g. like adjustable focal length. In most cases a fixed focal length is fine anyway, since you are limited by the selection of your baseline.
trigger - when you create your own stereo rig, your cameras should support hardware trigger and ideally one should trigger the other.
framerate - In my opinion the least important consideration. Unless you have a lot of processing power you won't be getting much more than something like 5 Hz anyway. So your algorithm is much more likely to be the bottleneck, rather than the chip or the connection.
interface - Most cameras come with Firewire/USB2/USB3/Ethernet. USB2 is useless as it consumes a lot of CPU. Firewire is good if you have a port, but I think it seems to be on the decline in favour of USB3 these days. Didn't have much experience with USB3 yet. Ethernet is quite nice because you are more likely to find embedded systems with GigEthernet than USB3 at the moment.
housing - as rigid as possible. Recalibrating is an annoying procedure.

A:

A few things you should be on the lookout for:

Global shutter basically means all pixels get captured at the same time, as opposed to Rolling shutter where they are captured sequentially in a line scan fashion. Since your UGV will be moving around and performing stereo algorithms over the images you capture, it could be important that you avoid aberrations that occure when camera move, such as the ones seen in the pictures below (taken from Wikipedia):

Camera synchronization in hardware is achievable by some cameras, notably firewire cameras AFAIK. That can greatly improve the results for stereo when things are moving around.
Mounting should be done in a way that changes in the extrinsic parameters (the relative pose between cameras) for the stereo pair will be unlikely to change after calibration. In your rig that might be more important, since the UGV might face uneven terrain outdoors and things will vibrate.
Dedicated stereo hardware makes it possible to acquire disparity images directly as output of your stereo vision system, which eases the load off your embedded computing. It also tends to be much faster than running the very same algorithms in software.

As usual, the more you're willing to pay the better the results. To be honest, if you're able to buy a full-blown stereo camera such as the Bumblebee2, that's what I'd do. Otherwise, if you're on the cheaper side, I would simply go with a Kinect: it's unlikely you'll be able to get a system that outperforms it for the same price.

A:

You should start by calculating how many frames per second you need, and how much camera resolution you can process at that framerate.  If nothing else, that will prevent you from overspending or from buying a camera that won't suit your needs.  
Beyond that, there are a variety of features that make the choice more difficult/interesting.  Different cameras (especially network cameras like Axis) allow you to alter the image quality, or to specify a max bitrate for the image stream.  Some cameras also give you choices on the shutter speed, allowing you to favor a constant exposure time or a constant average illumination in the image.  Some cameras are more sensitive than others (the last time I worked with this was in 2009, and we noticed that the PS3 Eye did really well in low light conditions).  
Probably the best thing you can do would be to run your image processing algorithms on a few static images that you take with a DSLR, then attempt to reduce the frame size and quality to see where things begin to break down.  

