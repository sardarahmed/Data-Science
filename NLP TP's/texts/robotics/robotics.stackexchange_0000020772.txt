Q:

Where do matrix A and A transpose come from in calculating the predicted covariance matrix?

I don't understand where the matrices A and A transpose come from in the equation in this series. I have done a one-dimensional example in the series but I don't see how to derive these matrices in matrix form.

A:

The $A$ matrix (sometimes $F$) comes from your equations of motion. There's a technical example on Wikipedia that goes over modeling position and speed of a truck. 
You can model speed and position with the following equations:
$$
x = x_0 + \Delta t \dot{x} + \frac{1}{2}\Delta t^2 \ddot{x} \\
\dot{x} = \dot{x}_0 + \Delta t \ddot{x} \\
$$
Assuming your input $u$ is the acceleration ($u = \ddot{x}$), and being more explicit with the coefficients on everything, you could rewrite the above as:
$$
x = \left(1\right)x_0 + \left(\Delta t\right) \dot{x} + \left(\frac{1}{2}\Delta t^2\right) u \\
\dot{x} = \left(0\right)x_0 + \left(1\right)\dot{x}_0 + \left(\Delta t\right)u \\
$$
And then you convert to matrix form:
$$
\left[\begin{matrix}
x \\
\dot{x}\end{matrix}\right] = 
\left[\begin{matrix}
1 & \Delta t \\
0 & 1 \end{matrix}\right]
\left[\begin{matrix}
x_0 \\
\dot{x}_0 \end{matrix}\right] + \left[\begin{matrix}
\frac{1}{2}\Delta t^2 \\
\Delta t\end{matrix}\right]u
$$
The current sample being:
$$
x_k = \left[\begin{matrix}
x \\
\dot{x}\end{matrix}\right]
$$
and the previous sample being:
$$
x_{k-1} = \left[\begin{matrix}
x_0 \\
\dot{x}_0 \end{matrix}\right]
$$
You can then define your "state matrix" $A$ or $F$ as:
$$
A = 
\left[\begin{matrix}
1 & \Delta t \\
0 & 1 \end{matrix}\right]
$$
and your input matrix $B$ or $G$ as:
$$
B = \left[\begin{matrix}
\frac{1}{2}\Delta t^2 \\
\Delta t\end{matrix}\right]
$$
And so you have:
$$
x_k = Ax_{k-1} + Bu
$$
And then those are used with the output equations:
$$
y_k = Cx_k + Du
$$
to form the Kalman filter. These are all standard matrices from the state space representation of a system. 

