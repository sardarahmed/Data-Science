Q:

Robot_localization for fusing model pose and SLAM odometry

Hi there,
I'm using the robot_localization package for fusing several data inputs.
I have a theorical model that estimates an ideal odometry for my robot only based on my commands and the robot model. On the other hand, I have a SLAM estimation system as input for the EKF too.
My robot is a quadcopter and it has a yaw drift. I mean, its yaw value changes slowly over the time; and that is not registered by the theoretical model estimation. So model a slam orientation diverge very fast (in a minute or so).
With enough time, there would be even 90ยบ between their orientations, so it would be like one of them were not accomplishing the rep 103..
The question is: What would be the best way to fuse those estimations? Should I associate the "model yaw" to the estimated pose or is the EFK robust against orientation differences? Maybe I should do some reset of the theoretical pose estimated?
Thank you in advance,
Juan.

Originally posted by JSandu on ROS Answers with karma: 20 on 2018-04-04
Post score: 0

A:

Please see this section in the wiki. If I were you, I'd fuse the SLAM orientation as an absolute pose variable, and fuse the quadcopter yaw with differential set to true. That, or I'd make your quadcopter odometry message also produce velocities, and just fuse those instead.

Originally posted by Tom Moore with karma: 13689 on 2018-05-22
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by JSandu on 2018-10-01:
Thanks you so much Tom

