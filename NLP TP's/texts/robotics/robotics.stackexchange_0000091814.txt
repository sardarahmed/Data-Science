Q:

Multiple sensors using robot localization

Hello, currently i'm using an EKF from the robot localization package to generate the odom->base_link transformation. For this, i'm using three sources: wheels velocities, laser and visual. Since visual and laser approaches rely heavily on features my approach was to derive instantaneous velocities from two consecutive measurements in time (yea i know they can be noisy).
In this EKF i'm only using velocities so i don't have any reference for position, thus it seems like that my filter covariances for a two d mode starts to grow slowly for position (velocities are fine).
Besides all this, i never have jumps or nothing on my global EKF which takes this velocities from the first ekf and fuse them with a global estimator such as AMCL.
My questions are:

can the parameter dynamic process covariance help me in this case? Or
since i'm not relying on the state prediction (not feeding any dynamics to the my prediction stage) is generating this behaviors?
Or is just some issue with the integration from velocities to position?

I'm still very new on using and tuning Kalman Filters ;)
Thank you in advance.

Originally posted by tiagojdias on ROS Answers with karma: 16 on 2019-05-28
Post score: 0

Original comments
Comment by Tom Moore on 2019-06-06:
I'm not clear what the actual issue is. Are you trying to get the state estimate to jump/correct when you fuse it with AMCL data?
In any case, I can't comment at all unless you provide your full EKF configurations, as well as a sample sensor message for each sensor input.
I will say that you should not be fusing the output of one EKF into the second. Just fuse the same input sources in both.
Comment by Tom Moore on 2019-08-22:
Any update on this? If not, may I close the question?

A:

You can close the issue.
I was able to solve the problem after some tune on each sensor covariance.

Originally posted by tiagojdias with karma: 16 on 2019-08-25
This answer was ACCEPTED on the original site
Post score: 0

