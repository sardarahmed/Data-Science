Q:

Magabot ROS Integration

Hey all,
I've the following Arduino based educational robot:

magabot.cc

which comprises the following specs:

differential drive system w/ encoders on both wheels
2x front bumpers
5x sonar sensors on the front

And I'd like to integrate it with ROS environment. I've already put a laptop on top running ROS and communicating with the robot through rosserial Arduino package and now I'd like to setup it with the 2D Navigation Stack by adding a laser scanner.
While reading this tutorial - Setup and Configuration of the Navigation Stack on a Robot - some questions arise:

Which TF broadcasters should I implement? (I thought of a laser scanner TF + a Sonar TF (group or individual for each sensor?), maybe a bumper TF too?!)
How about odometer TF? Which kind of transformation is correct, since both wheels are paralell to the robot? Just translation? Or maybe rotation to?!
Should all TF broadcasting msgs be published by a single node or different nodes for each frame?!
Regarding sensors and particularly sonar, should I publish their information like a sensor_msgs/PointCloud or sensor_msgs/LaserScan?

Sorry for so many questions and thank you very much in advance. ;)

Originally posted by rflmota on ROS Answers with karma: 11 on 2013-11-25
Post score: 0

A:

Provide tf information for base_link to any sensor that you have connected. Depending on how far you'd like to go, writing an URDF might be easier (in that case robot_state_publisher will do tf for you).

Provide /odom -> /base_link which is the full pose (translation and rotation).

Does not matter.

Depends on what fits the sensor better. LaserScans will be interpreted as a range sensor with beams that are equally spaced (by angles) and provide measurements for all angles.

Originally posted by dornhege with karma: 31395 on 2013-11-25
This answer was ACCEPTED on the original site
Post score: 1

