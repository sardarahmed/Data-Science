Q:

People perception modules: detectors and trackers

Hello,
I am working on human-aware navigation and human-robot spatial interaction, therefore, I am looking into different people detectors. In our project we use a ROSyfied version of this detector: www.vision.rwth-aachen.de/publications/pdf/jafari-realtimergbdtracking-icra14.pdf which is based on RGB-D data, gives quite reasonable results, and will be made public soon. However, to enhance this detection I am currently looking for other people detection methods (like laser based leg detection) which I can combine with our tracker. Since the detection and tracking is not really part of my work I am looking for existing ROS packages that can be easily installed and trained.
Our set-up is comprised of hydro and Ubuntu 12.04 using a sick s300 and an asus xtion
So far I looked at David Lu's fork of the people_experimental: github.com/DLu/people stack, which apart from some compilation errors that are easy to fix, works out of the box but gives very bad results (only detects legs at distances <2m) which I think is because of the bad resolution of our laser (3cm in distance). Due to the non-existent or very well hidden documentation I have no idea how to retrain it with data collected from our robot. Any help on this would be greatly appreciated.
Almost all of the other perception algorithms I found or which are mentioned on this site are either not catkinized or are not available as a hydro package. My main question to the community would therefore be: What other people detectors are available for hydro?
Any hints and suggestions would be greatly appreciated.
I am sorry if that question has been asked already. I could only find one similar question which exclusively listed things that do not seem to exist for hydro. If there is a similar thread I would appreciate if you could refer me to it.
Cheers,
Christian
P.S.: Apparently my karma is insufficient to publish links. Sorry for the workaround.

Originally posted by Chrissi on ROS Answers with karma: 1642 on 2014-08-05
Post score: 1

Original comments
Comment by Dan Lazewatsky on 2014-08-05:
FYI, the leg detector from that fork has been merged into the main people repo, and is now available in the debs in hydro.
Comment by Chrissi on 2014-08-06:
Thanks Dan, I tried that as well but some of the launch files don't work (wrong paths to config files and included launch files) so I decided to check it out from github because that makes it easier to mend imo.
Do you know if there is a more detailed documentation on the usage of the leg_detector than this: http://wiki.ros.org/leg_detector?distro=hydro ?
Comment by Dan Lazewatsky on 2014-08-06:
If something isn't working, please submit a ticket in the issue tracker so we can get it fixed. I'm not aware of any more detailed documentation, but @David Lu might be able to help.
Comment by Chrissi on 2014-08-06:
Don't get me wrong, the leg_detector works fine. It is just some of the other components as discussed here: http://answers.ros.org/question/78026/problem-with-leg_detector-and-people_tracking_filter/
Comment by Dan Lazewatsky on 2014-08-06:
You said some of the launch files don't work - I was referring to that.
Comment by Chrissi on 2014-08-06:
Ah, OK. Sorry for the confusion. Never used the issue tracker. A link would be nice. Thanks.
Comment by Dan Lazewatsky on 2014-08-06:
https://github.com/wg-perception/people/issues/new

A:

https://github.com/spencer-project/spencer_people_tracking
This Github repository contains people and group detection and tracking components developed during the EU FP7 project SPENCER for 2D laser, camera and RGB-D data. As the project is still going on, new detection and tracking modules and documentation will still be added during the next 12 months.
Our laser detector (reimplementation of the boosted classifier using laser segment features from Arras et al., ICRA'07) is trained on data from an LMS 200 and LMS 500 at around 70 cm height above ground, and it works at ranges up to 15-20 meters, though precision drops at larger distances.
In general, detection results are of course much better when visual data is available (esp. in complex environments). We have also integrated the upper-body RGB-D detector and groundHOG detectors by RWTH Aachen by Jafari et al. mentioned in the original question, as well as the RGB-D people detector from PCL.
All components are tested on ROS Hydro and Indigo. There is also a set of reusable RViz plugins for visualizing the outputs of the perception pipeline.

Originally posted by timm with karma: 376 on 2015-04-10
This answer was ACCEPTED on the original site
Post score: 3

