Q:

Node Agent texplore "killed", using reinforcement learning pkg

Hi, I using ROS fuerte, ubuntu 11.10 and I am testing the RL pkg. I am runing texplore as option for the agent node and I have been tried to run different environmens but the node is killed before one or two episodes. Below I attach the terminal ouput of the agent node, this is run with mcar stocastic environment.
I have tried with car72, car27, carranddom, mcar, and several planners and models with the same problem.
Thanks.
agent: 

texplore
model: M5 Tree
planner: Parallel Real-Valued UCT
[ INFO] [1363138771.925508025]: RLAgent: starting main loop
Agent: Model Based
Agent: Model Based
feature 0 has range 1.8
feature 1 has range 0.14
reward range: 1
Parallel ETUCT tracking real state values
Planner using history size: 0
Start model learning thread
start parallel uct planning search thread
Created MultClass 0 with nModels: 5, addNoise: 0
Created m5 decision tree 0 multivariate regression (all feats) MIN_SDR: 0.00018
Created m5 decision tree 6 multivariate regression (all feats) MIN_SDR: 0.00018
Created m5 decision tree 12 multivariate regression (all feats) MIN_SDR: 0.00018
Created m5 decision tree 18 multivariate regression (all feats) MIN_SDR: 0.00018
Created m5 decision tree 24 multivariate regression (all feats) MIN_SDR: 0.00018
Created MultClass 2 with nModels: 5, addNoise: 0
Created m5 decision tree 2 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 8 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 14 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 20 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 26 multivariate regression (all feats) MIN_SDR: 0.0001
Created MultClass 3 with nModels: 5, addNoise: 0
Created m5 decision tree 3 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 9 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 15 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 21 multivariate regression (all feats) MIN_SDR: 0.0001
Created m5 decision tree 27 multivariate regression (all feats) MIN_SDR: 0.0001
Created MultClass 1 with nModels: 5, addNoise: 0
Created m5 decision tree 1 multivariate regression (all feats) MIN_SDR: 1.4e-05
Created m5 decision tree 7 multivariate regression (all feats) MIN_SDR: 1.4e-05
Created m5 decision tree 13 multivariate regression (all feats) MIN_SDR: 1.4e-05
Created m5 decision tree 19 multivariate regression (all feats) MIN_SDR: 1.4e-05
Created m5 decision tree 25 multivariate regression (all feats) MIN_SDR: 1.4e-05
Episode 0 reward: -44
Killed
dlf@dlf-Satellite-L745:~/fuerte_workspace/sandbox/rl-texplore-ros-pkg/stacks/reinforcement_learning/rl_env$

Originally posted by LeonardoLeottau on ROS Answers with karma: 58 on 2013-03-12
Post score: 0

A:

Hi,
It would help to see what command(s) you used to start the experiment.
My guess would be its because you need to provide a discretization for the value function in these continuous domains. You can do that with --nstates x option to discretize each dimension into x discrete states for the value function. On mountain car, I believe --nstates 10 or --nstates 20 work well. You can try this, or you can also try running an experiment on a discrete task such as taxi or tworooms and see how those go.
-Todd

Originally posted by toddhester with karma: 26 on 2013-03-13
This answer was ACCEPTED on the original site
Post score: 0

