Q:

Sensor bridge runtime framework

I'm currently using LGSVL and trying to implement ROS and YOLO there. What does the sensor bridge runtime framework mean?

A:

I am going to be a little indirect as it appears you are new to ROS and robotics (the unknown-unknowns paradigm).
You have not specified what sensor bridge you are talking about, so I am assuming you mean the ROS sensor bridge (and its associated packages).
Ros is simply a collection of C++ and python packages to connect sensors or computers together. In other words, ROS is just a glue framework to make things talk to each other that normally don't talk to each other. The sensor bridge is simply a metapackage that contains ROS messages for transporting data relating to sensors, like IMUs, lidars, stereocameras, etc.
If I had to guess, what you mean to do is take a camera input video stream from a ROS node, send the image to YOLO (inside of your ROS node or through another ROS node), and then take the resultant classification from YOLO and change the state of your simulation. ROS has the image_transport package to handle sending images between ROS nodes. This is as much as I can say with the minimal information provided as well as the broad nature of the question.

