Q:

Integrating an IMU with rtabmap

My rtabmap is having a very hard time with keeping track of orientation during both localization and mapping. I'm wondering if there is any easy way to feed in IMU data so that the direction of gravity can help orient the images and produce better results. That is, I'm wondering if I can associate orientation data with every frame such that it improves rtabmap's SLAM capabilities.

Originally posted by natejgardner on ROS Answers with karma: 36 on 2016-11-14
Post score: 0

A:

Related topics:

http://answers.ros.org/question/221103/combine-imu-with-visual-odometry-using-rtabmap/
http://answers.ros.org/question/242417/sensor-fusion-of-imu-and-asus-for-rtab-map-with-robot_localization/
http://answers.ros.org/question/239646/build-a-map-with-husky-laser-and-kinectrealsense/

As mentioned in one of these posts,  robot_localization package could be used to do a loosely sensor fusion of IMU and visual odometry. The launch file sensor_fusion.launch is a simple example combining Kinect+IMU with rtabmap.
cheers

Originally posted by matlabbe with karma: 6409 on 2016-11-15
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by Danilo_BR on 2017-11-14:
HI! I was just checking this sensor_fusion.launch and is it correct to assume that it is just combining position information from odom0 and orientation information from imu0 (if argument imu_ignore_acc is set)? wouldnt be better to set true the orientation parameters of odom0_config? rookie question
Comment by matlabbe on 2017-11-14:
1-Yes. 2-It depends: covariance should be carefully tuned if you want to fuse orientations of both sensors. The example is like assuming that IMU orientation covariance is a lot smaller than vo.

