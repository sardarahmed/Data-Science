Q:

performance of VSLAM

Hello all,
Does anybody know why the VSLAM node in ROS doesn't perform too well when the robot is not moving exceptionally slow or while it takes a sharp turn?
I know there are some limitations to using images to determine position and generating a map.. but if someone could pinpoint the exact shortcomings to the algorithm used in the VLSAM package (or at least tell me what algorithm has been followed in this case), it would be reallly helpful!
I am new to SLAM and ROS.. this may be a very silly question, but it'd really help me learn!
Thanks!
Divya

Originally posted by Divya on ROS Answers with karma: 46 on 2011-11-17
Post score: 1

A:

When the camera is moving quickly (particularly when it's rotating), every stage of VSLAM gets harder. It's harder to extract features, because of camera blur. It's harder to match features, because it's hard to initialize well, and because the viewpoint has changed, fouling up which features are visible. The geometric constraints that can help start to fall apart in the monocular case with rotations.
In general, VSLAM (and monocular VSLAM in particular) are very tricky; one of the reasons the VSLAM package isn't getting attention is because it's very, very hard to make VSLAM systems work reliably for everyone; a package that works great on a PR2, in a particular environment, may need to be re-tuned arbitrarily for your robot in your building; this just isn't something where general-purpose code that Just Works (or even Sorta Just Kinda Works) can be shipped.

Originally posted by Mac with karma: 4119 on 2011-11-18
This answer was ACCEPTED on the original site
Post score: 4

