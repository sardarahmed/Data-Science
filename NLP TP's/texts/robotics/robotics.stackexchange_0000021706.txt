Q:

What is the Point of Monocular SLAM

I am not a V-SLAM expert yet, but as far as I understand with monocular V-SLAM there is a scale ambiguity introduced by the fact that a camera essentially is an azimuth sensor that maps the 3D world to the 2D world via a projectivity.
In particular I was reading/using orb_slam_2_ros and came across the following:

This is the ROS implementation of the ORB-SLAM2 real-time SLAM library for Monocular, Stereo and RGB-D cameras that computes the camera trajectory and a sparse 3D reconstruction (in the stereo and RGB-D case with true scale).

So my question is, from a practical perspective, if with monocular SLAM you don't have "true scale" then what is the point, what useful information would monocular V-SLAM give to a mobile robot trying to localize in a space?
Thanks!
Cheers

A:

I would say true scale actually doesn't really matter. A good way to reason about this is actually video games. If you play a racing game(or really any kind of 3D game) do you care that the world has the proper scale? No you don't. If I went in and modified the video game to double the size/scale of all the models you would still be able to play it.
So it is possible to setup your system to navigate a world without knowing the true scale. It is what you do when you play a video game. A SLAM map still has a use in this world as it can be used to localize your position/build a map.
The reason true scale is used in the real world is that it unifys the units of your other sensors, and devices like motors,encoders,... . E.g. if your motors makes you move 1 m/s you know exactly how it will interact with some other sensor.
The are other tasks you can do that also don't require knowing the scale e.g. 3D reconstruction or structure from motion(computer vision terminology for monocular SLAM). We only care about the quality of the 3D reconstruction. The scale doesn't really matter. This scaleless 3D model can then be used in things like video games, 3D printing, and more which all don't care about the final scale of the model. If you do need true scale, you can also always scale it later to the correct size. E.g I know this object is 1 meter tall so scale the whole scene by the appropriate amount.
If you do need scale then another alternative is to is to fuse the monocular SLAM results in a loosely coupled fashion with an IMU or other sensor. So your SLAM algorithm may not be aware of the true scale, but your fused estimator algorithm is. A lot of of visual SLAM work on drones, was implemented this way before tightly coupled implementation became the standard.
Finally I would argue the lack of true scale is not the main problem of monocular SLAM algorithms, it is scale drift. As long as your map has the same consistent scale then everything works out. Problems start to occur when different parts of the map have different scales. This means reasoning in one area doesn't work in another.

