Q:

Alternatives to Finite State Machines (FSM's)?

In Udacity's Self-Driving Car Engineer online course, one instructor claims that "[Finite State Machines are] not necessarily the most common [approach for behavior planning] anymore, for reasons we will discuss later." I suppose the later assertions that FSM's are easily abused and become harder to understand and maintain as the state set increases amount for the "reasons", but we're never told what's used in its place.
I have been using FSM's for years, mostly for parsing-related problems in enterprise systems programming, but more recently for behavior planning problems. In my experience they're great for breaking down complex problems into manageable parts, not only when modelling but also in implementation – I usually implement each state as a separate class or function, allowing me to concentrate on the respective behavior and transition rules in relative isolation to the rest of the architecture.
That's why I find it frustrating that the lesson failed to discuss what is currently used instead of FSM's for behavior modelling: if a better approach exists for keeping track of a system's context and adjusting its behavior in response, I'm yet to hear of it, and I'd very much like to.

A:

Both FSM's and optimization approaches such as MPC will suffer as scenario constraints multiply. While at first glance FSM's may seem better suited to handle the increased complexity, in practice the interaction between different transition rules can quickly become difficult to track. This is most clear in the case of the so-called Zeno phenomenon, where a hybrid (FSM-based) controller repeatedly switches between states. Similarly, approaches based on optimizing a cost function can descend into "weight-tuning Hell", where increasing the weight of one objective has detrimental effects on another.
In either case the problem is not so much with the approach itself, but with taking a "flat" view of robot navigation, a problem that is hierarchical in nature. Instead of trying to satisfy every constraint at the same level of abstraction, modern navigation architectures divide them among a stack of modules:

Router: find a route from the current robot location to a desired destination, satisfying environmental constraints (keep to driveable roads, respect direction of traffic, etc.) and maximizing optimality metrics (distance traveled, fuel consumption, etc.);
Planner: Find paths that keep the robot advancing alongside the planned route, while also avoiding unexpected obstacles;
Kinematic controller: compute velocities that drive the robot forward alongside the planner path;
Dynamic controller: compute actuator commands that match the velocities generated by the kinematic controller.

In an architecture such as this "discrete" decisions are taken at the inter-module level — for example, the planner could report failure searching a path around an obstacle, prompting the router to generate an alternative route — while "continuous" policies are enforced at the intra-module level. In this latter case optimization-based approaches do have an edge over FSM's, as the former are fundamentally better at handling continuous domains.
That said, navigation systems based on Linear Temporal Logic (LTL) have successfully enabled discrete logic planning to be applied in continuous domains. LTL is a step up from FSM's, but still an appealing alternative for describing complex navigation objectives in a more human-readable form.

