Q:

empty frame_id when converting sensor_msgs/PointCloud2 to sensor_msgs/Image

Hi,
I am using iai_kinect2(ROS Indigo and Ubuntu 14.04) to get a depth cloud from my Kinect2  in the form sensor_msgs/Image. Then, it is converted to sensor_msgs/PointCloud2 using depth_image_proc to do all the filtering operations using pcl. Finally, I want to convert the filtered point_cloud back to sensor_msgs/Image and for that, I am using pcl_ros/CloudToImage to get sensor_msgs/Image (on topic /kinect2/filtered_image). It compiled properly but during run time, when I try to visualize it in RVIZ, I get the following :
MessageFilter [target=kinect2_link ]: Discarding message from [unknown_publisher] due to empty frame_id.  This message will only print once.

When I do rostopic echo /kinect2/filtered_image, I get:
header: 
  seq: 2139
  stamp: 
    secs: 0
    nsecs: 0
  frame_id: ''
height: 1
width: 68227
encoding: bgr8
is_bigendian: 0
step: 204681
data: [0, 0, 181, 209, 216, 179, 207, 214, 179, 207, 214, 0, 0, 0, 175, 204, 211, 176, 205, 212, 176, 205, 210, 177, 206, 211, 0, 0, 0, 0, 0, 0, 179, 207, 214, 179, 208, 215, 181, 210, 217, 0, 0, 0, 178, 207, 214, 179, 208, 215, 180, 209, 216, 175, 204, 209, 175, 205, 210, 174, 203, 210, 0, 0, 0, 174, 203, 210, 175, 204, 211, 174, 203, 210, 176, 204, 211, 177, 205, 212, 0, 0, 0, 178, 207, 212, 180, 209, 214, 178, 206, 213, 179, 208, 215, 177, 209, 215, 0, 0, 0, 0, 0, 0, 0, 0, 0, 180, 209, 216, 174, 203, 208, 174, 203, 208, 176, 205, 210, 174, 203, 208, 175, 204, 209, 175, 205, 210, 175, 205, 210, 175, 204, 211, 175, 204, 211, 173, 205, 211, 172, 204, 210, 173, 205, 211, 173, 205, 211, 176, 205, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 179, 208, 215, 171, 203, 209, ....... ]

It looks like there is some problem here. It does not have any time stamp or frame_id. Also, the encoding is bgr8, shouldn't it be 16UC1?
EDIT :
As suggested in the answer, after copying the header from the input point cloud into the image and then if I visualize the published image in RVIZ, I get the following issue and RVIZ shuts down :
[ WARN] [1451938112.487114384]: OGRE EXCEPTION(3:RenderingAPIException): Zero sized texture surface on texture ROSImageTexture0 face 0 mipmap 0. Probably, the GL driver refused to create the texture. in GLTexture::_createSurfaceList at /build/buildd/ogre-1.8-1.8.1+dfsg/RenderSystems/GL/src/OgreGLTexture.cpp (line 420)
Qt has caught an exception thrown from an event handler. Throwing
exceptions from an event handler is not supported in Qt. You must
reimplement QApplication::notify() and catch all exceptions there.

terminate called after throwing an instance of 'Ogre::RenderingAPIException'
  what():  OGRE EXCEPTION(3:RenderingAPIException): Zero sized texture surface on texture ROSImageTexture0 face 0 mipmap 0. Probably, the GL driver refused to create the texture. in GLTexture::_createSurfaceList at /build/buildd/ogre-1.8-1.8.1+dfsg/RenderSystems/GL/src/OgreGLTexture.cpp (line 420)
Aborted (core dumped) 

Does anyone have any idea why is this happening? Any suggestions will be helpful.
Thanks in advance.
Naman Kumar

Originally posted by Naman on ROS Answers with karma: 1464 on 2016-01-04
Post score: 0

A:

From the CloudToImage page:

Given a dense cloud, you can efficiently grab the rgb image from it as a sensor_msgs::Image

The CloudToImage example is expecting a colored point cloud, and is trying to extract the RGB image from it; not the depth image. This is why you're getting an RGB image.
It looks like the missing frame and timestamp is a separate issue. Perhaps pcl::toROSMsg() isn't preserving header information as it should. This is probably a bug in pcl_conversions, but you can work around it by copying the header from your input point cloud to the final image before you publish it.

Originally posted by ahendrix with karma: 47576 on 2016-01-04
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by Naman on 2016-01-04:
Thanks @ahendrix! Yes, I am giving Color Point cloud. Is there a way to get the depth_image in the form sensor_msgs/Image from the dense Point Cloud? I want to use it with depthimage_to_laserscan. Also regarding your second part of the answer, I have updated the original question. TIA!
Comment by ahendrix on 2016-01-04:
I'm sure you can reconstruct a depth image from a point cloud, but I haven't done it myself, so I'm not sure where to start. You may also want to look into the pointcloud_to_laserscan package, and avoid the need to convert back to a depth image.
Comment by ahendrix on 2016-01-04:
I'm not sure why rviz is crashing. Are you trying to display an RGB image in a depth image display or something weird like that?
Comment by Naman on 2016-01-04:
Yes.. I have looked into pointcloud_to_laserscan package but my only concern with that is it might be less efficient than depthimage_to_laserscan but again I am not sure how efficient it will be to generate depth image from a point cloud.

