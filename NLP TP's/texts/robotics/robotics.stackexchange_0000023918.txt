Q:

Calculating the depth in a general stereo vision system

When calculating the depth of a pixel using two cameras, most of the literature I have read describes stereo vision with the cameras having parallel optical axis as shown in the picture below. Because of similar triangles, the depth Z can be calculated as
Z = (f * B) / (x_l - x_r)

What if the cameras are rotated as in the following picture? How can I calculate the depth then?

A:

The complete mathematics for this are a bit tricky, as they work in 4D space, with homography projections.
In a practical sense, you can use the following functions from OpenCV library:

stereoCalibrate() to calculate calibration matrices for both cameras, as well as the relationship between them.
stereoRectify() to convert the images, using the data calculated with stereoCalibrate(), into an equivalent pair of images but with the configuration shown in your first picture. From that you can easily triangulate points position.

https://docs.opencv.org/4.8.0/d9/d0c/group__calib3d.html#ga617b1685d4059c6040827800e72ad2b6
OpenCV also provides for functions to directly convert to 3D any pair of 3D points, given a calibrated system.
Finally, there are lots of nice tutorials explaining the complete pipeline for stereo reconstruction, like this one I found with a bit of googling:
https://temugeb.github.io/opencv/python/2021/02/02/stereo-camera-calibration-and-triangulation.html

