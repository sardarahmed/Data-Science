Q:

streaming pointcloud to remote workstation

Hello,
I am trying to use pointcloud generated by a robot on remote workstation. However, I figured that susbscribing pointcloud2 is eating too much bandwidth.
Could anybody teach me what is the best way to get pointcloud data from a robot and use it on the remote workstation?
My current idea is instead of subscribing pointcloud2 data directly, setting up compressed version of pointcloud_xyzrgb image_pipeline on the remote workstation and re-produce pointcloud2 data.
Thanks,
Jihoon

Originally posted by jihoonl on ROS Answers with karma: 634 on 2013-06-11
Post score: 0

A:

In our setup, we've split the openni_launch-launch-file into two separate launch-files:

The one running on the machine which is connected to the kinect (in your case: on the robot) only loads the driver and publishes raw images and the tf-data
On a remote machine, image_proc is launched which calculates and publishes the actual point clouds

This way, only the raw 2d data (depth/image_raw, rgb/image_raw) is transmitted over the network.

Originally posted by Philip with karma: 990 on 2013-06-11
This answer was ACCEPTED on the original site
Post score: 0

Original comments
Comment by jihoonl on 2013-06-11:
Looks good thanks! Have you tried compressed image_transport too?
Comment by Ben_S on 2013-06-12:
Would it be possible to post your splitted launch files? Thanks! :)
Comment by jihoonl on 2013-06-12:
I have similar but a little different launch file created for turtlebot pointcloud streaming. Please refer this.https://gist.github.com/jihoonl/5770238

