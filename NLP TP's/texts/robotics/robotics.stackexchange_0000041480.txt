Q:

Point Cloud SLAM without RGB Information

Hi all,
As far as I understand, RGBD SLAM uses visual features in addition to the point cloud to perform SLAM. If I use a tilting LRF, which has high resolution and range than a kinect, can I use RGBD SLAM package (probably with some modification) to do just point cloud SLAM without using any visual features?
Thanks in advance
CS

Originally posted by ChickenSoup on ROS Answers with karma: 387 on 2012-06-19
Post score: 1

A:

Yes and No. You could disable Features by sending a blank depth image and enable GICP to estimate the motion, but GICP is not used for finding large loop closures, since the convergence of ICP does not necessary mean you are matching the same scene. This problem is of course less pronounced with the FOV of a LRF.
A good way to go would be to extract 3D features (NARF, Spin Images) and match these. But RGBDSLAM doesn't to this, so you would need to modify it on the source code level.

Originally posted by Felix Endres with karma: 6468 on 2012-06-19
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by ChickenSoup on 2012-06-19:
Thanks @Felix Endres. I will go through the RGBDSLAM code and try to modify as you suggested.
Comment by Felix Endres on 2012-06-19:
If you want to replace the visual features with 3d features, the easiest way should be to add a new callback to openni_listener for a point_cloud (or depth image and camera_info) and then modify the Node class to your needs.
Comment by ChickenSoup on 2012-06-19:
I see. Thanks for the tip. @Felix Endres
Comment by chukcha2 on 2016-02-17:
@peshala, were you able to modify RGBD SLAM to use just your laser range finder?
Comment by ChickenSoup on 2016-02-18:
@chukcha2 no i did not use RGBD SLAM after all.

