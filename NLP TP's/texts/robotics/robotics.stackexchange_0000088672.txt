Q:

robot_pose_ekf visual odometry

Hi all, I am working on a project which runs SLAM (RTAB map) on an autonomous land rover. The rover is equipped with a real sense D415 camera, a wheel odometry system and Pixhawk. We have been using robot_pose_efk to fuse the wheel odometry and IMU measurements. Since we have the real sense camera and the robot_pose_efk, which takes visual odometry message, I am wondering if it would be worth feeding the visual odometry into the robot_pose_efk in terms of computation point of view? (the RTAB mapping is already using the topics from real sense camera).
If it is worth it to incorporate the camera into robot_pose_efk, how do I publish the /vo topic using the D415 camera? my robot_pose_efk launch file is shown as below. Thanks
<launch>
   <node pkg="robot_pose_ekf" type="robot_pose_ekf" name="robot_pose_ekf">
      <param name="output_frame" value="odom_combined"/>
      <param name="base_footprint_frame" value="base_footprint"/>
      <param name="freq" value="30.0"/>
      <param name="sensor_timeout" value="1.0"/>  
      <param name="odom_used" value="true"/>
      <param name="imu_used" value="true"/>
      <param name="vo_used" value="false"/>
      <remap from="mavros/imu/data" to="imu_data" />
   </node>
</launch>

Originally posted by buckbuck on ROS Answers with karma: 3 on 2018-08-22
Post score: 0

A:

AFAIK, the visual odometry portion of robot_pose_ekf is not really used by anyone, and is probably poorly tested. You might also want to look at robot_localization package which is way better documented, and also since we have dropped support for robot_pose_ekf in Melodic (it is not released into debians).

Originally posted by fergs with karma: 13902 on 2018-08-23
This answer was ACCEPTED on the original site
Post score: 2

