Q:

Simulated kinect rotation around X [bug?]

Hi,
In our robot, the Kinect can be mounted on the side of the arm, as shown in the screenshot below. When running the simulation in Fuerte, I found this weird behaviour. As you can observe on the image, the point cloud does not match the robot model (we see a partial image of the hand/arm at the bottom left of the screenshot, which should be on the robot model).

As soon as I rotate the kinect against its X axis (so that the kinect is horizontal as you can see on the second screenshot), then the point cloud and robot model are aligned properly.

The kinect xacro and dae are the one from the turtlebot. I'm simply attaching them with a rotation:
<joint name="base_camera_joint" type="fixed">
  <origin  xyz="0.01216 0.1713 0.433"
       rpy="-${M_PI/2} ${M_PI/4} -${M_PI/12}" /> 
  <!-- This -pi/2 in origin rpy is the offending parameter -->

  <parent link="shadowarm_trunk"/>
  <child link="camera_link" />
</joint>

The code can be seen on github.
Any help is greatly appreciated!

Originally posted by Ugo on ROS Answers with karma: 1620 on 2013-01-30
Post score: 2

Original comments
Comment by georgebrindeiro on 2013-01-31:
Your problem might be that you assume the Kinect tf has the y axis pointing up, but many frames related to cameras actually have the y axis pointing down. Think about it and see if that makes sense!
Comment by Ugo on 2013-01-31:
I'm using the standard kinect from the turtlebot, the y axis is pointing down (towards the base of the kinect). When rotating so that the kinect is vertical, I rotate the main frame of the kinect, so relative orientations of all the different frames are kept.
Comment by georgebrindeiro on 2013-02-01:
I'm not sure what is going on (the first image isn't very clear as to where the part is supposed to be) but I still think looking at the coordinate systems is the way to go. You seem to be projecting XYZ coordinates given in a down-facing coordinate frame into an up-facing coordinate frame.
Comment by Ugo on 2013-02-01:
I annotated the picture to make it hopefully clearer. The point cloud we see is the robot seen through the kinect. The robot is also displayed as the 3d model, so they should be both at the same position (which is what I have when the kinect is horizontal).
Comment by georgebrindeiro on 2013-02-01:
Sorry, I don't think I can help you. Since I think this problem is more gazebo-related, you should probably ask here: answers.gazebosim.org
Comment by Ugo on 2013-02-03:
Good point. I'll ask it there. Thanks for your time anyway,.

A:

An answer from David Butterworth which solved my problem! Thanks David.

I found that if you modify the visual/collision mesh to be aligned with your joint origin, then it's okay.
Don't do extra translations/rotations of the mesh from within your URDF, because that is broken.
The orientation of the sensor data should depend on the Gazebo macro, but there should be only translations in there, with 2 joint rotations for the extra pair of camera frames.
My Gazebo macro is based on the PR2 one, but with the visual/collision meshes fixed and re-scaled as per above.
The end result is that any translation/rotation is only done at the head_mount_kinect joint that orientates everything else, and you can successfully pitch the sensor up-down or vertically.
I'm guessing that in your situation, the PointCloud data is actually in the correct place, but because of the bug with the meshes, the visual model is in the wrong place.

Originally posted by Ugo with karma: 1620 on 2013-02-21
This answer was ACCEPTED on the original site
Post score: 3

Original comments
Comment by georgebrindeiro on 2013-02-22:
so in the end it was a gazebo bug? good to know you finally got your answer!
Comment by fvd on 2018-07-12:
There is a Github issue about this: https://github.com/ros-simulation/gazebo_ros_pkgs/issues/243

