Q:

Extract video from PointCloud2

I have a rosbag file with sensor_msgs/PointCloud2 data. I want to extract a video from these data. All the ROS tools I found is related to the extraction of video from an Image topic. Is it possible to create a video directly from PointCloud2?
Or, is there a straightforward way to revert the PointCloud2 to the original image and depth topics?
Thanks to Martin Gunther I used the convert_pointcloud_to_image . But when I run image_view it crashes with this error:

Using transport "raw"
OpenCV Error: Bad argument (Unknown array type) in cvarrToMat, file /build/buildd/opencv-2.4.8+dfsg1/modules/core/src/matrix.cpp, line 698
terminate called after throwing an instance of 'cv::Exception'
what():  /build/buildd/opencv-2.4.8+dfsg1/modules/core/src/matrix.cpp:698: error: (-5) Unknown array type in function cvarrToMat

If I echo the image topic I can see the data, the header is:
header: 
seq: 1934
stamp: 
  secs: 0
  nsecs: 0
frame_id: ''
height: 1
width: 289946 
encoding: bgr8
is_bigendian: 0
step: 869838

What is the problem with this data?

Originally posted by rastaxe on ROS Answers with karma: 620 on 2016-04-21
Post score: 0

A:

The convert_pointcloud_to_image node in pcl_ros does exactly what you're looking for.

Edit: The reason for that crash you're seeing is that you put in an unorganized point cloud (i.e., height = 1). The convert_pointcloud_to_image node can only process organized point clouds. For example, this is how the data from an Asus Xtion looks like:
$ rostopic echo -n1 /camera/depth_registered/points | grep -v data
header: 
  seq: 0
  stamp: 
    secs: 1445245860
    nsecs: 100976221
  frame_id: camera_rgb_optical_frame
height: 240
width: 320
fields: 
  - 
    name: x
    offset: 0
    count: 1
  - 
    name: y
    offset: 4
    count: 1
  - 
    name: z
    offset: 8
    count: 1
  - 
    name: rgb
    offset: 16
    count: 1
is_bigendian: False
point_step: 32
row_step: 10240
is_dense: False

Notice that height !=1, which means this is an organized point cloud.

Originally posted by Martin G端nther with karma: 11816 on 2016-04-21
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by rastaxe on 2016-04-22:
Thanks! I used it, but with errors.. I updated my question.
Comment by rastaxe on 2016-04-22:
Ok, so first of all, I have to find a way to convert my data in organized point cloud, right?
Comment by Martin G端nther on 2016-04-22:
Right. But that won't be easy, since all you have is the rosbag, right? Usually your input cloud is organized (e.g., from a Kinect), and you would make sure that all your processing steps don't destroy the organization.
Comment by Martin G端nther on 2016-04-22:
But since you only have the rosbag left, it's going to be harder. You'll have to reproject the 3D data of each point into the image plane to get the pixel coords, then fill the missing pixels with NaN values.
Comment by Martin G端nther on 2016-04-22:
Your data is from a projective device (camera-like), not a 3D laser scanner or such, right? In that case, have a look at https://github.com/PointCloudLibrary/pcl/blob/master/common/include/pcl/common/projection_matrix.h , and grep the PCL code for usage examples.

