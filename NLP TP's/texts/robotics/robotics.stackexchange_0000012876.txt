Q:

Forward monocular stereo vision (Structure from Motion)

I am looking for a library (or algorithm) that computes 3D scene (point cloud) from 2 consecutive images of a monocular sequence. I mean something like OpenSfM but only for 2 consecutive frames and also with a known camera calibration data (I dont need to do "bundle adjustment" like most of the SfM libraries do). I do know my absolute camera translation for the scale.

A:

It turns out this can easily be done with OpenCV - just find image features (FAST etc.) in first image, track them to the second image (get a set of corresponding features between two images) and then use triangulatePoints function to get the 3D scene.
triangulatePoints accepts two projection matrices - one for each image. Each projection matrix defines camera intrinsic (focal + principal point) and extrinsic (rotation + translation) parameters. Intrinsics will be the same for both images, first image may have R+t all zero (coordinates origin) so just use R+t for your second image (compared back to zero).

