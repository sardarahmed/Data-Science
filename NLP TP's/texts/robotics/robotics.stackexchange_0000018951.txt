Q:

Can neural network probability directly be used as inverse sensor model?

For my robot i'm using semantic segmentation neural network that assigns to every pixel probability of being "road" (not occupied). By using homography matrix i'm re-projecting image to top-down view. The final goal is to build a map (poses are known).
I'm going to use simple algorithm "occupancy grid mapping" described in "Probabilistic Robotics" chapter 9.2. Core component of algorithm is "inverse sensor model" $p(m_i |z_t,x_t)$ - probability for cell $m_i$ being occupied given measurement $z_t$ and robot pose $x_t$
Will it be correct if i directly use probabilities from neural network as "inverse sensor model"?
if cell is outside current "top-down":
  return probability_0.5
else
  return probability_from_network

A:

Sure, it's possible to assign the conditional probability of a pixel to the map, but there is an easier way for occupancy mapping. A normal neural network can learn the probabilities internally so the programmer doesn't has to care about the value by it's own. This will make the development process lighter and modern frameworks like Tensorflow have the natural ability in model building.
So the answer to the question is, that the neural network will learn directly the grid map and this allows the programmer to focus on other tasks like pathplanning and steering control. Probabilistic robotics is overestimated because the weights in the neural network are able to adapt to new situation by it's own.
[1] Zhang, Jingwei, et al. "Neural SLAM: Learning to explore with external memory." arXiv preprint arXiv:1706.09520 (2017).

