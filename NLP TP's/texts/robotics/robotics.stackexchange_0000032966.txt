Q:

Publish Kinect Depth information to a Ros Topic

Hello, all,
Recently, we've been attempting to access the kinect depth data from the published point cloud provided by the openni_node, but we've run into a couple stumbling points:
first, the ros tutorial for pcl_ros
http://www.ros.org/wiki/pcl_ros/Tutorials/CloudToImage
references a topic published by openni called:
/camera/depth/points2
but our version of openni_kinect only publishes:
/camera/depth/points
Are we using an outdated version?
Also, we tried working with /camera/depth/points and we believe that this information is published in binary format.  When we attempted to convert the binary format of a single point to x,y,z information though, we received a list of 4 integers.  Are we interpreting the information incorrectly?
We also subscribed to the /camera/depth/image, and we could access the depth information from a single point, but we're restricted to meter-by-meter resolution.  Is there a better way of getting more resolution with the /camera/depth/image ?
Thanks for reading, and we appreciate any directions you can point us to accessing the depth information (of points) from the kinect.
Sincerely,
Poofjunior

Originally posted by Poofjunior on ROS Answers with karma: 88 on 2011-07-13
Post score: 1

A:

The current driver publishes both point clouds and images:

/camera/depth/points -- this is the non-colored point cloud. To use this, you'd probably want to use PCL (Point Cloud Library) functions to access individual points in a meaningful manner.
/camera/depth/image -- this is the depth image (not a point cloud). It can easily be converted to an OpenCV image using the cv_bridge package. For using the depth image, it is important to note that is a 32-bit float for each pixel, corresponding to meters. This answer and this one contain some useful information on using the image.

Originally posted by fergs with karma: 13902 on 2011-07-13
This answer was ACCEPTED on the original site
Post score: 6

Original comments
Comment by fergs on 2011-07-14:
Great! Please click the checkmark next to my answer to accept it.
Comment by Poofjunior on 2011-07-14:
Many thanks, fergs!  It turns out that we weren't interpreting the image correctly.  We changed                                  cv_image = self.bridge.imgmsg_to_cv(data, "mono8")      to      cv_image = self.bridge.imgmsg_to_cv(data, "32FC1")    and we started seeing much better results.
Comment by Poofjunior on 2011-07-14:
Many thanks, fergs!
Comment by Consider1001 on 2014-04-15:
Thank you for your answer. May I ask a question that if there is a way to get the value(float) of each point on the depth/image_raw before we convert it in to a cvmat?

