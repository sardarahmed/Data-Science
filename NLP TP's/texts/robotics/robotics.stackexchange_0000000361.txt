Q:

Programming a line following robot with reinforcement learning

I am considering programming a line following robot using reinforcement learning algorithms. The question I am pondering over is how can I get the algorithm to learn navigating through any arbitrary path?
Having followed the Sutton & Barto Book for reinforcement learning, I did solve an exercise problem involving a racetrack where in the car agent learnt not to go off the track and regulate its speed. However, that exercise problem got the agent to learn how to navigate the track it trained on.
Is it in the scope of reinforcement learning to get a robot to navigate arbitrary paths? Does the agent absolutely have to have a map of the race circuit or path? What parameters could I possibly use for my state space?

A:

One of the key measures of any machine learning algorithm is it's ability to generalize (i.e. apply what it has learned to previously unsceen scenarios). Reinforcement learners (RL) can generalize well but this ability is in part a function of the state-space formulation in my experience. This means that if you can find the right setup then the RL learner will not need a map of of the race circuit.
This leaves the question of which parameters to use. Without knowing more about the sensors available on your robot I can only speculate. My first inclinition is to try to encoded the relative orientation of the line and robot (i.e. is the robot tending to the right, left, or simply moving parallel with the line). Doing so would result in a nice small state-space. Though not strictly necessary it would make for a quick and simple implementation. Furthermore, if the robot is not going to move at a constant rate then it may help to encode the robots velocity as the robot will need to react more quickly when moving at higher speeds.

