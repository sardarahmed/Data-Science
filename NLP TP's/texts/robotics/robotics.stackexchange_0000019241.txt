Q:

Do self-driving robots use object-level SLAM?

How do self-driving bots usually deal with transient objects, e.g., parked cars on the side of roads when they can come and go? These aren't moving objects at the time of capture, but they do move at a later time. Is it common to run a CNN to detect static/dynamic objects prior to feature extraction? It's certainly much more computationally expensive, but otherwise how are dynamic objects dealt with or filtered out?

A:

How do self-driving bots usually deal with transient objects, e.g., parked cars on the side of roads when they can come and go?

No. In most of the open-source slams, dynamic objects are ignored which means they are just mapped as a stationary object. But there are few papers that deal with this in the way you think.

These aren't moving objects at the time of capture, but they do move at a later time. Is it common to run a CNN to detect static/dynamic objects prior to feature extraction?

It is not common. There are some papers that introduced object-level features but simply it is not very useful.

It's certainly much more computationally expensive, but otherwise how are dynamic objects dealt with or filtered out?

Any features from dynamic objects should be filtered out by either deep learning approach or conventional soft outlier rejection scheme. You will find the most of optimization-based slams are using M-estimator whereas some of the recent papers introduced deep learning approach.
This kind of topic is refered as semantic SLAM. You can find some related papers in ICRA, IROS 17,18,19.

