Q:

localization of robot/kinect within saved octomap

Hi, I have been able to successfully use the rgbdslam package with a kinect to create a 3D scan and send it to octomap. After that I am able to save it as a .bt file and visualize it with octovis.
Question: How can I use the saved octomap to localize my robot/kinect?
Thanks in advance.
-Scott

Originally posted by Scott on ROS Answers with karma: 693 on 2012-04-04
Post score: 0

A:

You'll have many options for that, but afaik no working solution out of the box. You can e.g. use scan matching with your point clouds to the known volumetric octomap model, but that's quite involved and computationally expensive.
I did some 3D localization with laser, IMU, and odometry on a humanoid in a known OctoMap model, you can find details in the paper "Humanoid Robot Localization in Complex Indoor Environments". As measurement model, you can immediately apply the ray casting functionality in octomap ("castRay" in OcTree) although I would suggest exploiting parallelization with OpenMP and downsampling the full point cloud.
Edit: I just published the localization code at http://ros.org/wiki/humanoid_localization
It's mostly designated for humanoid robots and still being polished right now, but I'm sure you can use much of the sensor model code as example.

Originally posted by AHornung with karma: 5904 on 2012-04-05
This answer was ACCEPTED on the original site
Post score: 0

