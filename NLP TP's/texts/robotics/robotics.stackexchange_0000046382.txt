Q:

Trouble viewing Lidar data in rviz

Hello everyone,
I am working on a project where it requires for me to fuse lidar data and also the data from a stereo camera(bumblebee).
The main issue for now ,the Lidar data which is being viewed in rviz is not showing the coordinates in the z-axis. Please have a look at this video for more detailed picture of my project: http://www.youtube.com/watch?v=vCrcEc5B6p0&feature=g-crec-u .  As you see towards the end of the video the point clouds are set flat on the screen. I want to be able to do 3D rendering like the PR2 does.
Also I am using the hokuyo Lidar(URG-04LX),Can it do the 3D rendering as I expect it to?. I think there is a need to have an on-board IMU for this problem. Please share your views. Thank you.
karthik

Originally posted by metal on ROS Answers with karma: 174 on 2012-12-08
Post score: 0

A:

Hi Karthik,
What you'll need to do is make sure that the frame that the LIDAR data is broadcast in (set in the Header) is referenced against the world frame with an appropriate transform. This transform needs to incorporate the roll, pitch, and yaw from the powered mounting you've built. I presume that you have a node which controls the LIDAR mount. In there, you could use the tf library (Tutorials) to broadcast a transform which relates the stationary part of the LIDAR mount to the LIDAR itself.
If you use the de-facto naming convention, you would wind up with a /base_link -> /lidar transformation. Then, set rviz to use /base_link as the fixed frame and make sure that /lidar is set as the frame_id in the header of your LIDAR data. rviz will now be able to show the LIDAR scans in 3D. Without the transform, rviz doesn't know anything about how the LIDAR is moving with respect to the world.

Originally posted by Ryan with karma: 3248 on 2012-12-08
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by metal on 2012-12-08:
Yes there is a node which controls roll,pitch and yaw of the whole sensor module. The lidar tilt (as you can see) is done by a dynamixel and I will read its current position. Like wise the current position of the other dynamixels can be read too. Can this be used for tf publishing ?.
Comment by metal on 2012-12-08:
Also,I am controlling  the sensor head through a joy stick(whose commands are sent from a node).
Comment by Ryan on 2012-12-08:
Yes, you should be able to modify that node to publish a suitable tf.
Comment by metal on 2012-12-09:
http://www.ros.org/wiki/laser_assembler/Tutorials/HowToAssembleLaserScans I came across this ,I think it would be helpful for my issue. Any thoughts ?.

