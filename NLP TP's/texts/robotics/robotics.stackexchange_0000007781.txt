Q:

How do I decide the size of the time steps between sensing and control actuation?

My Background:
My experience is in solid mechanics and FEA.  So I have zero experience in robotics/controls.  
Problem Description
I'm developing a control strategy to stabilize a complicated 6-legged dynamical system.  Torques Ti from each leg's joints will be used to create a net moment M on the body, stabilizing the system.  This moment M is known from the pre-determined control strategy.  (Side note: the dynamical solver is of the nonlinear computational type)
Due to my lack of background, I have a fundamental confusion with the dynamical system.  I want to use joint torques Ti to create this known net moment M on the body.  This moment M is a function of the

current positions/angles of all the leg segments
reaction forces and moments (that cannot be controlled) of each leg
controllable joint torques Ti of each leg
time

$(*)$ At a given time $(n-1)\Delta$t: 

--From the control strategy, the desired net moment M is computed/known
--One can read/sense the legs' positions, angles, reaction forces, and reaction moments (say, from well placed sensors), at this time $t = (n-1)\Delta$t.  
--From this information, vector algebra easily yields the desired joint torques Ti required to create the net moment M

$(**)$ At the time $(n)\Delta$t:

--one applies the previously determined joint torques Ti (determined at $t=(n-1)\Delta$t) to create the desired moment M 
--of course these torques Ti are applied at the immediate proceeding time step because they cannot be applied instantaneously

So this is exactly where my fundamental confusion exists.  The torques Ti were calculated in $(*)$, based on data of angles/positions/reactions in $(*)$, with the objective to create moment M.  However, these torques Ti are applied in $(**)$, where the data (angles/positions/reactions) are now different - thus the desired net moment M can never be created (unless you an magically apply actuation at the instantaneous time of sensing).  Am I understanding the controls problem correctly?  
Questions

Am I understanding the robotics problem correctly?  What are the terms and strategies around this dilemma?
Of course I could create the time steps between the sensing and the actuation to be infinitely small, but this would be unrealistic/dishonest.  What is the balance between a realistic time step, but also performs the task well?

A:

Regarding point 1, yes you are understanding the problem correctly.
Regarding points 1 and 2, I believe what you are looking for is the Nyquist-Shannon sampling theory. This theory says that your sampling frequency should be greater than 2x your "highest frequency of interest". This is to prevent aliasing, where you can incorrectly measure a high-frequency signal as low frequency.

The image above is from Wikipedia. So, you have your robot with all its joints and limbs and such - how fast can those limbs move? Your moments and torques will all cause accelerations at the joints; what is the top rotational speed at a joint? Or, put another way, what's the peak moment you would expect and how long would it be applied? You can calculate a speed from that as well.
You want to sample your joints fast enough that you can capture the full dynamics of the system. That's the sampling threshold (minimum!) I would set for my own robotics project for sensing. For control, most , reputable , sources , say 5-10 times the frequency of interest.
Your peak accelerations, from your peak torques and moments, are going to be limited by the mass (moment of inertia) of your limbs. The limbs that limit your accelerations are also going to act as a low-pass filter to keep the system relatively constant between samples such that the fact that you're off by one sample shouldn't matter too much.
Hope this helps!

