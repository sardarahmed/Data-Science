Q:

What is the API to generate a registered point cloud from raw kinect streams

As specified on the openni_launch web page, I have been recording live Kinect data by recording the following 4 topics with rosbag record
camera/depth_registered/image_raw
camera/depth_registered/camera_info
camera/rgb/image_raw
camera/rgb/camera_info
/tf

To generate registered pcl::PointXYZRGB point cloud topics from this bag file, I have been playing the bag file at the same time as:
roslaunch openni_launch _load_driver:=false

I now need to read the bag file in my source code using the rosbag python API.  However, I do not know how to produce the registered pcl::PointXYZRGB point cloud from these recorded topics in code.  Is there a library function that takes in these 5 image topics and outputs the registered pcl::PointXYZRGB point cloud?
Many Thanks

Originally posted by Arrakis on ROS Answers with karma: 163 on 2012-09-11
Post score: 2

A:

There is a script provided with the RGBDSLAM benchmark data set from Freiburg that adds a pointcloud to a bagfile given these topics.  Take a look here http://vision.in.tum.de/data/datasets/rgbd-dataset/tools#adding_point_clouds_to_ros_bag_files
Take a look at the script 'add_pointclouds_to_bagfile.py'.  You can either use it on your bagfile or look at the code.  Note if you want to use it you will need to change the topic names in the script, as the script was written for the electric openni drivers.
EDIT: Sorry I didn't see that you had recorded the raw images.  I don't know how to rectify these images, however recording /camera/depth_registered/image and /camera/rgb/image_rect_color instead of the raw images would solve this.

Originally posted by RossK with karma: 141 on 2012-09-12
This answer was ACCEPTED on the original site
Post score: 2

