Q:

Getting Start with Kinect and ROS

Hi all,
I want to use a Gazebo world and a robot with a kinect on it where I can identiy objects of this world.
I'm thinking on getting the kinect RGB images and process, but I'm a little confuse about how to simulate the kinect on gazebo and parse the image data to ROS, so I was thinking if any of you doesn't have some quick start or tutorials to give me (even some tips), I know normally OpenNI and PCL are used, but I don't know exactly how to use them with ROS and Gazebo together. I searched at ROS forum but related questions normally was closed as a Gazebo question, so I thought maybe here was the best place to discuss it.

Originally posted by cflavs on Gazebo Answers with karma: 1 on 2016-09-12
Post score: 0

Original comments
Comment by kerem on 2016-10-07:
I'm also looking for a similar solution, have you got any clues yet?

A:

Just add this lines in ur sdf file with a model and launch it, than after this u can run rostopic echo in another terminal to see the published topics, it will exactly work like real kinect sensor, but if u want to make it more realistic u need to add some noise in it.
 <!-- camera -->
  <gazebo reference="camera_link">
    <sensor type="depth" name="camera1">
        <always_on>1</always_on>
        <visualize>true</visualize>             
        <camera>
            <horizontal_fov>1.047</horizontal_fov>  
            <image>
                <width>640</width>
                <height>480</height>
                <format>R8G8B8</format>
            </image>
            <depth_camera>

            </depth_camera>
            <clip>
                <near>0.1</near>
                <far>100</far>
            </clip>
        </camera>
             <plugin name="camera_controller" filename="libgazebo_ros_openni_kinect.so">
             <alwaysOn>true</alwaysOn>
                <updateRate>10.0</updateRate>
                <cameraName>camera</cameraName>
                <frameName>camera_link</frameName>                   
            <imageTopicName>rgb/image_raw</imageTopicName>
            <depthImageTopicName>depth/image_raw</depthImageTopicName>
            <pointCloudTopicName>depth/points</pointCloudTopicName>
            <cameraInfoTopicName>rgb/camera_info</cameraInfoTopicName>              
            <depthImageCameraInfoTopicName>depth/camera_info</depthImageCameraInfoTopicName>            
            <pointCloudCutoff>0.4</pointCloudCutoff>                
                <hackBaseline>0.07</hackBaseline>
                <distortionK1>0.0</distortionK1>
                <distortionK2>0.0</distortionK2>
                <distortionK3>0.0</distortionK3>
                <distortionT1>0.0</distortionT1>
                <distortionT2>0.0</distortionT2>
            <CxPrime>0.0</CxPrime>
            <Cx>0.0</Cx>
            <Cy>0.0</Cy>
            <focalLength>0.0</focalLength>
            </plugin>
    </sensor>
  </gazebo>

U have to define link, collision element and visual element to represent the kinect sensor and add this sensor plugin before  i.r ur model or link which u want to see as a kinect sensor.

Originally posted by hari1234 with karma: 56 on 2016-12-19
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by aadityacr7 on 2018-05-01:
I get this particular error message when copy pasted this code inside the link tag. XML Element[gazebo], child of element[link] not defined in SDF. Ignoring[gazebo].  Any suggestions on why this could be happening?
Thanks in advance.
EDIT: Solved the problem. Gazebo tag is used for URDF files not for SDF files.

