Q:

Problem simulating kinect in gazebo

Hi,
I am trying to simulate the turtlebot in gazebo. I am using the turtlebot_gazebo and stack for that (using robot.launch).
However, the depth data coming from the (simulated) kinect is all wrong. Every point in the point cloud published by the /camera/depth/points topic has a depth of 1.0. This is when the light source in the .world file is of the directional kind. When I use a point or spot light source, the bottom half of the pointcloud has depth of 1.0 and the top half either NaN or 1.0 (depending on whether something is within range or not). This is preventing me to use any SLAM algorithm in gazebo. I get the camera rgb image through correctly.
I am using Ubuntu 11.04 and electric.
Thanks a lot.

Originally posted by Laurie on ROS Answers with karma: 103 on 2011-11-29
Post score: 5

A:

@Laurie, In general you want a discreet graphics card to run the simulations.  There's a list of user tested cards at http://www.ros.org/wiki/simulator_gazebo/SystemRequirements

Originally posted by tfoote with karma: 58457 on 2011-12-12
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by Laurie on 2011-12-21:
I am using a nVidia card now, and the depth data is correctly simulated. Thanks.

