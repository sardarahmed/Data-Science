Q:

Run tf/tf2 as nodelet

Is it possible to run tf/tf2 as nodelet?
EDIT: What I mean is that, for example, the robot_state_publisher is always a node. Is there a nodelet version? If not, is there any reason or just nobody needed it?
Also: if I publish TF transformations and I do lookup transformations in nodelets, do I get the advantages of using nodelets? I guess that in this case I should be careful that everybody publishing and subscribing to TF are nodelets. However, when using nodelets I should subscribe to ConstPtr and publish Ptr. How do I guarantee this with TF?
Thanks!

Originally posted by Javier V. G贸mez on ROS Answers with karma: 1305 on 2015-11-30
Post score: 0

Original comments
Comment by gvdhoorn on 2015-11-30:
Just to avoid an xy-problem: could you tell us what you are trying to achieve? That might also make potential answers more relevant to your issue.
Comment by Javier V. G贸mez on 2015-11-30:
I have some nodelets running in my application, and so far tf is used only in nodelets. I am trying to improve performance.
Comment by gvdhoorn on 2015-11-30:
I've not looked into this directly, but nodelets mainly avoid the costly (de)serialisation step in the msg exchange. Seeing as TF msgs are rather small (ie 100s of bytes), I'd expect that overhead to be negligable. Do you have a specific case where middleware perf is a bottleneck?
Comment by Javier V. G贸mez on 2015-11-30:
@gvdhoorn Currently tf is not my bottleneck, but if there is an option for that I do not see why not doing it, as it is not difficult to deal with nodelets. And I agree TF message is not that big, but for my application is one of the largest messages.

A:

tf and tf2 are not runnable which is why it's hard to answer your question.
tf and tf2 are libraries which are integrated into your node or nodelet. If you create a nodelet and use tf inside of it, you will get all the speedups of working inside a nodelet.
There are some standalone executable tools. However they are low bandwidth and I highly doubt that they will become a bottleneck for your performance.
Update: It looks like it's not actually using the shard pointer when publishing. here and here A PR to fix that would be great. However before you try to optimize too much you should really profile what's taking your time.
It's much more likely that avoiding multiple listeners such as using a buffer server and buffer client will be a way to save a lot more resources. an example usage A buffer server is very simple to setup This has the highest payoff for low frequency scripts which just need to poll tf infrequently and are tolerant of higher latency calls.

Originally posted by tfoote with karma: 58457 on 2015-12-02
This answer was ACCEPTED on the original site
Post score: 4

Original comments
Comment by Javier V. G贸mez on 2015-12-03:
You are right, my question might not be properly written. I have edited it to make it more clear. Anyway, you replied what I wanted to know more or less :)

