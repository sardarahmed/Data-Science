Q:

DepthImage to Mat (OpenCV)

I am working with a 3d camera that provides a depthimage which is encoded in 32FC1
I need the image in OpenCV format (Mat) in order to access each component as a matrix
The problem is that when I have done the transformation, I try to access the Matrix data with Mat::at but I can not see real values. I don't know where the problem is.
EDIT
I have discovered that the problem is the ros encoding of the image. I have simulated a depth camera and I don't know the equivalence between each pixel value and the distance it represents. My camera code is the following:
  <gazebo reference="kinect_depth_frame">
    <sensor type="depth" name="fotonic">
      <update_rate>30.0</update_rate>
      <camera name="fotonic">
        <horizontal_fov>1.221730476</horizontal_fov>  <!-- 70 deg -->
        <image>
          <width>800</width>  <!-- 160 -->
          <height>600</height> <!-- 120 -->
          <format>R8G8B8</format>
        </image>
        <clip>
          <near>0.05</near>
          <far>7.0</far>         
        </clip>
        <noise>
          <type>gaussian</type>
          <mean>0.0</mean>
          <stddev>0.007</stddev>
        </noise>
      </camera>
      
      <plugin name="kinect_depth_optical_frame_controller" filename="libgazebo_ros_openni_kinect.so">
        <baseline>0.2</baseline>
        <alwaysOn>true</alwaysOn>
        <updateRate>30.0</updateRate>
        <cameraName>fotonic_3dcamera</cameraName>
        <imageTopicName>/fotonic_3dcamera/image_raw</imageTopicName>
        <cameraInfoTopicName>/fotonic/depth/camera_info</cameraInfoTopicName>
        <depthImageTopicName>/fotonic/depth/image_raw</depthImageTopicName>
        <depthImageInfoTopicName>/fotonic_3dcamera/depth/camera_info</depthImageInfoTopicName>
        <depthImageCameraInfoTopicName>/fotonic_3dcamera/camera_info</depthImageCameraInfoTopicName>
        <pointCloudTopicName>/fotonic_3dcamera/depth/points</pointCloudTopicName>
        <frameName>kinect_depth_optical_frame</frameName>
        <pointCloudCutoff>0.5</pointCloudCutoff>
        <distortionK1>0</distortionK1>
        <distortionK2>0</distortionK2>
        <distortionK3>0</distortionK3>
        <distortionT1>0</distortionT1>
        <distortionT2>0</distortionT2>
        <CxPrime>0</CxPrime>
        <Cx>0</Cx>
        <Cy>0</Cy>
        <focalLength>0</focalLength>
        <hackBaseline>0</hackBaseline>
      </plugin>      
    </sensor>
  </gazebo>

Originally posted by arenillas on ROS Answers with karma: 223 on 2014-09-25
Post score: 0

Original comments
Comment by Wolf on 2014-09-30:
Can you please add your code for retreiving your cv::Mat from the image message and the cv::Mat::at statement?

A:

The depth image does not follow OpenCV standards. The value of each pixel represents the distance in meters,

Originally posted by arenillas with karma: 223 on 2014-09-30
This answer was ACCEPTED on the original site
Post score: -1

Original comments
Comment by Wolf on 2014-09-30:
There is no standard that specifies a cv::Mat may not contain depth values as distances in meters. OpenCV allows floating point matrices.
Comment by Wolf on 2014-09-30:
Of course, image processing function that assume color images will not work with such image; but cv::Mat::at (which the user mentioned) should work if templates are selected correctly!
Comment by arenillas on 2014-09-30:
Yeah, but I tried to represent the image with OpenCV and, because of I had it in 32float, it expects the image to have values between 0 to 1. So, when I tried to represent the image It was not the original I had in ROS and I was becoming crazy.
Comment by Wolf on 2014-09-30:
Still, this should work; if you have a cv::Mat your_mat of type CV_32FC1 using your_mat.at<float>( i,j ) you are able to set it to any float value and retrieve any float value out of it; not just those between 0 and 1

