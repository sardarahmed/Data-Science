Q:

How to access and use skeleton joint coordinates using OpenNI, ASUS Xtion, and ROS?

To develop a person follower robot, I am using ASUS Xtion and OpenNI. To obtain both RGB image and skeleton joints, I am using a skeleton tracker script (https://github.com/Chaos84/skeleton_tracker). Tracker publishes joints in "/tf" But the thing is that I cannot use those joint coordinates in my script. I don't know how to access them. How can I access and use them in my script to make the robot move according to those coordinates? Thanks.

Originally posted by gokay on ROS Answers with karma: 1 on 2016-04-22
Post score: 0

A:

The information you are interested in that is contained in the /tf data will be transformations from some frame on the Kinect to some frame on the user (e.g. right_hand). What you need to do is write a node that creates a tf listener that periodically looks up this transform data. Here are the tutorials on tf listeners in Python and C++. Once you have that transformation information, it's up to you to decide what to do with it. For example, you could publish the relevant geometric information on a new topic that a robot control node subscribes to. Or you could directly control the robot in the node with the tf listener.
EDIT
The above links aren't working (seems like a bug in Askbot or Askbot config)... they work in my preview window. Here are the links:
Python: http://wiki.ros.org/tf/Tutorials/Writing%20a%20tf%20listener%20(Python)
C++: http://wiki.ros.org/tf/Tutorials/Writing%20a%20tf%20listener%20(C%2B%2B)
EDIT 2
Fixed links using answer from @joq here.

Originally posted by jarvisschultz with karma: 9031 on 2016-04-22
This answer was ACCEPTED on the original site
Post score: 0

