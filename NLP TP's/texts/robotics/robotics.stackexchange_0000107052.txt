Q:

sensor fusion of lidar and camera detection

I am trying to achieve sensor fusion between two sensors(camera and lidar). I have two separate node(one is publishing detection results using camera, and other is using lidar and they both are operating on a seperate deep learning based object detection methods) which are publishing detection results in the form of vision_msgs detection array.
Now I want to fuse these detection results. How can I go further?
I am using ros2 humble with gazebo fortress and I am trying this experiments in the simulated environment only. (no real sensors)

A:

If you're looking to fuse the sensor readings together into one better measurement, the right tool for the job is generally a Kalman Filter. It's not ROS specific, but OpenCV has a Kalman Filter Implementation. The OpenCV kalman filter is available in python and C++. It's well documented and there are plenty of online tutorials available for it that may apply directly to your use.

