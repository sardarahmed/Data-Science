Q:

Localization of a Robot to find it Coordinates according to the Known Map

I am a third-year electrical engineering student and am working on an intelligent autonomous robot in my summer vacations.
The robot I am trying to make is supposed to be used in rescue operations. The information I would know is the position of the person (the coordinates of the person in a JSON file that can be changed anytime except during the challenge) to be rescued from a building on fire. I would also know the rooms of the building from a map, but I don't know where the robot may be placed inside the building to start the rescue operation.
That means I have to localise the robot placed at an unknown position in a known environment, and then the robot can plan its path to the person who has to be rescued. I can use gyroscope, accelerometer, magnetometer and ultrasonic sensors to do the localising job. I cannot use a GPS module or a camera for this purpose.
The object to be rescued (whose location is known in terms of coordinates & can be changed anytime) is surrounded by walls from 3 sides. Hence, adding more walls in this map.
According to my research particle filter is the best method used for localization of robot. But how can I deal with the landmarks (walls) that are fixed as shown in the map image and that are variable depending on the location of the object to be rescued being provided in the JSON file?
I can do the path planning from a known position to the target position, but I'm not sure how to determine the starting position.
More about JSON file:
(1) json file containing the coordinates of the object to be rescued can change. (2) it won't change during the challenge. (3) json file will be provided to me in an SD card that my robot has to read. I have successfully written the code that will allow the robot to read the json file and hence the coordinates of the object to be rescued.
Here is the map of the building which is known to me.

A:

Particle filter
According to the OP a robot with at least a distance sensor is available and a map too. That's a nice starting point for developing a hypothesis tracker aka particle filter. At first a game engine is needed which simulate the map and the position of particles. The game-engine calculates the expected sensor-information from the distance-sensor. E.g. the particle is on left top in the map and direction is "north" and the game-engine says "distance=10 cm". This is done for every random particle in the map.
Now comes the nice part: a particle will be deleted which has the greatest difference to the real measurement. That means, if the robot has a real distance of 5 cm on the sensor, than a particle with a distance of 200 cm can not be the right one. After deleting the particle the robot will be moved ahead, and the particles also. Again, the worst particle has to be deleted.
From a theoretical point of view, this is called a hypothesis elimination. It means, that the algorithm deletes the particle with the lowest probability to be the right answer. After a while a particle cloud with the real position of the robot is remaining.
Landmarks
Fixed landmarks in the map (like a door which is marked with a red line on the ground) can be easily integrated in the particle filter because in the map are particles who fulfill the conditions and others who don't. E.g. if the real robot detect a door, all particle in the game-engine who not detect the door are wrong. A more complicated task are variable landmarks which can be anywhere in the map. These obstacle change the map itself and create an extended problem called SLAM (=map building). Algorithms like FastSlAM  and Hyperparticle  (every particle has its own map) build a map and localize together.

