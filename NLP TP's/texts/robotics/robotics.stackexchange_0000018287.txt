Q:

Fusing absolute robot localization from markers

I have a system which is composed of a rig of 8 cameras which are used for detecting markers in the environment and which outputs 8 estimates of the absolute robot's position and orientation.
Now, I need to fuse these estimations. I don't know if the best way is using a Kalman Filter or something like that.
On the other hand, I do not know if it would be convenient to track the position of each camera through a particle filter before fusing.

A:

If you just have 8 redundant transformations, I think taking an average on se3 is the simplest way. Or you can fuse them on se3 if you can estimate the uncertainty of each pose estimation. You can define the uncertainty e.g, by the distance of markers from the camera.  
EKF is the best if you have complementary sensors or good estimation of uncertainty. But it seems this is not your case. 
I don't see any meaning of using PF in your case.

