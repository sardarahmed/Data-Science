Q:

How to make SLAM with other programs and tools?

Hi everyone
I'd like to know a way to make Simultaneous Localization And Mapping (SLAM). All projects I've seen are driven by teleop_twist_key node, or a joystick. In order to apply SLAM, the wheeled robot I'm looking for needs to make autonomously a mapping for the planar environment it moves, preferably indoors. I know teleop node, navigation stack and gmapping from ROS are always the chosen by almost everyone to make this task.
Edit
Thanks to @gvdhoorn now I know other implementation for ROS like frontier_exploration package and turtlebot_exploration_3d
Which other implementations exists to use SLAM in the way I'm looking for?
Thanks

Originally posted by gerson_n on ROS Answers with karma: 43 on 2017-09-05
Post score: 0

Original comments
Comment by gvdhoorn on 2017-09-05:
Is this related to #q269765 (your previous question)? If not, can you clarify what you actually want to do?
Comment by gerson_n on 2017-09-05:
Oh, yes it is. I forgot I've asked the same question a week ago. In this case I should delete this question?
Comment by gvdhoorn on 2017-09-05:
We can close it as a duplicate and then optionally delete it.
Comment by gerson_n on 2017-09-05:
Thanks for reopen this one

A:

The nav2d package provides both SLAM and navigation for indoor robots. It can load exploration strategies to make the robot explore its environment autonomously. There are also tutorials how to set it up.

Originally posted by Sebastian Kasperski with karma: 1658 on 2017-09-06
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by gerson_n on 2017-09-06:
Thanks a lot man, I'd like to use the package you've done. That's what I've been looking for. Just a few questions about the params: What about it performance for kinect? is it appropiate? I haven't found people who has used that sensor for it. And how it works for odometry?
Comment by gerson_n on 2017-09-06:
I understand I need position (odom) and a vision sensor (kinect) which together as inputs are used for a filter like kalman or particle filter (this case). The thing is, I didn't see how can I send the odom info to this algorithm, can you tell me how to achieve that? Thanks
Comment by Sebastian Kasperski on 2017-09-07:
Odometry is input via topic tf, same as for navigation stack. I never used nav2d with a Kinect, which is a 3d sensor. But I think there are already ROS-nodes to create virtual 2d-scans from a Kinect sensor.
Comment by gerson_n on 2017-09-11:
Thanks again man.

