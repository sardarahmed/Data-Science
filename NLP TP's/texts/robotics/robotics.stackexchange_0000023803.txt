Q:

AWS RoboMaker simulations + testing explained

I am trying to understand how AWS RoboMaker and WorldForge work, and am having trouble "seeing the forest through the trees," and might need someone to "explain it to me like I'm 5" (ELIF).
Do you:

Write your robot's firmware (in any language/library/RTOS you choose) and upload it to AWS and run it through their simulations/tests/workbenches? or...
Write your robot's firmware in Python (which seems to be the only language they currently support, at least in the examples I can find), use their Python libraries/modules for interacting with their WorldForge simulations, and upload your Python code to AWS and run it through their simulations/tests/workbenches; or...
Something else completely different?

Thanks for any clear + succinct (good step-by-step examples would be amazing!) steering here!

A:

If you take a look at their Getting started > Concepts section, they mention

A typical simulation might use Robot Operating System (ROS) with one container simulating the environment in Gazebo, and a second container simulating the robot.

As I discuss in my answer to your other question, your robot needs some way to interact with the virtual environment. By the way it's described above, Amazon is assuming you're going to have some network I/O that will bridge your robot to the simulated environment. The simulated environment would be what hosts your virtual robot, with all the virtual sensors and encoders, etc. The virtual environment would all be put on one docker container.
The robot (as described by Amazon in the quote above) would run on another docker container. Your robot runs on whatever software you choose to write, Python, C++, etc., and it communicates over that network I/O to the simulator, which will generate synthetic feedback based on whatever your virtual sensors are programmed to do.

