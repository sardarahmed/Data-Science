Q:

Tuning down PointCloud2 data for smaller computation devices

Hello,
I have installed ROS navigation on a Jetson TK 1 microprocessor and I am using Kinect for /scan sensory using laser_to_scan node.
I have added the scan topic inside costmap_common_params.yaml
observation_sources:  scan
scan:
data_type: LaserScan
topic: kinect_scan

It computes the AMCL and executes tway points pretty well but now I would like to add the point cloud topic as well so that it avoids obstacles in the way using the local costmap obstacle avoidance.
bump:
data_type: PointCloud2
topic: camera/depth/points

Unfortunately by doing this I have slowed down the path planning drastically.
Sending a goal pose from RVIZ makes the ros navigation about 25 seconds to send the first plan and even worse, since it doesnt send the next plan in time, the path planning fails altogether.
It seems that the CPU on the Tegra might not be managing all the computation required from the pointcloud topic so I was wondering if there were ways to tune the data down or even take only a chunk from it so that move_base can compute with less resource consumption.
Thanks in advance.

Originally posted by dgrixti on ROS Answers with karma: 95 on 2017-03-21
Post score: 0

A:

What I do for small computation devices is to set the Kinect driver to QQVGA mode (160x120). The default mode is VGA (640x480 pixels). It makes a huge difference to process only 19.200 points per frame (QQVGA) instead of 307.200 points per frame (VGA)
If you are using openni2_launch you can set the parameter camera_mode (11 is QQVGA@30fps) either in your launch file or using dynamic reconfigure.
Although the ideal solution would be to modify costmap_2d package to process the pointcloud using the GPU in TK1 instead of the CPU

Originally posted by Martin Peris with karma: 5625 on 2017-03-21
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by dgrixti on 2017-03-21:
Thanks for your great answer, I see that in fact openni has image_mode which can be reduced. A couple of questions please: do you also reduce depth_mode res? And do these modifications affect your /scan performance?
Comment by Martin Peris on 2017-03-21:
Yes, I do reduce the depth_mode res as well. I always use the depth sensor as a complement of a real laser range finder but I would expect these modifications to affect the laser_to_scan /scan performance, although not critically

