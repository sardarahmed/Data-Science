Q:

Translating Cartesian Coordinates from Hand frame to World Frame: ROS & Baxter Help

Hi,
So I'm working with the baxter robot and using the ROS workspace. The baxter has a camera attached to its arm, from which I can read x,y,z coordinates of certain object, relative to the hand frame.
Once my object is detected, I need its x,y,z coordinate, but from the robot's main frame, so i need to translate from the hand to the robot frame, and given that the robot has 6 degrees of motion, I'm having a hard time figuring out how to do that. I know that I'm supposed to use DH matrices, but could someone try and explain to me how i should proceed?

Originally posted by laurent on ROS Answers with karma: 21 on 2016-06-13
Post score: 0

A:

I know that I'm supposed to use DH matrices [..]

well, that is one possibility, but ..

[..] but could someone try and explain to me how i should proceed?

I would use the TF(2) framework (wiki):

tf2 is the second generation of the transform library, which lets the user keep track of multiple coordinate frames over time. tf2 maintains the relationship between coordinate frames in a tree structure buffered in time, and lets the user transform points, vectors, etc between any two coordinate frames at any desired point in time.

I think you'll be most interested in the "lets the user transform points, vectors, etc between any two coordinate frames at any desired point in time" bit.
TF can be a bit of a challenge to get to grips with, so I highly recommend you do the tutorials first (and try to understand them, not just copy/paste the examples), before you try to integrate it into your own code.

Originally posted by gvdhoorn with karma: 86574 on 2016-06-13
This answer was ACCEPTED on the original site
Post score: 2

Original comments
Comment by laurent on 2016-06-13:
So using tf echo i was able to obtain the position and rotation coordinates of the hand of my robot. but i can't seem to figure out how, using tf, i would transform coordinates from my hand to my base perspective
Comment by gvdhoorn on 2016-06-13:
tf_echo is a nice command line tool, but what you really want to use is the tf library in your C++ or Python based node / script. Have you looked at the other tutorials?
Comment by laurent on 2016-06-13:
yes i have, I actually figured out a way to get the transformation matrix using fromTranslationRotation()! Thank you so much!!
Comment by gvdhoorn on 2016-06-14:
See if the tf2_ros::BufferInterface::transform(..) function already does what you want. Manually transforming poses is fine, but the utility functions exist for a reason.
Comment by laurent on 2016-06-14:
Do yoiu know if there's an API for the BufferInterface for python? There this link(http://docs.ros.org/jade/api/tf2_ros/html/python/tf2_ros.html?highlight=bufferinterface) but somehow i can't access the buffer interface API
Comment by gvdhoorn on 2016-06-14:
I think it's this but it appears the Python side is slightly under-documented. You might want to ask about that at the issue tracker.
Comment by laurent on 2016-06-14:
I don't know much C++, But looking at the function in the c++ api, it says that it returns the transformed output. Which is a little confusing to me, since it doesn't know the input frame, only the frame you want to transform to
Comment by gvdhoorn on 2016-06-14:
ROS msgs like geometry_msgs/Pose include a header.frame_id field. That contains what you call the input frame (or at least: it should contain it). Make sure you input properly setup Poses/Points/etc, and the rest should be taken care of for you.
Comment by laurent on 2016-06-14:
So should i define header.frame_id as my input frame? Sorry im at a very beginner level at coding
Comment by gvdhoorn on 2016-06-14:
No: the source of your poses (ie: your object recognition node/program) should set it, and probably to the frame your camera / sensor works in.
Comment by M@t on 2016-08-23:
For anyone viewing this question at a later data looking for the exact python commands to do this transformation, I think the correct commands are covered in this question

