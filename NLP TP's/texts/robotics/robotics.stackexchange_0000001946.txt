Q:

What is the most appropriate SLAM algorithm for quadrotors with RGB-D camera?

I have been researching on SLAM. I came across EKF SLAM which uses odometry to measure the robot's initial position in the map and as well as landmarks which helps the robot's position to be more accurate. Based on the SLAM for dummies, it has a problem of loop closure. In another journal, it was compared to fastSLAM and EKF has a big-O function of $O(K^2)$ where $K$ is the number of landmarks while fastSLAM has $O(M\log(K))$.
It was also said that the most promising SLAM algorithm from the journal "The vSLAM Algorithm for Navigation in Natural Environments"
 is FastSLAM 
However, the vSLAM used by an experiment done by the University of Pennsylvania is the occupancy grid SLAM.
I want to ask what would be the most approriate SLAM algorithm for vSLAM given an unmanned aerial vehicle like the quadrotor and RGB-D camera + IMU? Also are there any algorithm that can be extended to support co-operation?

A:

I assume that your target environment is indoors as you use RGB-D camera.
When you want to use it with quadrotor, you need high update rate for accurate pose estimation. Some packages that you can look at are
http://vision.in.tum.de/data/software/dvo
http://wiki.ros.org/demo_rgbd
https://github.com/ccny-ros-pkg/ccny_rgbd_tools
Next, if you want to use only RGB camera + IMU, you must look at this 
http://wiki.ros.org/ethzasl_ptam

M. Li and A. I. Mourikis, “High-precision, consistent EKF-based visual–inertial odometry,” Int. J. Rob. Res., vol. 32, pp. 690–711, 2013.

There might be many others but these might be some starting points...

