Q:

Using Kinect for both navigation and user tracking

Hi there!
I'm trying to use one Kinect for two tasks: navigation and user tracking. At first firing navigation simultaneously with user_tracking doesn't work, and I couldn't find any information if anyone tried that?
Navigation and tracking work if I run them separately.
Any help would be appreciated!
da-na

Originally posted by da-na on ROS Answers with karma: 306 on 2013-05-16
Post score: 1

Original comments
Comment by David Lu on 2013-05-16:
Please be more specific as to "doesn't work". Also, what user_tracking package are you using?
Comment by sealguy77 on 2014-12-04:
I am working on the same type of project.  What packages are you using?
I am using openni_camerafor the Kinect, openni_tracker for skeleton tracking, and p2os-vanderbilt for Pioneer3DX.
Comment by sealguy77 on 2014-12-04:
I have not yet started on the navigation piece yet, but I figure I would start with this package.  I figure the 'goal location' could subscribe to the tf topic of the skeleton with an offset.  I'll keep you posted with updates and you will see my questions soon.

A:

ROS nodes are a publisher/subscriber system - the publishing nodes (should) operate normally no matter how many subscribers are consuming the data downstream. Are you pushing the limits of your hardware's processing capability?
Check top output to see the CPU load. An easy way to reduce processing load with Kinect or other RGBD cameras is to reduce the resolution using dynamic_reconfigure.
How are you using the Kinect output in navigation? Instead of using the pointcloud as a datasource, try feeding it through pointcloud_to_laserscan or use the depth image via depthimage_to_laserscan, both options will reduce the CPU load significantly.
Please add launch files and debug output to your question.

Originally posted by paulbovbel with karma: 4518 on 2014-11-07
This answer was ACCEPTED on the original site
Post score: 1

