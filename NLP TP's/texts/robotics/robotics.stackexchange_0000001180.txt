Q:

information filter instead of kalman filter approach

I read many sources about kalman filter, yet no about the other approach to filtering, where canonical parametrization instead of moments parametrization is used. 
What is the difference?

Other questions:

Using IF I can forget KF,but have to remember that prediction is more complicated link 
How can I imagine uncertainty matrix turning into an ellipse? (generally I see, area is uncertainty, but I mean boundaries) 
Simple addition of information in IF was possible only under assumption that each sensor read a different object? (hence no association problem, which I posted here

A:

They are exactly the same. Information matricies (aka precision matricies) are the inverse of covariance matricies. Follow this. The covariance update $$P_{+} = (I-KH)P$$ can be expanded by the definition of $K$ to be
$$ P_{+} = P - KHP $$
$$ P_{+} = P - PH^T (HPH^T+R)^{-1} HP $$
Now apply the matrix inversion lemma, and we have:
$$ P_{+} = P - PH^T (HPH^T+R)^{-1} HP $$
$$ P_{+} = (P^{-1} + H^TR^{-1}H)^{-1} $$
Which implies:
$$ P_{+}^{-1} = P^{-1} + H^TR^{-1}H $$
The term $P^{-1}$ is called the prior information, $H^TR^{-1}H$ is the sensor information (inverse of sensor variance), and this gives us $P^{-1}_+$, which is the posterior information. 
I'm glossing over the actual state estimate, but it's straightforward. The best intro I've seen on this is not Thrun's book, but Ben Grocholsky's PhD thesis. (Just the intro material). It's called Information Theoretic Control of Multiple Sensor Platforms. Here's a link.

EDITS
To answer the questions posed.

It is not more complicated to predict, it is more computationally costly, since you must invert the $n \times n$ covariance matrix to get the true state output. 
To view the ellipse from a covariance matrix, just note that the covariance matrix has a nice Singular Value Decomposition. The square root of the eigenvalues of the ellipse, or the square root of the singular values of the ellipse, will define the principal axes of the ellipse.
No, addition of information depends only on the assumption of independence of measurement noise. If you want to use two information filters to track two objects, that's fine. Or if you want to use an IF to track two objects, that's also fine. All you need is the correct association of measurements, so that you know which part of the state (object 1 or object 2) to update.

