Q:

real time interface in ur5 robot

Hello,
I am writing my final bachelor project. I have to run an Universal UR5 robot with speech recognition. At the moment I have signs like "right", "left", etc. in python.
So I've got a few questions.
Is it possible to have an real time interface in the ur5 robot and the simulation?
Do you have any ideas how to realise this? I read about an moveit interface with python. Is it working with this in real time?
I would be very greatful for any help =)

Originally posted by Jan Moritz on ROS Answers with karma: 15 on 2014-12-19
Post score: 1

Original comments
Comment by gvdhoorn on 2014-12-19:
Could you clarify what you exactly mean with "real time interface". Do you need hard real-time 1kHz force/velocity control for instance, or is 10Hz position control sufficient? The quality of the answers will probably depend on what your requirements are.
Comment by Jan Moritz on 2014-12-22:
10 Hz position control is ok. do you have any ideas?

A:

Based on the requirements you state (and the fact that you haven't mentioned it yet), I'd take a look at the universal_robot package. It can probably do what you want.

The wiki page is a bit barren, but the README.md file in the github.com/ros-industrial/universal_robot repository should clear things up.
Note that the driver provides just a FollowJointTrajectoryAction server. You'll have to write a client yourself (ur_driver/test_move.py shows a minimal example of how to do this).

Originally posted by gvdhoorn with karma: 86574 on 2014-12-22
This answer was ACCEPTED on the original site
Post score: 3

