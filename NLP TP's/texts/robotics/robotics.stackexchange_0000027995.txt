Q:

Gazebo System Requirements

Hi all,
I intend to buy a new laptop and configure a PC and wish to run Gazebo under Ubuntu. My experiments background are quadrotors swarm (more than 15 vehicles) whose software is based on PX4 SITL with Gazebo6.6.
I searched the internet and found the similar answers,

http://answers.gazebosim.org/question/8919/gazebo-system-requirements/
http://answers.gazebosim.org/question/4191/can-a-graphics-card-speed-up-gazebo/.

But these answers were little outmoded and I would like to know that

Whether NVIDIA GeForce is the bottleneck for Gazebo performance (real-time factor)?
On your experience related to Gazebo-based UAV Swarm Simulation, which type processor and graphic card are recommended?

Originally posted by Weiwei on Gazebo Answers with karma: 1 on 2017-01-01
Post score: 0

Original comments
Comment by Lyndwyrm on 2017-01-02:
I'm running gazebo on an octa-core, 8GB Ram and an nvidia quadro 5000, and it's already kind of laggy for my single robot simulation :D. The simulation takes up roughly 3 cores(running i3 instead of KDE).
So I would think my graphics card makes it slow.
Comment by Weiwei on 2017-01-03:
@Lyndwyrm Thank you for your reply. :)

A:

There are multiple bottlenecks in simulation, which depend on your use case. For example:

If you have lots of camera sensors, or a few high-resolution cameras, then rendering can be a bottleneck.
If you have a robot with many degrees of freedom, then physics (CPU) will be a bottleneck.
It is also likely that you have a combination of 1 & 2.

We recommend, and develop Gazebo on, a fairly modern computer (within the last two years). Not bleeding edge, but not 5 years old either.
Keep in mind that throwing more expensive hardware at a problem is not usually the best solution. Chances are you should modify simulation parameters to achieve desired results.

Originally posted by nkoenig with karma: 7676 on 2017-01-04
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by Weiwei on 2017-01-04:
@nkoenig Thank you for your kind reply. Would the Nvidia Graphic Card will speed up the rendering or ODE calculation? or all the ODE burden is for CPUs?
Comment by nkoenig on 2017-01-04:
Currently ODE uses only the CPU.
Comment by Weiwei on 2017-01-04:
@nkoenig Great. So Nvidia Graphic Card only enhances the rendering assignments?

