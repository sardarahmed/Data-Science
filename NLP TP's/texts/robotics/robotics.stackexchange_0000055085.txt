Q:

Which technique for 2D SLAM is easy to learn?

Hello Everybody,
A ROS newbie here. I'm learning ROS and currently at the file system tutorials.
I'm currently running ROS on 64-bit Ubuntu 12 and soon I'm going to install it on Beaglebone Black (Angstrom).
I have a Logitech C920 webcam with hardware H264. Please suggest me 2D slam technique which can be used with my webcam and is easy to learn.
Regards,
sarkar

Originally posted by sarkar on ROS Answers with karma: 36 on 2013-10-27
Post score: 1

A:

Hi
2D SLAM gives a 2D map of the envirnment called GMAP.(Refer to http://wiki.ros.org/gmapping) GMAP gives you detailed information about the object occupancy in that 2D plane. This occupancy grid generated from gmapping gives a accurate scaled information about the actual real world. Each x and y coordinate in this 2D grid is accurate just scaled to some particular resolution, whereas in image captured from camera is a perspective image hence there is no possible transformation possible from image to real world coordinates.
2D SLAM is technique, which is quite easily be performed using lasers. Since you are a "newbie", I would suggest you to use Kinect, which is cheapest multi-sensor available.
I am not saying that it is impossible to do 2D SLAM from a webcam, but it would require a lot of knowledge and effort.

Originally posted by sudhanshu_mittal with karma: 311 on 2013-10-29
This answer was ACCEPTED on the original site
Post score: 1

Original comments
Comment by MartinW on 2013-10-29:
Related sub-question, sudhanshu_mittal, Is it fairly easy to implement the 3D SLAM instead of the 2D SLAM in the Navigation stack? I am wondering because I am more familiar with ROS but not yet familiar with the Navigation stack or SLAM :) Thanks!
Comment by sudhanshu_mittal on 2013-10-29:
Definitely 2D SLAM is much more easier to implement that 3D SLAM, I have implemented 2D SLAM with turtlebot  as well as seen people implement 2D SLAM on self built robots using navigation stack. What i believe from my experience is, 3D SLAM is harder to implement and computationally very expensive.
Comment by sarkar on 2013-10-30:
sudhanshu_mittal,
I have IR Proximity sensors which I can easily connect to Beaglebone Black. Are they good choice for 2D slam? I think I'd need some kind of middleware to read their data in ROS through BBB pins.
sarkar
Comment by sarkar on 2013-10-30:
and the Kinect options seems reasonable. It's advantageous due to it's design as a slam and image processing sensor. Please provide a tutorial on how to use kinect for slam. However I think kinect doesn't have hardware H264 encoding that would make it difficult to use with Beaglebone.
Comment by MartinW on 2013-10-30:
Thanks for the reply! I eventually want to get 3D recognition (maybe SLAM) within the robot project I am working on but first I will get 2D SLAM working and then work on the more complex problems. Kind Regards, Martin
Comment by sudhanshu_mittal on 2013-10-30:
@sarkar: I have no experience with Beaglebone Black, but i can definitely say that its not possible to perform 2D slam/ gmapping from simple IR proximity sensor, since it gives only single point distance plus the data measured is raw.
Comment by sudhanshu_mittal on 2013-10-30:
@sarkar: First of all, if you have a ROS supported robot like turtlebot,..then you just have to launch a few files. If you are working with a self made robot, then a few extra steps need to be performed before using the inbuilt packages of ROS. Let me know, which robot you are using ?

