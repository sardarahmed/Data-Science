Q:

Real-time TCP position/pose control on a robotic arm such as YuMi: recommendation to calculate IK/Inverse Jacobian?

I plan to make a mouse or a gesture control robot like this video on YouTube : ABB Externally guided motion. 
For a 6-axes robot, I could implement it by using ABB’s EGM (Externally Guided Motion) option, which allows to send a Cartesian position and pose of TCP, and all the tedious calculation was handled by its controller. 
However, when I started to work on YuMi, I noticed that EGM’s position guide control cannot be applied to the 7-axes robot (For YuMi, a joint control mode in EGM is only available). Are there any recommendations to implement what I described above? 
Also, I'm guessing that I need to implement IK class to get the correct joints' angles from a desirable TCP position. Maybe using OpenRAVE or OMPL? If you have any recommendation to calculate IK / Inverse Jacobian, please let me know too.

A:

You have to differ between motion planning and control approaches:
What you want is control (no fancy planning algorithms in the loop).
Regarding the IK problem, this is the lib that you want to use:
https://bitbucket.org/traclabs/trac_ik
It is amazingly fast and super easy to use (given you have a URDF description of your robot). And it combines different IK approaches that run concurrently under the hood.
It is also available as a ROS package.
BUT: You have to take care about pose changes! So with a six / seven axis robot you can reach TCP poses with a variety of joint configurations. And if you just query the IK algorithm, it could spit out altering configurations, which would mean huge motions for your robot.
So thats why TracIK must be initialized with the current joint angles, so that it can chose a solution that is similar to the current one.
On top I would suggest a sanity check (accumulated joint distance threshold), so that you do not execute jumps, if Trac delivers a solution that implies a configuration change.

