Q:

How did the principle of explosion come up and was developed historically?

I am looking for some background information on the principle of explosion. When was it first formulated, how was it justified, and how did it affect interpretation and development of logic? Please include references where I can find more information.

A:

The principle/law of explosion had a curious history. Anellis in his review of Handbook of the History of Logic suggests that it was known already to ancient Stoics. Indeed, it is closely linked to the idea of the material conditional, which is true whenever the premise is false, and which goes back to Philo the Dialectician, c. 300 BC. It was not accepted in antiquity, however, Aristotle in Prior Analytic II 4 57b3 asserted quite the opposite:"it is impossible that the same thing should be necessitated by the being and by the not-being of the same thing". But it reappeared in the 12th century AD in Paris, where William of Soissons produced a derivation of it reconstructed by C.I. Lewis. Martin describes the path of the medieval theories of logical consequence towards William's derivation, going through Boethius and Abelard among others, in William's Machine.
The law was widely accepted in Europe by 14th century, when it appears in Questions on Aristotle’s Prior Analytics originally ascribed to a prominent scholastic Duns Scotus (authorship and dating are controversial), and in Book I of Tractatus de Consequentiis (c. 1330) by Buridan, a Parisian, who advanced remarkably modern notions of logical consequence and material conditional, see What were the historical interpretations of Aristotle's definition of validity/logical consequence? Łukasiewicz mentions pseudo-Scotus's example:"If Socrates exists and Socrates does not exist then Plato is an ass" in a 1925 paper. On Buridan there is a study by D'Ors Ex impossibili quodlibet sequitur (Jean Buridan), which is hard to find, and a commentary on it by Normore. Buridan is explicit about the connection of the law with the definition of the material conditional, see SEP, Medieval Theories of Consequence.
But wide does not mean universal. In the 15th century William's derivation was rejected by the school of Cologne, who objected to a step in it now called disjunctive syllogism, see SEP, Paraconsistent Logic. And in another paper, The Necessity in Deduction, Normore observes that the formal notion of logic that prevailed in the 14th century was replaced by a psychologistic one in the 16th (Leibniz was a rare late exception to the trend):

"Scholastic logic disappeared from the curriculum in Paris during the 1520s and disappeared from much of Europe by the middle of the century. The logical climate in which Descartes grew up was one in which the classical conception of validity that we share with the high Middle Ages was being eclipsed in favor of conceptions that emphasized the psychological dimension of reasoning. Within such a framework the Cartesian stress on the role of the natural light makes sense and so does the suggestion that what a deduction is to preserve is not necessity but certain truth.
If this is correct, then the logical revolution of the first half of the sixteenth century, a revolution that has seemed to most recent historians of logic to be a revolution away from logic, can perhaps be better seen as a revolutionary redirection of the conception of correct inference."

Formal logic and the material conditional, made a comeback again in the second half of 19th century, when Boole and De Morgan algebraized propositional logic, then Frege and Peirce invented predicate logic, and Frege and Husserl sharply criticized logical psychologism. And ex falso quodlibet came back along with them.
A detailed study of its early modern history, in connection with the emergence of the paraconsistent logic, is The Origins of the Use of the Argument of Trivialization in the Twentieth Century by Bobenrieth. Russell-Whitehead's Principia presents an "immediate consequence" of the principles, the formula $∼ p · ⊃ · p ⊃ q$ ($\neg p\to (p\to q)$), as formalizing that "one false proposition entails any proposition". Hilbert derived $(A\&¬A)→B$ from the "principle of contradiction" $(A → (B \& ¬B)) →¬A$ in his papers in 1920s. The first textbook on mathematical logic, Hilbert-Ackermann's Grundzüge der theoretischen Logik (1928), put into wide circulation the now familiar argument for consistency as a means of avoiding trivialization:

"It might seem as though we were giving a preferred position to one particular logical principle — the principle of contradiction. The fact is, however, that the occurrence of a formal contradiction, i.e. the provability of two formulas $A$ and $-A$, would condemn the entire calculus as meaningless; for we have observed above that if two sentences of form $A$ and $-A$ were provable the same would be true of any other sentences whatsoever. Thus consistency of the calculus in the sense of the definition has the same meaning as the stipulation that not every arbitrary formula be provable."

This argument was soon disputed by Wittgenstein in his Lecture XXI on the Foundations of Mathematics:"Well then, don’t draw any conclusions from a contradiction.  Make that a rule". He was challenged by Turing, who pointed out that arbitrary formulas can still be derived even without going through a contradiction explicitly. Eventually, this motivated a paraconsistent reworking of classical logic, where such roundabout ways are blocked as well, by dialetheists like Priest. To some extent, both the argument from trivialization and the ways around it were also anticipated by Łukasiewicz.

