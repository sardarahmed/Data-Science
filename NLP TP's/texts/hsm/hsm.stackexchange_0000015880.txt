Q:

Reference request: What were the problems of accepting zero, negative numbers, and complex numbers? And how were they solved?

I asked this question on MSE and comments suggested I should ask it here
I am currently reading Baby Rudin as my second analysis book (after Introduction to Real Analysis by Robert G. Bartle and Donald R. Sherbert) and I was surprised that Rudin’s book includes complex numbers, I tried to avoid complex numbers for a while because the way we were taught about them in school and even college was unsatisfactor They said something like "Mathematicians in the past didn’t accept complex numbers and thought they were meaningless and nonsense, but now they don't" and then moved on with the course without explaining why mathematicians in the past rejected complex numbers and what made them accept them later. This question has been on my mind for quite some time and I tried to avoid complex numbers as much as possible as this question is probably very hard to answer (after all, there must be a reason why we were not taught the answer to this question). But now, since I "have" to deal with complex numbers, I want to know the answer to this question. After some thought, I remembered that not only complex numbers was viewed as meaningless and nonsense then became normal, but also zero and negative numbers were not accepted and viewed as nonsense in the past, and then became normal.
So I want to ask for some references (books, articles, etc.) that explain what was the problem of accepting zero, negative numbers, and complex numbers, and how these problems were solved.
Jesse Madnick told me in the comments of my original question that

These problems were "solved" by humans understanding that mathematical ideas are just that: abstract concepts. All that's required for a mathematical object to exist is a precise definition and a rigorous proof of existence.

I want to ask what made modern mathematician think this way and when and how did this happen?

A:

What you write suggests that you still have difficulty with complex numbers.  I would suggest that you overcome such difficulties before you proceed to the next step such as delving deeply into real analysis and other advanced topics.  Results such as the fundamental theorem of algebra are ubiquitous in mathematics, including real analysis; therefore you would be seriously impeded in your progress in math without understanding complex numbers.
To respond to your historical question: the problem historically was that mathematical entities were required by many scholars to correspond to entities in the real world ("2" corresponds to two apples, etc.).  While modern mathematicians resolved the problem by rejecting such requirements, this was not the solution that initially allowed mathematicians to overcome such inhibitions.
Leibniz thought of numbers including surds (irrationals), negatives, imaginaries, infinitesimals as fictions that are only accidentally impossible but not contradictory.  This ties in to a certain extent with his doctrine of possible worlds: while such fictional numbers can't be found in our world, perhaps they could be found in other worlds (modern mathematicians of course don't need such justifications).  Thus there was an approach to justifying complex numbers several centuries before they were declared to be abstract entities (possibly fluttering in some realm of the abstracta).  Leibniz's approach didn't require that.  For a recent study of Leibnizian methodology, see this article.
In the last quarter of the 17th century, some leading scholars were still puzzled by the success of the complex numbers.  Thus, a famous episode has young Leibniz explaining to no less an authority than C. Huygens, and the latter reacting: "there is something here beyond my comprehension".  Leibniz did a lot to make complex numbers "legitimate".  The history of the solution of the cubic in the context of the development of Leibniz's philosophy was studied in detail in this publication.
Euler had numerous publications using complex numbers, and of course the famous formula $e^{i\theta}=\cos\theta+i\sin\theta$ was already in common use by the middle of the 18th century.  It would be a mistake to place the "legitimation" of complex numbers as late as the 19th century with Gauss.

A:

The problem with accepting complex numbers, when your only experience with "numbers" is the real number line, is lacking a visualization of them. No ordinary (i.e., real) number can square to a negative number, so square roots of negative numbers were considered impossible or fictional.
It took the authority of someone like Gauss to use complex numbers in productive ways in order to make their usage more widely accepted.  Moreover, the realization that complex numbers can be visualized as points in the ordinary plane helped lower the barrier to working with them: we could see what adding and multiplying does to complex numbers, so they are no longer scary objects.
The Springer-Verlag book "Numbers" by Ebbinghaus and several other people is a great resource on this: see the 1st section in Chapter 3.
The Veritasium video on the cubic formula here describes the algebraic source of complex numbers: solving cubic equations. A cubic polynomial clearly, by a graph, always has at least one real root, but the cubic formula sometimes expresses that root in terms of square roots of negative numbers (the formulas is a sum of two parts, and the imaginary parts cancel out, leaving a purely real number even when separate parts of the formula are not real).
The realization that math can describe things not immediately related to things in the real world was a slow process that accelerated throughout the 1800s. It came up most strikingly in geometry, with the discovery of non-Euclidean geometry (the hyperbolic plane) independently by Lobachevsky and Bolyai, as well as Gauss earlier, who kept his discovery secret because he knew it would be really controversial. Riemann introduced the idea of manifolds in any number of dimensions decades before others could really appreciate what he had done. In algebra there was the development of unusual number systems like  quaternions by Hamilton, which require 4 coordinates (at a time when the idea of 4 dimensions was unfamiliar).
In 1910, Ernst Steinitz wrote a very influential article on a general theory of fields. Its axiomatic approach was revolutionary and led to the viewpoint in abstract algebra advocated in the 1920s and 1930s by Artin and Noether, reaching a worldwide audience (well, among math students) when their lectures appeared in van der Waerden's textbook Morderne Algebra (1930). Steinitz wrote in a footnote in the introduction to his paper that the main inspiration leading him to prepare that article was Kurt Hensel's creation of the very unusual fields of $p$-adic numbers, which unlike all earlier fields were not in any natural way a subfield of the real or complex numbers or fields of functions (there are finite fields too, going back to Galois in the early 1800s).

